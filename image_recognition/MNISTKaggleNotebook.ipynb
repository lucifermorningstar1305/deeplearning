{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNISTKaggleNotebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjRVgFx-SnEE",
        "colab_type": "code",
        "outputId": "4dcc68bb-af23-47f3-83a1-80209eeab367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install torchvision torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp3p5upmStKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsOR-V2IS6JW",
        "colab_type": "code",
        "outputId": "fb8c5ea1-e15b-42e7-e427-4de39aacafa3",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "js = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bf1701aa-9504-4bc8-b0c3-cc0da6935c5f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-bf1701aa-9504-4bc8-b0c3-cc0da6935c5f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEmttpRiTB0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjF2x4BGTIHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp kaggle.json ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsmvSLsTTNSv",
        "colab_type": "code",
        "outputId": "76a056e1-bfae-4247-fd1f-5db0480af154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!kaggle competitions download -c digit-recognizer"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content\n",
            "  0% 0.00/6.09M [00:00<?, ?B/s]\n",
            "100% 6.09M/6.09M [00:00<00:00, 100MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/235k [00:00<?, ?B/s]\n",
            "100% 235k/235k [00:00<00:00, 74.7MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            "  0% 0.00/9.16M [00:00<?, ?B/s]\n",
            "100% 9.16M/9.16M [00:00<00:00, 151MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOSUthVQTfTu",
        "colab_type": "code",
        "outputId": "e22d0fb1-1fc2-4fea-e4f8-977aadb56a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6jWzaeVTvDz",
        "colab_type": "code",
        "outputId": "4593906a-dab4-46ff-be76-9c2bbbb2325f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!unzip train.csv.zip\n",
        "!unzip test.csv.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WZVwI3rcxQ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2fd1349e-8f8f-4bab-ad49-1b8a20d10784"
      },
      "source": [
        "!wget https://data.deepai.org/mnist.zip"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-25 20:44:47--  https://data.deepai.org/mnist.zip\n",
            "Resolving data.deepai.org (data.deepai.org)... 138.201.36.183\n",
            "Connecting to data.deepai.org (data.deepai.org)|138.201.36.183|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11600687 (11M) [application/zip]\n",
            "Saving to: ‘mnist.zip’\n",
            "\n",
            "mnist.zip           100%[===================>]  11.06M  11.0MB/s    in 1.0s    \n",
            "\n",
            "2020-01-25 20:44:49 (11.0 MB/s) - ‘mnist.zip’ saved [11600687/11600687]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW2dBqwzcybr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "603f0551-729c-4ebc-acfb-6bae9dcf0954"
      },
      "source": [
        "!unzip mnist.zip"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  mnist.zip\n",
            "  inflating: t10k-images-idx3-ubyte.gz  \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._t10k-images-idx3-ubyte.gz  \n",
            "  inflating: t10k-labels-idx1-ubyte.gz  \n",
            "  inflating: __MACOSX/._t10k-labels-idx1-ubyte.gz  \n",
            "  inflating: train-images-idx3-ubyte.gz  \n",
            "  inflating: __MACOSX/._train-images-idx3-ubyte.gz  \n",
            "  inflating: train-labels-idx1-ubyte.gz  \n",
            "  inflating: __MACOSX/._train-labels-idx1-ubyte.gz  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ_lwQlpT2g-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as Data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcmNxcr8VUo3",
        "colab_type": "code",
        "outputId": "07ab826c-666e-4f42-862d-cd1da15348f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.manual_seed(1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f2ae8302350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxmv0D7rVcwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7ZWYwOGVnmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain, ytrain = train_data.loc[:, 'pixel0':].values.astype('float32'), train_data.loc[:,'label'].values.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyLpUpIlWByf",
        "colab_type": "code",
        "outputId": "d67b595c-1433-41ce-8a3e-cb6f7a112041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(1,11):\n",
        "  ax = fig.add_subplot(1,10,i)\n",
        "  ax.set_title(ytrain[i-1])\n",
        "  ax.axis('off')\n",
        "  plt.imshow(np.reshape(Xtrain[i-1,:],(28,28)),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAABNCAYAAACi7r7XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKIqiKIoSenTBoyiKoihK6Pl/2u6EbRPhqEkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl-L0E8cWvvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1,out_channels=64, kernel_size=5, stride = 1, padding = 2),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.25)\n",
        "    )\n",
        "    \n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, stride=1, padding=2),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.25)\n",
        "    )\n",
        "    \n",
        "    # self.conv3 = nn.Sequential(\n",
        "    #     nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size=5, stride = 1, padding=2),\n",
        "    #     nn.MaxPool2d(2),\n",
        "    #     nn.ReLU(),\n",
        "    #     nn.Dropout(p=0.25)\n",
        "    # )\n",
        "    \n",
        "\n",
        "    self.fc1 = nn.Linear(128*7*7, 1024)\n",
        "    self.batchNorm = nn.BatchNorm1d(1024)\n",
        "    self.out = nn.Linear(1024, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    # x = self.batchNorm1(x)\n",
        "    x = self.conv2(x)\n",
        "    # x = self.batchNorm2(x)\n",
        "    # x = self.conv3(x)\n",
        "    # x = self.batchNorm3(x)\n",
        "    # print(x.size())\n",
        "    x = x.view(x.size(0),-1)\n",
        "    # print(x.size())\n",
        "    x = self.fc1(x)\n",
        "    x = self.batchNorm(x)\n",
        "    output = self.out(x)\n",
        "    return x, output\n",
        "\n",
        "cnn = CNN().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjXgu_zaZR7r",
        "colab_type": "code",
        "outputId": "182af150-2c89-414f-913a-2494f8718265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "cnn \n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              "  (fc1): Linear(in_features=6272, out_features=1024, bias=True)\n",
              "  (batchNorm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (out): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALkAVx5HZoD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.01)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwnOxWnYZ9Tq",
        "colab_type": "code",
        "outputId": "c851b9ba-9530-4ee9-8eb0-90e9d3146fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train_data.values"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [7, 0, 0, ..., 0, 0, 0],\n",
              "       [6, 0, 0, ..., 0, 0, 0],\n",
              "       [9, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2csQSLr0a6K8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainingX = torch.Tensor(Xtrain)\n",
        "trainingY = torch.Tensor(ytrain)\n",
        "trainingX = trainingX/255.\n",
        "trainingY = trainingY"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3ODyCVabNo4",
        "colab_type": "code",
        "outputId": "30d94369-bb67-445e-bfd6-7be64dfb5b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(trainingX)\n",
        "print(trainingY)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "tensor([1., 0., 1.,  ..., 7., 6., 9.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpVyPMM9bOd6",
        "colab_type": "code",
        "outputId": "477dbb09-14d2-4c34-a896-3bfeb49dce5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print(trainingX.size())\n",
        "print(trainingY.size())\n",
        "training = Data.TensorDataset(trainingX, trainingY)\n",
        "train_loader = Data.DataLoader(dataset=training, batch_size = 256, shuffle=True)\n",
        "testing = test_data.values\n",
        "testing = torch.from_numpy(testing)\n",
        "testing = testing.type(torch.FloatTensor)/255.\n",
        "print(type(testing))\n",
        "print(testing)\n",
        "print(train_loader)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([42000, 784])\n",
            "torch.Size([42000])\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7f2ace075f28>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7UEHWSycekm",
        "colab_type": "code",
        "outputId": "4318e579-1d33-4012-f561-8ae0bf331832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(500):\n",
        "  for x,y in train_loader:\n",
        "    # print(_t)\n",
        "    b_x = Variable(x.cuda()).float()\n",
        "    b_y = Variable(y.cuda()).long()\n",
        "    b_x = b_x.view(-1,1,28,28)\n",
        "    # print(b_x.size())\n",
        "    output = cnn(b_x)[0]\n",
        "    # print(output)\n",
        "    # print(b_y)\n",
        "    # print(type(output))\n",
        "    # print(type(b_y))\n",
        "    # b_y = b_y.type(torch.FloatTensor)\n",
        "    loss = loss_func(output, b_y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i % 10 == 0:\n",
        "      prediction, last_layer = cnn(b_x)\n",
        "      prediction = torch.max(prediction,1)[1].data.squeeze()\n",
        "      accuracy = (prediction == b_y).sum().item()/float(b_y.size(0))\n",
        "      print('Epoch : {}, Loss: {:.9f}, TrainingAccuracy: {:.5f}'.format(i, loss, accuracy*100))\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0, Loss: 7.338175297, TrainingAccuracy: 3.12500\n",
            "Epoch : 0, Loss: 6.075191021, TrainingAccuracy: 24.21875\n",
            "Epoch : 0, Loss: 5.401498318, TrainingAccuracy: 63.67188\n",
            "Epoch : 0, Loss: 5.231554031, TrainingAccuracy: 68.35938\n",
            "Epoch : 0, Loss: 4.929961681, TrainingAccuracy: 85.93750\n",
            "Epoch : 0, Loss: 4.875289440, TrainingAccuracy: 80.85938\n",
            "Epoch : 0, Loss: 4.735418320, TrainingAccuracy: 87.10938\n",
            "Epoch : 0, Loss: 4.742014885, TrainingAccuracy: 85.54688\n",
            "Epoch : 0, Loss: 4.534196377, TrainingAccuracy: 86.71875\n",
            "Epoch : 0, Loss: 4.525298595, TrainingAccuracy: 85.54688\n",
            "Epoch : 0, Loss: 4.489111423, TrainingAccuracy: 87.10938\n",
            "Epoch : 0, Loss: 4.360131741, TrainingAccuracy: 89.06250\n",
            "Epoch : 0, Loss: 4.279912472, TrainingAccuracy: 89.06250\n",
            "Epoch : 0, Loss: 4.191609383, TrainingAccuracy: 91.01562\n",
            "Epoch : 0, Loss: 4.157455444, TrainingAccuracy: 90.23438\n",
            "Epoch : 0, Loss: 4.136871338, TrainingAccuracy: 88.28125\n",
            "Epoch : 0, Loss: 4.037359238, TrainingAccuracy: 88.67188\n",
            "Epoch : 0, Loss: 3.948515177, TrainingAccuracy: 93.35938\n",
            "Epoch : 0, Loss: 3.887818098, TrainingAccuracy: 92.18750\n",
            "Epoch : 0, Loss: 3.833229065, TrainingAccuracy: 92.18750\n",
            "Epoch : 0, Loss: 3.789742708, TrainingAccuracy: 93.75000\n",
            "Epoch : 0, Loss: 3.677623510, TrainingAccuracy: 93.35938\n",
            "Epoch : 0, Loss: 3.623339891, TrainingAccuracy: 94.14062\n",
            "Epoch : 0, Loss: 3.637643099, TrainingAccuracy: 91.01562\n",
            "Epoch : 0, Loss: 3.561802387, TrainingAccuracy: 91.79688\n",
            "Epoch : 0, Loss: 3.458434582, TrainingAccuracy: 93.35938\n",
            "Epoch : 0, Loss: 3.412330389, TrainingAccuracy: 94.92188\n",
            "Epoch : 0, Loss: 3.412137985, TrainingAccuracy: 94.14062\n",
            "Epoch : 0, Loss: 3.328975439, TrainingAccuracy: 96.48438\n",
            "Epoch : 0, Loss: 3.277785540, TrainingAccuracy: 91.79688\n",
            "Epoch : 0, Loss: 3.260105848, TrainingAccuracy: 92.96875\n",
            "Epoch : 0, Loss: 3.178619862, TrainingAccuracy: 95.31250\n",
            "Epoch : 0, Loss: 3.097280264, TrainingAccuracy: 91.79688\n",
            "Epoch : 0, Loss: 3.041702986, TrainingAccuracy: 96.48438\n",
            "Epoch : 0, Loss: 3.031817675, TrainingAccuracy: 93.35938\n",
            "Epoch : 0, Loss: 2.939327478, TrainingAccuracy: 96.87500\n",
            "Epoch : 0, Loss: 2.873884201, TrainingAccuracy: 96.09375\n",
            "Epoch : 0, Loss: 2.793208838, TrainingAccuracy: 96.09375\n",
            "Epoch : 0, Loss: 2.852110624, TrainingAccuracy: 96.09375\n",
            "Epoch : 0, Loss: 2.707406521, TrainingAccuracy: 95.70312\n",
            "Epoch : 0, Loss: 2.792052507, TrainingAccuracy: 94.92188\n",
            "Epoch : 0, Loss: 2.652401209, TrainingAccuracy: 93.75000\n",
            "Epoch : 0, Loss: 2.608872890, TrainingAccuracy: 95.70312\n",
            "Epoch : 0, Loss: 2.496698141, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 2.568159342, TrainingAccuracy: 94.53125\n",
            "Epoch : 0, Loss: 2.485766411, TrainingAccuracy: 95.31250\n",
            "Epoch : 0, Loss: 2.421247721, TrainingAccuracy: 96.48438\n",
            "Epoch : 0, Loss: 2.364551306, TrainingAccuracy: 97.26562\n",
            "Epoch : 0, Loss: 2.426554441, TrainingAccuracy: 95.70312\n",
            "Epoch : 0, Loss: 2.274868011, TrainingAccuracy: 97.26562\n",
            "Epoch : 0, Loss: 2.322252274, TrainingAccuracy: 95.31250\n",
            "Epoch : 0, Loss: 2.220371008, TrainingAccuracy: 96.48438\n",
            "Epoch : 0, Loss: 2.216285229, TrainingAccuracy: 94.92188\n",
            "Epoch : 0, Loss: 2.189753294, TrainingAccuracy: 95.31250\n",
            "Epoch : 0, Loss: 2.117542028, TrainingAccuracy: 95.70312\n",
            "Epoch : 0, Loss: 2.082088470, TrainingAccuracy: 95.70312\n",
            "Epoch : 0, Loss: 2.024225473, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 1.967272639, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 1.952428341, TrainingAccuracy: 96.87500\n",
            "Epoch : 0, Loss: 1.983247280, TrainingAccuracy: 94.53125\n",
            "Epoch : 0, Loss: 1.913853884, TrainingAccuracy: 96.48438\n",
            "Epoch : 0, Loss: 1.855330944, TrainingAccuracy: 96.48438\n",
            "Epoch : 0, Loss: 1.848672986, TrainingAccuracy: 96.48438\n",
            "Epoch : 0, Loss: 1.772989631, TrainingAccuracy: 96.87500\n",
            "Epoch : 0, Loss: 1.748010874, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 1.619307280, TrainingAccuracy: 97.26562\n",
            "Epoch : 0, Loss: 1.692320704, TrainingAccuracy: 95.31250\n",
            "Epoch : 0, Loss: 1.581456304, TrainingAccuracy: 98.43750\n",
            "Epoch : 0, Loss: 1.591196060, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 1.533529401, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 1.544857264, TrainingAccuracy: 96.87500\n",
            "Epoch : 0, Loss: 1.462348819, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 1.476594448, TrainingAccuracy: 98.43750\n",
            "Epoch : 0, Loss: 1.495427370, TrainingAccuracy: 96.87500\n",
            "Epoch : 0, Loss: 1.446328044, TrainingAccuracy: 96.48438\n",
            "Epoch : 0, Loss: 1.355727315, TrainingAccuracy: 98.82812\n",
            "Epoch : 0, Loss: 1.378052354, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 1.327734828, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 1.290023327, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 1.347985029, TrainingAccuracy: 96.87500\n",
            "Epoch : 0, Loss: 1.262022376, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 1.219696879, TrainingAccuracy: 97.26562\n",
            "Epoch : 0, Loss: 1.209287524, TrainingAccuracy: 96.87500\n",
            "Epoch : 0, Loss: 1.182998300, TrainingAccuracy: 98.43750\n",
            "Epoch : 0, Loss: 1.200395584, TrainingAccuracy: 96.09375\n",
            "Epoch : 0, Loss: 1.104423881, TrainingAccuracy: 99.21875\n",
            "Epoch : 0, Loss: 1.081272125, TrainingAccuracy: 98.82812\n",
            "Epoch : 0, Loss: 1.139032960, TrainingAccuracy: 96.48438\n",
            "Epoch : 0, Loss: 1.171939731, TrainingAccuracy: 95.70312\n",
            "Epoch : 0, Loss: 1.087696671, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 1.054112911, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 1.078028440, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.987943530, TrainingAccuracy: 98.82812\n",
            "Epoch : 0, Loss: 0.914304972, TrainingAccuracy: 98.82812\n",
            "Epoch : 0, Loss: 0.958427370, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 0.934558690, TrainingAccuracy: 98.82812\n",
            "Epoch : 0, Loss: 0.945056021, TrainingAccuracy: 96.09375\n",
            "Epoch : 0, Loss: 0.950730562, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.847343862, TrainingAccuracy: 96.87500\n",
            "Epoch : 0, Loss: 0.862920642, TrainingAccuracy: 98.43750\n",
            "Epoch : 0, Loss: 0.916495860, TrainingAccuracy: 95.70312\n",
            "Epoch : 0, Loss: 0.856038570, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.799321294, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.803908765, TrainingAccuracy: 97.26562\n",
            "Epoch : 0, Loss: 0.792185247, TrainingAccuracy: 98.43750\n",
            "Epoch : 0, Loss: 0.796859801, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 0.770768881, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 0.720100880, TrainingAccuracy: 98.82812\n",
            "Epoch : 0, Loss: 0.741564929, TrainingAccuracy: 97.26562\n",
            "Epoch : 0, Loss: 0.667348742, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.702164829, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.690013051, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.649839520, TrainingAccuracy: 98.82812\n",
            "Epoch : 0, Loss: 0.712294757, TrainingAccuracy: 97.26562\n",
            "Epoch : 0, Loss: 0.613782227, TrainingAccuracy: 98.43750\n",
            "Epoch : 0, Loss: 0.654481947, TrainingAccuracy: 98.43750\n",
            "Epoch : 0, Loss: 0.595962882, TrainingAccuracy: 99.21875\n",
            "Epoch : 0, Loss: 0.626030028, TrainingAccuracy: 96.87500\n",
            "Epoch : 0, Loss: 0.599551320, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 0.593818426, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 0.579550803, TrainingAccuracy: 99.21875\n",
            "Epoch : 0, Loss: 0.538156152, TrainingAccuracy: 99.21875\n",
            "Epoch : 0, Loss: 0.574301898, TrainingAccuracy: 97.26562\n",
            "Epoch : 0, Loss: 0.564967215, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.562980115, TrainingAccuracy: 96.87500\n",
            "Epoch : 0, Loss: 0.513890326, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 0.501987338, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.554481864, TrainingAccuracy: 96.87500\n",
            "Epoch : 0, Loss: 0.493064702, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.430442631, TrainingAccuracy: 99.60938\n",
            "Epoch : 0, Loss: 0.499546349, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.524672687, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 0.529946506, TrainingAccuracy: 97.26562\n",
            "Epoch : 0, Loss: 0.468281060, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.483422190, TrainingAccuracy: 99.21875\n",
            "Epoch : 0, Loss: 0.421932906, TrainingAccuracy: 98.82812\n",
            "Epoch : 0, Loss: 0.460628211, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.494364053, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 0.445642650, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 0.465440750, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 0.440883994, TrainingAccuracy: 98.43750\n",
            "Epoch : 0, Loss: 0.436695278, TrainingAccuracy: 98.43750\n",
            "Epoch : 0, Loss: 0.379766703, TrainingAccuracy: 99.21875\n",
            "Epoch : 0, Loss: 0.392794579, TrainingAccuracy: 98.82812\n",
            "Epoch : 0, Loss: 0.392394483, TrainingAccuracy: 99.21875\n",
            "Epoch : 0, Loss: 0.378716499, TrainingAccuracy: 98.82812\n",
            "Epoch : 0, Loss: 0.382567763, TrainingAccuracy: 99.21875\n",
            "Epoch : 0, Loss: 0.419940472, TrainingAccuracy: 98.82812\n",
            "Epoch : 0, Loss: 0.449330539, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.402077377, TrainingAccuracy: 97.65625\n",
            "Epoch : 0, Loss: 0.395325691, TrainingAccuracy: 98.43750\n",
            "Epoch : 0, Loss: 0.336521506, TrainingAccuracy: 98.43750\n",
            "Epoch : 0, Loss: 0.449794948, TrainingAccuracy: 98.43750\n",
            "Epoch : 0, Loss: 0.355878830, TrainingAccuracy: 98.82812\n",
            "Epoch : 0, Loss: 0.399819911, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.307226539, TrainingAccuracy: 99.60938\n",
            "Epoch : 0, Loss: 0.385850072, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.333766431, TrainingAccuracy: 98.43750\n",
            "Epoch : 0, Loss: 0.325277954, TrainingAccuracy: 99.60938\n",
            "Epoch : 0, Loss: 0.325660437, TrainingAccuracy: 98.04688\n",
            "Epoch : 0, Loss: 0.359230995, TrainingAccuracy: 99.60938\n",
            "Epoch : 0, Loss: 0.337459564, TrainingAccuracy: 99.60938\n",
            "Epoch : 0, Loss: 0.323789626, TrainingAccuracy: 98.82812\n",
            "Epoch : 0, Loss: 0.309544981, TrainingAccuracy: 98.82812\n",
            "Epoch : 0, Loss: 0.801294804, TrainingAccuracy: 93.75000\n",
            "Epoch : 10, Loss: 0.021913441, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.013104502, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.010083521, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.057922453, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.016223596, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.031476997, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.014175143, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.036658660, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.030076101, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.022073340, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.038721554, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.024247985, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.025892444, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.067382991, TrainingAccuracy: 98.43750\n",
            "Epoch : 10, Loss: 0.018888792, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.019858226, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.045404818, TrainingAccuracy: 98.82812\n",
            "Epoch : 10, Loss: 0.022519596, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.018599778, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.014385490, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.018840235, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.027687350, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.036269132, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.031511337, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.042059794, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.022435986, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.029705169, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.030495999, TrainingAccuracy: 98.82812\n",
            "Epoch : 10, Loss: 0.017565684, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.025918866, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.033558957, TrainingAccuracy: 98.82812\n",
            "Epoch : 10, Loss: 0.036341053, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.010723827, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.028309155, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.016822163, TrainingAccuracy: 98.82812\n",
            "Epoch : 10, Loss: 0.015390106, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.022536064, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.015638452, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.021921754, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.020621479, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.022900412, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.018760135, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.014035119, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.018597648, TrainingAccuracy: 98.82812\n",
            "Epoch : 10, Loss: 0.023987042, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.030578725, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.052373275, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.019850401, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.020398406, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.026909083, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.010039262, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.013427567, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.013844766, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.014278391, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.048357688, TrainingAccuracy: 98.82812\n",
            "Epoch : 10, Loss: 0.022653282, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.033209201, TrainingAccuracy: 98.82812\n",
            "Epoch : 10, Loss: 0.024496550, TrainingAccuracy: 98.43750\n",
            "Epoch : 10, Loss: 0.014820790, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.014851246, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.011303006, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.016787345, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.013701841, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.017541775, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.018010072, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.028060431, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.021872813, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.022736814, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.008964727, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.012932979, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.016354809, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.022468537, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.015121071, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.010470873, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.013290115, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.015979825, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.020655315, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.013528336, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.015421035, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.013863727, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.024598446, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.015242592, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.023947168, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.021035662, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.029913994, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.014957475, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.015722347, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.009317389, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.013485471, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.017040635, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.036455445, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.033147879, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.014095899, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.008037955, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.019922977, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.041392617, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.026372466, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.017649764, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.007401522, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.026367716, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.015460998, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.016098462, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.021739019, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.037254535, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.065797672, TrainingAccuracy: 98.82812\n",
            "Epoch : 10, Loss: 0.016122703, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.032358889, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.017870981, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.015020613, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.020916618, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.011451613, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.023665057, TrainingAccuracy: 98.82812\n",
            "Epoch : 10, Loss: 0.006643191, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.039426263, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.014728880, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.027857812, TrainingAccuracy: 98.82812\n",
            "Epoch : 10, Loss: 0.027732246, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.026950654, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.013661759, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.024344010, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.021272022, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.037646405, TrainingAccuracy: 98.82812\n",
            "Epoch : 10, Loss: 0.021989943, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.041732304, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.016466150, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.017926414, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.012693051, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.014041465, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.019688277, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.037339158, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.017172024, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.012873182, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.016014356, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.018440392, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.012864942, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.019519668, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.012102408, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.014579872, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.015851937, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.025011895, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.010176804, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.044257265, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.008040005, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.012560982, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.016412534, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.038585246, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.010061193, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.011240982, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.006857485, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.027267318, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.032783177, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.018963797, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.018517921, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.041891076, TrainingAccuracy: 98.82812\n",
            "Epoch : 10, Loss: 0.030151818, TrainingAccuracy: 98.82812\n",
            "Epoch : 10, Loss: 0.021766346, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.015677439, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.011185851, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.036354601, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.028309796, TrainingAccuracy: 99.21875\n",
            "Epoch : 10, Loss: 0.026512953, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.009865217, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.025883894, TrainingAccuracy: 99.60938\n",
            "Epoch : 10, Loss: 0.010588072, TrainingAccuracy: 100.00000\n",
            "Epoch : 10, Loss: 0.268817157, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.006414693, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.011312736, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.010196934, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.010753829, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.017486358, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.023603436, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.023076320, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.055290498, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.018910397, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.014041947, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.029986624, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.022903768, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.028642075, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.029073846, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.015128991, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.028244564, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.019612690, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.031583492, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.026294025, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.029123968, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.010911124, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.023798173, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.050351489, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.016735153, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.020720880, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.009052167, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.010437848, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.021066939, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.016094338, TrainingAccuracy: 98.82812\n",
            "Epoch : 20, Loss: 0.025030674, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.046118785, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.014210625, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.017735077, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.019804318, TrainingAccuracy: 98.43750\n",
            "Epoch : 20, Loss: 0.028565824, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.017260648, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.014905933, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.019672628, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.022335837, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.025380567, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.049892597, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.007922325, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.014318068, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.009733103, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.022303505, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.008221021, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.006244155, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.026120756, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.023656094, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.006062880, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.035342012, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.018975742, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.009807672, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.017673174, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.015769225, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.008693717, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.012629895, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.015739851, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.061719757, TrainingAccuracy: 98.43750\n",
            "Epoch : 20, Loss: 0.032390315, TrainingAccuracy: 98.82812\n",
            "Epoch : 20, Loss: 0.007457739, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.007781357, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.010139639, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.005252043, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.005961170, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.012598734, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.012639645, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.009660017, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.016821109, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.029979156, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.043668408, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.017668832, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.019604553, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.019464444, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.018043444, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.017065030, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.017568519, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.010003993, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.010482047, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.005588580, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.010580080, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.025372803, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.016423125, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.013682146, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.004323853, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.008630631, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.007473648, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.003925795, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.008054711, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.019397302, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.012545537, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.011213671, TrainingAccuracy: 98.82812\n",
            "Epoch : 20, Loss: 0.005793391, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.011341676, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.014656801, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.033301122, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.010157241, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.004856911, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.015157484, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.014596768, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.010658041, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.006675361, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.019128969, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.014015412, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.007620739, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.018034970, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.009906244, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.008138645, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.007958861, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.014778066, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.007891981, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.015008671, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.013206849, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.012573030, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.005726639, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.017015066, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.013606580, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.011695111, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.011356778, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.009550644, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.011902483, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.006511360, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.007702818, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.007616630, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.029115675, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.008512188, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.009546565, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.015303025, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.014681481, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.027825698, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.010696542, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.033208285, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.017399693, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.003623951, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.008769870, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.012835346, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.014692558, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.009204302, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.009839395, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.006352846, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.010623598, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.010692796, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.015210627, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.031470753, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.010572974, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.010122405, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.010548795, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.005786138, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.010219032, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.008832326, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.007285841, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.011655288, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.010352068, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.003145318, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.008287540, TrainingAccuracy: 99.21875\n",
            "Epoch : 20, Loss: 0.008496109, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.025472296, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.015271192, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.009754697, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.003076177, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.007009221, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.009245632, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.010583414, TrainingAccuracy: 100.00000\n",
            "Epoch : 20, Loss: 0.018279698, TrainingAccuracy: 99.60938\n",
            "Epoch : 20, Loss: 0.279443711, TrainingAccuracy: 93.75000\n",
            "Epoch : 30, Loss: 0.004734404, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.003018025, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.013558036, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.023481220, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.028487729, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.028999152, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.010716712, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.034697581, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.057162087, TrainingAccuracy: 98.43750\n",
            "Epoch : 30, Loss: 0.031664468, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.014332129, TrainingAccuracy: 98.82812\n",
            "Epoch : 30, Loss: 0.041319311, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.017274190, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.032436021, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.029329086, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.018947138, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.030088920, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.010646107, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.008984879, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.047499776, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.037000112, TrainingAccuracy: 98.82812\n",
            "Epoch : 30, Loss: 0.015726309, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.020218808, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.012671981, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.028175004, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.031182090, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.006239302, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.009991782, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.031433865, TrainingAccuracy: 98.82812\n",
            "Epoch : 30, Loss: 0.010972939, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.002521230, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.009447815, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.036957748, TrainingAccuracy: 98.82812\n",
            "Epoch : 30, Loss: 0.010150373, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.023135774, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.018536204, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.009684410, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.016030949, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.039569151, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.012635916, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.009621764, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.013708610, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.022659604, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.006732870, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.007958136, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.027738955, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.003547572, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.015554214, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.028641518, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.005378731, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.029242937, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.011748020, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.014277577, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.021336481, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.004653167, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.008988261, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.007564960, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.031885173, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.009571292, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.018938532, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.012078419, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.010765897, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.011838596, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.010245398, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.022441188, TrainingAccuracy: 98.43750\n",
            "Epoch : 30, Loss: 0.007445406, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.021191614, TrainingAccuracy: 98.43750\n",
            "Epoch : 30, Loss: 0.011889474, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.012048569, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.007948702, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.005484702, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.017884595, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.007061914, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.011008330, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.014584666, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.016567281, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.010227740, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.017479686, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.005011454, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.006917544, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.012134546, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.016306695, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.007429607, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.020406473, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.008700546, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.013583675, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.006995499, TrainingAccuracy: 98.82812\n",
            "Epoch : 30, Loss: 0.005363669, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.014902219, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.006027015, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.014515925, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.004034411, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.010100950, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.007255463, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.015279289, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.003155062, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.005824316, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.024303529, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.004716657, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.008565754, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.009069687, TrainingAccuracy: 98.82812\n",
            "Epoch : 30, Loss: 0.004400345, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.007157151, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.006485889, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.018750144, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.014015011, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.006043132, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.024295475, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.028555971, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.008001016, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.013025520, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.004962889, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.007726924, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.005358251, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.006910160, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.007746113, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.021621279, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.008527007, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.035022207, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.004037380, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.013033222, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.003140479, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.004732570, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.003953617, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.023961606, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.017994111, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.003578208, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.003485978, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.006159833, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.018385658, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.012260586, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.010091456, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.018567247, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.009694390, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.007369457, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.008847976, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.019656776, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.031743120, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.010598015, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.021994393, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.007158408, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.004205070, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.006093618, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.009971151, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.013667405, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.012164585, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.002992673, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.016617980, TrainingAccuracy: 99.21875\n",
            "Epoch : 30, Loss: 0.008185340, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.010757115, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.014275024, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.006527711, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.008481756, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.010254959, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.004141241, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.015371099, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.003281444, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.016043317, TrainingAccuracy: 99.60938\n",
            "Epoch : 30, Loss: 0.002917502, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.010645211, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.012518495, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.001630254, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.002648752, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.010251977, TrainingAccuracy: 100.00000\n",
            "Epoch : 30, Loss: 0.216424763, TrainingAccuracy: 87.50000\n",
            "Epoch : 40, Loss: 0.001910141, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.002146866, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.008982942, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.007608030, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.020027280, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.001525540, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.001266379, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.004423235, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.002899181, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.013990099, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.016372016, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.004605897, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.005810611, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.006297670, TrainingAccuracy: 99.21875\n",
            "Epoch : 40, Loss: 0.017048962, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.007073477, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.004365621, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.013391403, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.023063736, TrainingAccuracy: 99.21875\n",
            "Epoch : 40, Loss: 0.012967924, TrainingAccuracy: 98.82812\n",
            "Epoch : 40, Loss: 0.035142716, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.001534324, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.002949713, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.012617368, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.005323768, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.025049232, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003991218, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.002633389, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003729897, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.002413969, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.013747763, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.005964946, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.004540540, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.002360715, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.001858694, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.005086849, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.005015925, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.005275453, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.005939648, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.002057008, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.005177619, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.007301982, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.006145338, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.014975891, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.008489892, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003398903, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003313815, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.002456147, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.007191066, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.003036302, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.001327537, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.002703091, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.012226522, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.008448049, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.001727089, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.007008811, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.011750050, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.004640229, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003873961, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.004421715, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.012854325, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003217699, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.013175325, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.008989261, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.003559824, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003250109, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.004725602, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.001026645, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.022652980, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.001641229, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.005006822, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.011470687, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.005771955, TrainingAccuracy: 99.21875\n",
            "Epoch : 40, Loss: 0.003367184, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.005296554, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.003901439, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.004828043, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.001885824, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003374921, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.009257492, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.006404534, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.027634872, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.003846910, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.020285590, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.038626246, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.009204028, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.001874387, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.002067275, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003456121, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.013364354, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.006891664, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.002316810, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.002580252, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.001600433, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.002091892, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.002318909, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.004617481, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.001522936, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003616028, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.004405079, TrainingAccuracy: 99.21875\n",
            "Epoch : 40, Loss: 0.001063474, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003709247, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.007409219, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.004269840, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.005187416, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.009186104, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003914179, TrainingAccuracy: 99.21875\n",
            "Epoch : 40, Loss: 0.006341601, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.004994178, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.007024536, TrainingAccuracy: 99.21875\n",
            "Epoch : 40, Loss: 0.004225679, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.005450526, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.017466120, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003793299, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.009647116, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.009897131, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.005407166, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003079034, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.012134664, TrainingAccuracy: 99.21875\n",
            "Epoch : 40, Loss: 0.011536755, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.002622735, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.005978646, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.002651624, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.007784003, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.001443811, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.005260257, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.002366208, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.015636493, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.002145808, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.001537923, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003915908, TrainingAccuracy: 99.21875\n",
            "Epoch : 40, Loss: 0.005054615, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.002109166, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.004156595, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.014855145, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.001924250, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003057290, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.008360324, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.007108599, TrainingAccuracy: 99.21875\n",
            "Epoch : 40, Loss: 0.002160199, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003970409, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.004175175, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.001618631, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.001719741, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003757801, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.002420481, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003273476, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.011735871, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.005674709, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.001714520, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.006985009, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.001560744, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.004599575, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.002874698, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.006179169, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.004696349, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.002509834, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.003168739, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.001937808, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.016012520, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.003206696, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.007894626, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.002932593, TrainingAccuracy: 99.60938\n",
            "Epoch : 40, Loss: 0.008208271, TrainingAccuracy: 100.00000\n",
            "Epoch : 40, Loss: 0.159113288, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.006116178, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.000546560, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002019200, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002345372, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.004204635, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.020542961, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.006519407, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.000539295, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.003317211, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.010779686, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.004366621, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.003275994, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002298642, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.005236264, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.002224971, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.014587428, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.024043700, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.001474541, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.003825944, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.004147753, TrainingAccuracy: 99.21875\n",
            "Epoch : 50, Loss: 0.003760779, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.003265381, TrainingAccuracy: 99.21875\n",
            "Epoch : 50, Loss: 0.006543364, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.002214935, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.002876811, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.010087550, TrainingAccuracy: 98.82812\n",
            "Epoch : 50, Loss: 0.021246567, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.019808527, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.004579905, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002032537, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.001499720, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.005219311, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.001536183, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.001121927, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.004870240, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.001085971, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.010863373, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.004629020, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002818283, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.003018163, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.005644163, TrainingAccuracy: 99.21875\n",
            "Epoch : 50, Loss: 0.002588296, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.012035400, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.012970468, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.009484027, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002084434, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.003334707, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002489693, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002093207, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.005374856, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.003424084, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.004392996, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.008800767, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.006253775, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.003119351, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.001198031, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.008078992, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.010563178, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.006063260, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002066918, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.003485423, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.003616463, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002155287, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.008326169, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002193052, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.003009595, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.001179855, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.003616329, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.003999330, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.002960915, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002467431, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.007256098, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.000832457, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.003130786, TrainingAccuracy: 99.21875\n",
            "Epoch : 50, Loss: 0.002206052, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.000679318, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.013089344, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.004169641, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.013710782, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.004569635, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.006076222, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.001452319, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.001819357, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.006984774, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.001225255, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.006795745, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.009655369, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.017212167, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.002807379, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.003287174, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.003927089, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.001416206, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.005180173, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.011854831, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.018578703, TrainingAccuracy: 99.21875\n",
            "Epoch : 50, Loss: 0.006665759, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.008869700, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.010568514, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002914608, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.003199611, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.001662496, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.010367678, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.007658811, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.007061865, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.009542156, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.001171093, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.003896400, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.019553542, TrainingAccuracy: 99.21875\n",
            "Epoch : 50, Loss: 0.004756812, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.001317259, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.007150069, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.001664884, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002117354, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.004146907, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.001849171, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.009466322, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.000712946, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.000880949, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.001898525, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.024332039, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002414830, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.007586166, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.005202027, TrainingAccuracy: 99.21875\n",
            "Epoch : 50, Loss: 0.003681116, TrainingAccuracy: 99.21875\n",
            "Epoch : 50, Loss: 0.007738547, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.000387304, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.011347245, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.006511221, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002813250, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.006251557, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.004678749, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002461238, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.010152919, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.005901013, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.003565842, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002501281, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002069047, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.003799444, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.000826426, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.019183647, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.004926024, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.002447773, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.003548894, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.002204143, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.008707244, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.003267691, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.001710149, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002952088, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.000942495, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.005701464, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.009347484, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.008550532, TrainingAccuracy: 99.21875\n",
            "Epoch : 50, Loss: 0.001393005, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.001455922, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.005230587, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.004499912, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002834368, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.004133625, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002785333, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.007755689, TrainingAccuracy: 99.60938\n",
            "Epoch : 50, Loss: 0.003408529, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.007658567, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.002580319, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.015842874, TrainingAccuracy: 100.00000\n",
            "Epoch : 50, Loss: 0.027216971, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.004633943, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.001648843, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.007917397, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.012495399, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.001886150, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.003200904, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.004148740, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.046085916, TrainingAccuracy: 98.82812\n",
            "Epoch : 60, Loss: 0.003767129, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.007240947, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.009067465, TrainingAccuracy: 99.21875\n",
            "Epoch : 60, Loss: 0.006525382, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.004320718, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.013355661, TrainingAccuracy: 99.21875\n",
            "Epoch : 60, Loss: 0.015516080, TrainingAccuracy: 99.21875\n",
            "Epoch : 60, Loss: 0.029073771, TrainingAccuracy: 98.82812\n",
            "Epoch : 60, Loss: 0.011019098, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.021543963, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.026976490, TrainingAccuracy: 99.21875\n",
            "Epoch : 60, Loss: 0.013327060, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.019834196, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.015765358, TrainingAccuracy: 99.21875\n",
            "Epoch : 60, Loss: 0.007960696, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.006454954, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.004434621, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.003373584, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.013352927, TrainingAccuracy: 98.82812\n",
            "Epoch : 60, Loss: 0.009594891, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.009604454, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.004861340, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.012627736, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.003264703, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.001865499, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.009303804, TrainingAccuracy: 99.21875\n",
            "Epoch : 60, Loss: 0.026194252, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.010803578, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.009259874, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.023297049, TrainingAccuracy: 99.21875\n",
            "Epoch : 60, Loss: 0.009125751, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.005194455, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.001704358, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.010790605, TrainingAccuracy: 99.21875\n",
            "Epoch : 60, Loss: 0.006528400, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.002807204, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.005411770, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.001448996, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.002445787, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.010715593, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.004033338, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.002239497, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.006956104, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.001064796, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.009175673, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.001795460, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.006627198, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.002618968, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.008442342, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.002165981, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.005073432, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.010129780, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.003716167, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.004534027, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.013880121, TrainingAccuracy: 99.21875\n",
            "Epoch : 60, Loss: 0.003955035, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.018611107, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.027088298, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.006682593, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.005605849, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.002719365, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.001958007, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.005813319, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.003492050, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.008761954, TrainingAccuracy: 99.21875\n",
            "Epoch : 60, Loss: 0.003212299, TrainingAccuracy: 99.21875\n",
            "Epoch : 60, Loss: 0.004569707, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.001663953, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.001748264, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.007933529, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.005058574, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.011445578, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.008610236, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.001435850, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.000863701, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.018509787, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.011340961, TrainingAccuracy: 99.21875\n",
            "Epoch : 60, Loss: 0.001845282, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.001601968, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.003441349, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.001142830, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.010134041, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.003492290, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.001590066, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.004077118, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.002501734, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.003402829, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.016212519, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.010526732, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.003912495, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.005577173, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.006332092, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.002213061, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.017348709, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.003423501, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.003320226, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.002182320, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.002773304, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.011737771, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.002752122, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.001464143, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.003547736, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.008673925, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.008168366, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.008355243, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.001091145, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.006755771, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.001382817, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.005307226, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.003725283, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.004196435, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.003148843, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.005167942, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.012679197, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.003482673, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.001607813, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.001657538, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.006285533, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.012725133, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.000576196, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.003416080, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.002602788, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.002058513, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.006206047, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.006212577, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.016780604, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.003289318, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.003330812, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.010068323, TrainingAccuracy: 99.21875\n",
            "Epoch : 60, Loss: 0.007414803, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.001953458, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.004853643, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.021165689, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.011196092, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.009787180, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.000706531, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.011787172, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.002938613, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.001022454, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.007476224, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.005287785, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.017044585, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.000974521, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.008081540, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.006940743, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.004152764, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.007979829, TrainingAccuracy: 99.21875\n",
            "Epoch : 60, Loss: 0.000571433, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.003479969, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.002248742, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.002447207, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.002676070, TrainingAccuracy: 99.60938\n",
            "Epoch : 60, Loss: 0.007090347, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.006580921, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.006367650, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.002932776, TrainingAccuracy: 100.00000\n",
            "Epoch : 60, Loss: 0.000953496, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000872236, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000989422, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001883864, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.008045960, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.005942134, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001080327, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001267087, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003394812, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000922700, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001699815, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003775042, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.001586271, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.002345625, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003245594, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001642771, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001230970, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001421127, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003256291, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.003269102, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.002375003, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001144368, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001775723, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000373218, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001067575, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003189333, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.006399188, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.002954990, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.004803650, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.001132144, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.004981050, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.010603961, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.001902413, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.000936374, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.002670446, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.001352657, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.011591017, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001446005, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.014000949, TrainingAccuracy: 99.21875\n",
            "Epoch : 70, Loss: 0.002167661, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.009614233, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.001442418, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001131825, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.006618671, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001742490, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000910293, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.006924866, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.006789763, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003846750, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000781842, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.000711896, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.002360154, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.006569609, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001085259, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001277033, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.002385683, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003309879, TrainingAccuracy: 99.21875\n",
            "Epoch : 70, Loss: 0.001127888, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001619466, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.002313495, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000556417, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.001230046, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.002271466, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001527023, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.002127608, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000443522, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.004232716, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000777416, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001966681, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.002870664, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.011573460, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.008935057, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001237821, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.012619512, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003154356, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003168903, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001702368, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003475117, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000351824, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001539588, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003941000, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003201501, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000965193, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001046324, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001290206, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001406930, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.001517689, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003075091, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.011728313, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000851240, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.006929358, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000987183, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003437851, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001539934, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.001443382, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.011678295, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.000606015, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000455994, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001536887, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.009779498, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000497680, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001061965, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.006639134, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003780864, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.008476123, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001648603, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.002251122, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001095735, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001892246, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000229165, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000884831, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.004922479, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.002438713, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.002379496, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000668544, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.005251473, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.000650540, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.010285193, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.001830246, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001170602, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.004296582, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003764642, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000201873, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001561608, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003065228, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.018757904, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000905022, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000650581, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.007864369, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.002859227, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003198467, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000284676, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.002390785, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.002586581, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000473239, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000889484, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000986192, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000829253, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.002125628, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003039382, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001340993, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.000667045, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.006185252, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.005954195, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001133379, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001192950, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001012988, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003269322, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001574451, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.003952000, TrainingAccuracy: 99.21875\n",
            "Epoch : 70, Loss: 0.003938008, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000658689, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001543824, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.002597708, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001165584, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000491455, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000224866, TrainingAccuracy: 99.60938\n",
            "Epoch : 70, Loss: 0.001558319, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.002408218, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.003645752, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001004208, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.010555854, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000535250, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.001493573, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000493832, TrainingAccuracy: 100.00000\n",
            "Epoch : 70, Loss: 0.000842631, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.004611671, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.001158487, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001108890, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.004464768, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001152072, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000875395, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.007151883, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.003201604, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.000161603, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000511393, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.002482023, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.005231643, TrainingAccuracy: 98.82812\n",
            "Epoch : 80, Loss: 0.001619466, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.001903920, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000503799, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001294177, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001476943, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.017551407, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000849254, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.003002509, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001775388, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000762563, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000801925, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.000469208, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.003302243, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001066297, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000589341, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000199448, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.019926971, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.002154324, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002767818, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000421975, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000663422, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001614265, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001311729, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.006136995, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.004905228, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.000798270, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.007904157, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.005035173, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000884149, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000456695, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.000768766, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.003412053, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001045693, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.006617945, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000682902, TrainingAccuracy: 99.21875\n",
            "Epoch : 80, Loss: 0.000803676, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.010351449, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001285300, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002751442, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001649030, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000472650, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001820732, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.003447942, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000674576, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.022679785, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.009275481, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.004576515, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000321954, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000785928, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001926728, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002678566, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.001964629, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000438165, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.005240170, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001522575, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002516858, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002414314, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.005739864, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001218494, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.004003296, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000784993, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001290971, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001244150, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.004843503, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.000831231, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.016155440, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.003471449, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000582505, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002686579, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002016004, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001536533, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002078339, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000473205, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002335250, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.003441993, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002347069, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000666473, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000836272, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.007824067, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.003070589, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.004806757, TrainingAccuracy: 99.21875\n",
            "Epoch : 80, Loss: 0.000240970, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002769709, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000266515, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001370689, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.007537279, TrainingAccuracy: 99.21875\n",
            "Epoch : 80, Loss: 0.000396695, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000725001, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.003901647, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.000699136, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001764148, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001926713, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000717025, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000278741, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.001280662, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.003112160, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.004915226, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.006092642, TrainingAccuracy: 99.21875\n",
            "Epoch : 80, Loss: 0.005302120, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002324928, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.003859956, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.003803425, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001356604, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000401963, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000948485, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002224747, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.000232946, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000544999, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.004380677, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001214288, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002610624, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002083894, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.000908587, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.002889559, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.000441749, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000741571, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000977689, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.000731455, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000627326, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000985090, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001188431, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000113212, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000428457, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001100574, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001801632, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001063697, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001794424, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.002205525, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001384541, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001621358, TrainingAccuracy: 99.21875\n",
            "Epoch : 80, Loss: 0.000770453, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001819499, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001662709, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002002403, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000928771, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002474453, TrainingAccuracy: 99.60938\n",
            "Epoch : 80, Loss: 0.002522532, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000306636, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000408046, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001957588, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.005312636, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000803508, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000294935, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.004599802, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001135167, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002071425, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.002308395, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001477432, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.003569055, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000471711, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.001850773, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.000289936, TrainingAccuracy: 100.00000\n",
            "Epoch : 80, Loss: 0.062941790, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001461707, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.002874002, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.008285847, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.001099203, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.000766126, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.006500391, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.005864874, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.000831658, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.004107218, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.001604501, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.026210830, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.003113728, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.018009527, TrainingAccuracy: 99.21875\n",
            "Epoch : 90, Loss: 0.016202483, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.008495728, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.013780341, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.008496856, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.003428396, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.020162918, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.038153570, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.004431698, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.037729949, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.015281100, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.015855970, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.025254533, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.020738371, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.016875828, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.006416839, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.004102383, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.007250650, TrainingAccuracy: 99.21875\n",
            "Epoch : 90, Loss: 0.013795912, TrainingAccuracy: 99.21875\n",
            "Epoch : 90, Loss: 0.001675854, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.008204233, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.022071846, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.004352693, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.000550997, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.005919332, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.008294471, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.021298423, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.001226615, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.002092076, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001596835, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001732724, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.013391277, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.002387337, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.013402583, TrainingAccuracy: 99.21875\n",
            "Epoch : 90, Loss: 0.011716448, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.000862313, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.011887098, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001208395, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.007780420, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.003929753, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.001785245, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.001225486, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.004767545, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001579938, TrainingAccuracy: 99.21875\n",
            "Epoch : 90, Loss: 0.009893192, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.031699471, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.002074961, TrainingAccuracy: 99.21875\n",
            "Epoch : 90, Loss: 0.002145566, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.000901651, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.011485621, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.007113187, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.008597275, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001925662, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.003845887, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.001749951, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.006948456, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.008681506, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.003656507, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.002293680, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.001933523, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001446228, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.002289968, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001548942, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.004159248, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.006653568, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.010339539, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.001172543, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.001165017, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.003160553, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.004954468, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001215382, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.001095518, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.002033152, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.004665423, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.000427600, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001458500, TrainingAccuracy: 99.21875\n",
            "Epoch : 90, Loss: 0.004873596, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.007343230, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.003363781, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.010389214, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.002375133, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.009403612, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.001482729, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.000739476, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.019083219, TrainingAccuracy: 98.82812\n",
            "Epoch : 90, Loss: 0.001452126, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.008032504, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.002578944, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.000850532, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.001114070, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.017398754, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.002035448, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.014998315, TrainingAccuracy: 99.21875\n",
            "Epoch : 90, Loss: 0.004439034, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.006023977, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.002133425, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.005046457, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001519602, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001606904, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.002559405, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.001222882, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.002278365, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.000606637, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.008457376, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.000907116, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.002267975, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.006974908, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.012225073, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.004145781, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.005366651, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.000739194, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001535773, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.002446963, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.012616642, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001785366, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.001528025, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.002965126, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.004025104, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.011649526, TrainingAccuracy: 99.21875\n",
            "Epoch : 90, Loss: 0.008080423, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.000331771, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.002568718, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.002257284, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001218770, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001934376, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.014195183, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.000872117, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.013681207, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.006151678, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.002611708, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.000854336, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.002592519, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.014531607, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.001801018, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001488037, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.003580920, TrainingAccuracy: 99.21875\n",
            "Epoch : 90, Loss: 0.001916019, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.002462685, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001685664, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.000722796, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.002781400, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.006563634, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.001405738, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.001089960, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.004435388, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.004379239, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.003923096, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.000531785, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.004180841, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.002436873, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 0.008734852, TrainingAccuracy: 99.60938\n",
            "Epoch : 90, Loss: 0.009718908, TrainingAccuracy: 100.00000\n",
            "Epoch : 90, Loss: 1.047622085, TrainingAccuracy: 93.75000\n",
            "Epoch : 100, Loss: 0.000641450, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.003287908, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000902817, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002586287, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000414975, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001861040, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000629898, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002441294, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002841791, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.000373155, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.003428856, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001768142, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.005904602, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.022594480, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002920367, TrainingAccuracy: 99.21875\n",
            "Epoch : 100, Loss: 0.001173452, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.010432027, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002057545, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.008503765, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002379999, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002198406, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.004455658, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001637772, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.004011970, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000321351, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.005696844, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000566628, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.005037028, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000488017, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001826603, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001598246, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.003926100, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.008098565, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.005202666, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000431739, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.007616160, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000486692, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000685055, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000792719, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002289869, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001701728, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001142958, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002984028, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.003086269, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000317026, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.003103079, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002580220, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001767464, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000716895, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001884788, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000459071, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000953585, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000989532, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001655601, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.004795251, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.018545099, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.005507477, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.001900699, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000351980, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000659525, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001603030, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.005433373, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001160406, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001747172, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000257090, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.011020176, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000477966, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002481643, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.006772522, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.001313586, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002608754, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000642844, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.000967070, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001892395, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000293631, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.004987542, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001253698, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.000826173, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001988873, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.007045601, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.016240735, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.002911545, TrainingAccuracy: 99.21875\n",
            "Epoch : 100, Loss: 0.007701833, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.005642645, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.003020950, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000580952, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.005694963, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001568222, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001305170, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002241572, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001369879, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001707532, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000921156, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000690179, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.003290422, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.001114253, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001442827, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000841230, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000741564, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002702866, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002133239, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001227306, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000794113, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001045905, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.003231995, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002006974, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.000383604, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.003517333, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.005268747, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.001744743, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.000610070, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002279524, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000756295, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002065351, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000226382, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.002077699, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.003454532, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000501323, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.004123453, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.005129842, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.007734705, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.003338566, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.000226486, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002640285, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000972003, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000478685, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.000555787, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.001244087, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000865931, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001873510, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000592638, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000932515, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.005155906, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001512339, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.002856266, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000220943, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000432752, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000780165, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000268707, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000606291, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.000908030, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000753790, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.003110863, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000782281, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000797588, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001229253, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000457965, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000469528, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001365181, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.003212929, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000457982, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.007350344, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.007100329, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.001777118, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000790033, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.006368564, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.003362482, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.004214261, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.003027525, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.004684851, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002641201, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.000231743, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.000995871, TrainingAccuracy: 100.00000\n",
            "Epoch : 100, Loss: 0.002474433, TrainingAccuracy: 99.60938\n",
            "Epoch : 100, Loss: 0.541043341, TrainingAccuracy: 93.75000\n",
            "Epoch : 110, Loss: 0.002270183, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000785187, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001054576, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000760324, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000353239, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001607670, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001768675, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.000359112, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000555616, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.002580615, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.002144251, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.009286541, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000394527, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000263743, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.005595017, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.002399171, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.000950191, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.002585256, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.003569627, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000217382, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.003790546, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000339683, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000513345, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000891013, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000851743, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000291867, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.000200873, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001091463, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000252157, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001441751, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.003041569, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000719078, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001011757, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.004585616, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.000216957, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000229452, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.003689233, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.002630137, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000381287, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001646623, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001289347, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.001219284, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.002903767, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.002453614, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001120307, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000311799, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.003641073, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.000308316, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000904398, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000991156, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001604430, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001602849, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000851223, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000356466, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.003754310, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000841707, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000337340, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000466697, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.002634056, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.003105843, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.008150341, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000705870, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000783924, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001122050, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.004334671, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.002841834, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.003118627, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.011102205, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000747178, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000702325, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.001097780, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000331033, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000664445, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.002788782, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001982290, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.002220549, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000940520, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000438623, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.002652362, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.001729248, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.002922710, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000540797, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000368778, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.003123730, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000125501, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001564823, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.000246283, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000877049, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000945341, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001664041, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.000439376, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.005726252, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001270879, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000440270, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.006822130, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001375038, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000972439, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.003837412, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.005115576, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.000954337, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001219202, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.007298864, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.006510453, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000420615, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.004669294, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000399172, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000471679, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.010351911, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000748385, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.006298069, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001234083, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001696642, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000580775, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000846023, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000609979, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000913173, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000762232, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001564227, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001572870, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000967894, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.004499137, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001976348, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.006104417, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000454679, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.007885961, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000526760, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000979243, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001778185, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000597641, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.001019936, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001659159, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.010410296, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000432413, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000441663, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.003160257, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000415988, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000498828, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000231899, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001684844, TrainingAccuracy: 99.21875\n",
            "Epoch : 110, Loss: 0.001799211, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.011328967, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.002510069, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.003420688, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000402577, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.003560048, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001648478, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001838595, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000761699, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001492906, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001318248, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001242571, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000259370, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001165725, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.003517047, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.005336102, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000790782, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001166597, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001116805, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.001621904, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000805713, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.004756361, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.001202643, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.000223342, TrainingAccuracy: 99.60938\n",
            "Epoch : 110, Loss: 0.003016364, TrainingAccuracy: 100.00000\n",
            "Epoch : 110, Loss: 0.012741089, TrainingAccuracy: 93.75000\n",
            "Epoch : 120, Loss: 0.002339169, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001854680, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.001139164, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.002212074, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000567921, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.002383970, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.005313639, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.000880163, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001430949, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000382815, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000822354, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.002155511, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000325397, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.020503866, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000403365, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000603069, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.001887098, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.006717749, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.002095941, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000474408, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001718935, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000477128, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000260971, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001825599, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.002710771, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000670269, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.003638245, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.006135188, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001250446, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000438865, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.002218856, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001355121, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000794694, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.005216230, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.001196353, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000529448, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001666782, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.005878825, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000819642, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000249702, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.008106116, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001298692, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001904830, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.010029322, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001322711, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.004660780, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.007521415, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000706594, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.010107515, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000701062, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.000795955, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.006367873, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001037177, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000353020, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000738889, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.000790704, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001700675, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.003818545, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001235250, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.000389770, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000754472, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.002110951, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.002147615, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.002753422, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.002959169, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000342596, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001000777, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000704106, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000902457, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000611216, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000740524, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.002141384, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001072340, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000845585, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000698764, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.004771762, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.002512058, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.002466278, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000536181, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.003358229, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000572698, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001655538, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.005804649, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001693692, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.003958389, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000176243, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.002885163, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000308648, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000215231, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000441983, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000757094, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000526257, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000415770, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.000398275, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.003068645, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001637978, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001779120, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001776375, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000563476, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000449818, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001329383, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000654750, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.006593827, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001965998, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001128746, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000530761, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.000271849, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000539511, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000567399, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001702005, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001059689, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.000234624, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001934402, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.003854292, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000317242, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000853498, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.000242122, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000426836, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001264058, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.004003795, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001596007, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.008541629, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.002557926, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.004628427, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.000291962, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000444848, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.004011668, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001238395, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.000955120, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000926509, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.010852454, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.008861924, TrainingAccuracy: 99.21875\n",
            "Epoch : 120, Loss: 0.006466905, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001931893, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001069449, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000710156, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.003441248, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.004188258, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.001125360, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.001798037, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.011038754, TrainingAccuracy: 99.60938\n",
            "Epoch : 120, Loss: 0.001120824, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001222633, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001179807, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000679750, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000853941, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000595991, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000995131, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000241980, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000753921, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001332525, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.004365463, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.003320798, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000504225, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000201043, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001252823, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000541683, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.001425328, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000248365, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.002856040, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.000804864, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.002161894, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.002273817, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.017714312, TrainingAccuracy: 100.00000\n",
            "Epoch : 120, Loss: 0.369428933, TrainingAccuracy: 93.75000\n",
            "Epoch : 130, Loss: 0.000801723, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000522941, TrainingAccuracy: 99.60938\n",
            "Epoch : 130, Loss: 0.000080882, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000618376, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.004874427, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.002948787, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000132244, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000174310, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000310782, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000298951, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000388240, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000417911, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.011000548, TrainingAccuracy: 99.60938\n",
            "Epoch : 130, Loss: 0.000371531, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.006671835, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000226196, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000127595, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000117598, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000211928, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000240557, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001182243, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.002396930, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000557926, TrainingAccuracy: 99.60938\n",
            "Epoch : 130, Loss: 0.003008474, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000256788, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000128694, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001630090, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001041915, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001328122, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000151034, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000207651, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000452165, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001586508, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000286529, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001437241, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000711158, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000969116, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.002021216, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.003031569, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.006247181, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000314601, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000497118, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000205360, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000738863, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000571907, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000479383, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000152767, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000196144, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001598727, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000809308, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.006617332, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000586927, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.017573029, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000079595, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000716321, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000117280, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001563504, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000874311, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000482373, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000296811, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000345305, TrainingAccuracy: 99.60938\n",
            "Epoch : 130, Loss: 0.000285922, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000208052, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001346733, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000257753, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000828097, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000241891, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001744937, TrainingAccuracy: 99.60938\n",
            "Epoch : 130, Loss: 0.000351500, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.005785232, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000499032, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000919163, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000228748, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000243301, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000352612, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001533413, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000406638, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000660975, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000456151, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000430249, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.002379429, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.004630500, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.003131265, TrainingAccuracy: 99.60938\n",
            "Epoch : 130, Loss: 0.000124276, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000736464, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000321742, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000339452, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000702567, TrainingAccuracy: 99.60938\n",
            "Epoch : 130, Loss: 0.000478823, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.004051540, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000179492, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.002336076, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.005717926, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000222791, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001415636, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000192925, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000241861, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000044849, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000420425, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001289228, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001354244, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000252951, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000160590, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.002089672, TrainingAccuracy: 99.60938\n",
            "Epoch : 130, Loss: 0.000172343, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000499874, TrainingAccuracy: 99.60938\n",
            "Epoch : 130, Loss: 0.000057541, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000895601, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.002785699, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000411917, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000339545, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000177596, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000173815, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.018675428, TrainingAccuracy: 99.60938\n",
            "Epoch : 130, Loss: 0.000395164, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000202406, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000407394, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000497971, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000125326, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000149589, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000537872, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000948139, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001661822, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001409106, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000240821, TrainingAccuracy: 99.60938\n",
            "Epoch : 130, Loss: 0.003659848, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000044744, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001460932, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001235973, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001592852, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.003510162, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001135141, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000433268, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.005632188, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000491682, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000208654, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.004480582, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000189032, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000045370, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000282215, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001069952, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.002471033, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000357915, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000665333, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000721063, TrainingAccuracy: 99.60938\n",
            "Epoch : 130, Loss: 0.002788719, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000141732, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000314094, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000922009, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000798367, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.002260294, TrainingAccuracy: 99.60938\n",
            "Epoch : 130, Loss: 0.000322238, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000330605, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000844497, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000543546, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000681672, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.011821052, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000091121, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.002611684, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.001407938, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.005512662, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000279196, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000413075, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.000722744, TrainingAccuracy: 100.00000\n",
            "Epoch : 130, Loss: 0.005941510, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000619885, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000372794, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001881294, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.004293397, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.003622480, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.004255593, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000471428, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000304738, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.003931589, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001279188, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000776533, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000964828, TrainingAccuracy: 99.21875\n",
            "Epoch : 140, Loss: 0.000953820, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.002716623, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.000915814, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000304498, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.005495723, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.002126520, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.004422165, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001091860, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000540383, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.002274118, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.002356447, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000864437, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.004418230, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.003315523, TrainingAccuracy: 99.21875\n",
            "Epoch : 140, Loss: 0.002337284, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.005449276, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.008101678, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001207866, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000378080, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.009582460, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.001691993, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.007167872, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000579901, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.001268206, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.002048757, TrainingAccuracy: 99.21875\n",
            "Epoch : 140, Loss: 0.001815299, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.001892863, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.006581068, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.080504656, TrainingAccuracy: 99.21875\n",
            "Epoch : 140, Loss: 0.000474434, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.008964155, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000668373, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.000969563, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.020614535, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000301769, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.007924031, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.001427617, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.003627636, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.003763236, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.017309541, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.003829943, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.002029535, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.016784189, TrainingAccuracy: 99.21875\n",
            "Epoch : 140, Loss: 0.000666732, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.004769206, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001069520, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.005264305, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.002250262, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.012098465, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001231277, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.002616342, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.001982866, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000897773, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000852995, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.004964905, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.001332216, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000447728, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000778059, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000916492, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.003350746, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.001731159, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.000353780, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001534190, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001364987, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.002780885, TrainingAccuracy: 99.21875\n",
            "Epoch : 140, Loss: 0.024848284, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001700219, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.014193907, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000505764, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.002444342, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000270549, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.007581601, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.002324503, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000836879, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000760555, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000087917, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.022360776, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.011164926, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000736570, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.003616203, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.004519831, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000885565, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.000707675, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000431469, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.005386233, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.000415638, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.005180459, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.005556755, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.000342969, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000913616, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.002007775, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.001792308, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.027295846, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.000323378, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000625461, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000421870, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000248965, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000193663, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.017524781, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000220563, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000488959, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000562906, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000216082, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.007442340, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.005853815, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000454631, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.005333550, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.003504384, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.005871287, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.000667907, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001167225, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.003563803, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.000346694, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.003186593, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.009589892, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000244396, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.005982745, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.002555151, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000423983, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.000355691, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000430323, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.002443571, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.007609595, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.000412893, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000331108, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001092408, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000388086, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001946330, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.002322029, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001972292, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001114029, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.003104344, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000855263, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000391260, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000392711, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.008323085, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001841290, TrainingAccuracy: 99.21875\n",
            "Epoch : 140, Loss: 0.000166396, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001238637, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.000654204, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.001867533, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.003751583, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.007936467, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.003445882, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.003312089, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.002108397, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000413701, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.010601955, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.003256392, TrainingAccuracy: 99.60938\n",
            "Epoch : 140, Loss: 0.004319862, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000477046, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.000390466, TrainingAccuracy: 100.00000\n",
            "Epoch : 140, Loss: 0.049166679, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000658777, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001478665, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000377644, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000698661, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000765014, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.002042856, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000431733, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001281718, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.004933290, TrainingAccuracy: 99.60938\n",
            "Epoch : 150, Loss: 0.003585245, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000235606, TrainingAccuracy: 99.60938\n",
            "Epoch : 150, Loss: 0.001047179, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000483811, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001663391, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000186138, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000200646, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.004476646, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.002033416, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000313587, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000048336, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000331704, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001930602, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.002458589, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000198215, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000392597, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001243072, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000614725, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000116929, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.002642039, TrainingAccuracy: 99.60938\n",
            "Epoch : 150, Loss: 0.001702858, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001635633, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000135593, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001072858, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.002829205, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000270573, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000401923, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000524562, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000212513, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000448000, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001545765, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000152193, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000201184, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000570707, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000222370, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000918077, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000802137, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000229597, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000721738, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001030823, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000428870, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000607010, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.003507042, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000101220, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000119992, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000112541, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000227420, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000253860, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000110077, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000334881, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.002601780, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000131648, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000376549, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000133108, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000293082, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000736132, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000075649, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000300445, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000672556, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000244312, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.006353322, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001049442, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000211895, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001213713, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000082331, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000109877, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001358081, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000357136, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000175394, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000229064, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000070088, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000215959, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000364762, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000347935, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000154693, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000953447, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000373326, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001835322, TrainingAccuracy: 99.60938\n",
            "Epoch : 150, Loss: 0.000283729, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000159737, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000594102, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000273827, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000227828, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001179388, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000232032, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000908948, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000125455, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000636600, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.006479688, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000312325, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000348290, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.003981337, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000135016, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000054596, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000639495, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000550058, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000092205, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.007778544, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001359794, TrainingAccuracy: 99.60938\n",
            "Epoch : 150, Loss: 0.000237182, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.002249584, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000100646, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000332516, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000161693, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000458911, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000284240, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000081133, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000645738, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.004293069, TrainingAccuracy: 99.60938\n",
            "Epoch : 150, Loss: 0.000423014, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001366440, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.006236413, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000139348, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000114236, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000754204, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000412941, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000682263, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000358865, TrainingAccuracy: 99.60938\n",
            "Epoch : 150, Loss: 0.000167608, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000896510, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000539113, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000271522, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000063092, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001186498, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000341043, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000583321, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000762222, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000200676, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000261117, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.003716880, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.004433554, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000443917, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001200171, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000483712, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000058658, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000162264, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000118703, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000208149, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000155892, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.002353951, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000092272, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001210297, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000219919, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000895606, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000788793, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001090147, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000083134, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.003745273, TrainingAccuracy: 99.60938\n",
            "Epoch : 150, Loss: 0.003832275, TrainingAccuracy: 99.60938\n",
            "Epoch : 150, Loss: 0.000120293, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.001983987, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.003263934, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000451244, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000244632, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000156928, TrainingAccuracy: 100.00000\n",
            "Epoch : 150, Loss: 0.000351906, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.002139190, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000256192, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000142682, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001263449, TrainingAccuracy: 99.60938\n",
            "Epoch : 160, Loss: 0.000343258, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000099981, TrainingAccuracy: 99.21875\n",
            "Epoch : 160, Loss: 0.000466291, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001360333, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000223298, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000375889, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001344537, TrainingAccuracy: 99.60938\n",
            "Epoch : 160, Loss: 0.000799276, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000215398, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000356875, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.006445356, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000265066, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000161879, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000294037, TrainingAccuracy: 99.60938\n",
            "Epoch : 160, Loss: 0.000367181, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000406664, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000246508, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000542700, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000364482, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000508996, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000077613, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000603616, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001153428, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.002391167, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000515508, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000357568, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000763778, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000169521, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000651514, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000159066, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.002018664, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000193294, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.002364080, TrainingAccuracy: 99.60938\n",
            "Epoch : 160, Loss: 0.000268886, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.002067391, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000189129, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000209853, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001583902, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.008888334, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000113584, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001573533, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000893753, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000493301, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000254352, TrainingAccuracy: 99.60938\n",
            "Epoch : 160, Loss: 0.001017025, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000278201, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000454053, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001383433, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000215579, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000158187, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000575604, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000308186, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000217784, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.003176464, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000470819, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000277750, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.008805525, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.007143170, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000919487, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.003814155, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001050327, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001428332, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000128362, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000139095, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000230756, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.003985956, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000423595, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000684757, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000533096, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000735858, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001748754, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000048835, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.005393492, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.011151742, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000684034, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000103945, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000464709, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.003687350, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000197556, TrainingAccuracy: 99.60938\n",
            "Epoch : 160, Loss: 0.000329383, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000275590, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000133514, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.003133262, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000184281, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.003038926, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000384154, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000525555, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000199202, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000244074, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001433518, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000380382, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000310298, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000171620, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000255957, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000423348, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000569697, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000289325, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.013940359, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.004572038, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000719516, TrainingAccuracy: 99.60938\n",
            "Epoch : 160, Loss: 0.000256406, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000054326, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000297323, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000072431, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000277583, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000371154, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.003056185, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000123203, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000379691, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000468541, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001660593, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000167578, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001996458, TrainingAccuracy: 99.60938\n",
            "Epoch : 160, Loss: 0.000840135, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001881529, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000207892, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001084728, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001630966, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001067646, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000129707, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.002154581, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001458745, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.003682937, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001135327, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000422280, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000676364, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001265572, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000303997, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000361532, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000616878, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001077145, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.003960675, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000512645, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000851445, TrainingAccuracy: 99.60938\n",
            "Epoch : 160, Loss: 0.000830343, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.002241556, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001163609, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000825286, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.002772931, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001940440, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000127992, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000812318, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000564851, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000179298, TrainingAccuracy: 99.60938\n",
            "Epoch : 160, Loss: 0.000147067, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001052453, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000694320, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000579683, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000104466, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.002987225, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.004203059, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000185806, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.001738317, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000201676, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000326745, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000289463, TrainingAccuracy: 99.60938\n",
            "Epoch : 160, Loss: 0.000769790, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000556864, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000463586, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.000063315, TrainingAccuracy: 100.00000\n",
            "Epoch : 160, Loss: 0.025798678, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.006970558, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000085641, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000633270, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000390727, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.000960287, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000580216, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.004576389, TrainingAccuracy: 99.21875\n",
            "Epoch : 170, Loss: 0.007071549, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.006295128, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.006715581, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.009501522, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.028410543, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.003263960, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.003383048, TrainingAccuracy: 98.82812\n",
            "Epoch : 170, Loss: 0.001176435, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.017760128, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.008461250, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000723844, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.015559973, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.001114161, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001372864, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.011453960, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.001214663, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.003731504, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.003467653, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001415355, TrainingAccuracy: 99.21875\n",
            "Epoch : 170, Loss: 0.006425260, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.026467528, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.011408824, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.011402447, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.020386625, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.000364114, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000222368, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.030204527, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.002398996, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000520442, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000557013, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.010311419, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.001057867, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.023930211, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001244277, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001995858, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.000503084, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001491586, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000775596, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.002937503, TrainingAccuracy: 99.21875\n",
            "Epoch : 170, Loss: 0.005267074, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.004305793, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001272015, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.003397305, TrainingAccuracy: 99.21875\n",
            "Epoch : 170, Loss: 0.028805219, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.003023878, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.008467192, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001826331, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000204150, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.002934968, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.000657305, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.002708858, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.011974318, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.013918635, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000218865, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.003755484, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.000715658, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001162130, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.002413040, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000504144, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.003396822, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.004294895, TrainingAccuracy: 99.21875\n",
            "Epoch : 170, Loss: 0.000898955, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.005660981, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000870179, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000378722, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.010228584, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001675406, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.001455344, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.012938896, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.002521243, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000553146, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000919940, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.002136751, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000175800, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000282742, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.007942418, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000465456, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.004586179, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000307441, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000585768, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.011266945, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.002872638, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001052648, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.023849510, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.003066037, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.004536526, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000511512, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.004685396, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000394952, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.002540857, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000105502, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000512546, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000357654, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.001453295, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.002274904, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001516920, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.004241716, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000516420, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.003181001, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.002009798, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.005665651, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001670700, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001036387, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000797000, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001300612, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.000292670, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000337116, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000797898, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.003647281, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000334188, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001982370, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000389554, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000171803, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000937100, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000186648, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001216032, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000058070, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000260258, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000041053, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000267535, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.005070761, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.004620330, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.002294157, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001363656, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000119187, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000928417, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000271065, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000344250, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001143042, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.003865726, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000175722, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.010151641, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.001759188, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001563434, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001506042, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.002606893, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000044506, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001741083, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.001511263, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000470333, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001824349, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000412820, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.000347868, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001590412, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000050012, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000737920, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000836857, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.003162384, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.002115067, TrainingAccuracy: 99.60938\n",
            "Epoch : 170, Loss: 0.001144711, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001228645, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.002401410, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000154201, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.001246242, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000752177, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000589896, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.000716753, TrainingAccuracy: 100.00000\n",
            "Epoch : 170, Loss: 0.195887029, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000178874, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000220466, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000083789, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.001262220, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000164071, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000354342, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000166971, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000451159, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000133991, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000119058, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000340670, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000172939, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000387842, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000120960, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.005351549, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.002108075, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000194103, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000072096, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000385333, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000267534, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000361154, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000213699, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000322551, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000532290, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000213411, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000182223, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.005615251, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000067174, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000173751, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000036269, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000078682, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000382446, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000216536, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000785807, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000945702, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.001021590, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.004800841, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000830095, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000340432, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000105329, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000202939, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000109872, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000334386, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.004719846, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000160564, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000046782, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.006257527, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000378869, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000958975, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000122461, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000300083, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000185363, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.001064699, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000248626, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000320002, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000441339, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000133339, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000717144, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000077888, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000568058, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000176184, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000416122, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000288958, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.002715169, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000294115, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000240693, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000485532, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000305865, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.001429151, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000474591, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000279102, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000820480, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.002994679, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000127822, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000303313, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000089373, TrainingAccuracy: 99.60938\n",
            "Epoch : 180, Loss: 0.000113171, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.003999010, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000196960, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000319242, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000173600, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000856357, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000102114, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000428382, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000235410, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000843860, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000093604, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000445822, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000178061, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000594048, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.003551165, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000921393, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000462675, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000334173, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000851089, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000136364, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000095550, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.003143877, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.008352503, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000377093, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000709096, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000133600, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000234362, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000170240, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000137027, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000230204, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000089813, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.001166277, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000132874, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000364952, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.012442105, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000324754, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000852335, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000085387, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000581175, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.002223074, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000088882, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000118837, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000168055, TrainingAccuracy: 99.60938\n",
            "Epoch : 180, Loss: 0.000055779, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000093104, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.004636291, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000218879, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000343310, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000329774, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000189917, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000120621, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000203423, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.001720292, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000091204, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000151332, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000070196, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000074858, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000347763, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000707021, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000886159, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000078134, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000066683, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000190001, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.001011513, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000113290, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.001948513, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000201935, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.001407173, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000068376, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000214927, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000756122, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000149157, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000161981, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000881661, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000157211, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000187408, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000140153, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000232648, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000267899, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000979427, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000471592, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000255547, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000420593, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000066116, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.001097362, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000170190, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.000115480, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.004740614, TrainingAccuracy: 100.00000\n",
            "Epoch : 180, Loss: 0.007901639, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000028580, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.002324786, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000219334, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.010129130, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000336889, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000633132, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000356678, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000512905, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000314303, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.007535517, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.036826104, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.002021566, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.013102848, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000923473, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000270020, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.001225993, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.002153840, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.023591604, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.004757490, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000341751, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.004838526, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.007049905, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.025763249, TrainingAccuracy: 99.21875\n",
            "Epoch : 190, Loss: 0.002841560, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000382412, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.002864916, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000268690, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000546707, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.001715416, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000191282, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.007080181, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000121377, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000248797, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000099581, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.004105388, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000229355, TrainingAccuracy: 99.21875\n",
            "Epoch : 190, Loss: 0.000314193, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000308894, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000308400, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.001056302, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.003180813, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000319296, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000596074, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.008557463, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.000943538, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000087377, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000312250, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.001013134, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.020123463, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.017601602, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000341911, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.006091423, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.008554542, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.004213771, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000340426, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000492226, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000166435, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000304855, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000657044, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.000741683, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.006134672, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000176564, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.012106596, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000542227, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000239844, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000017468, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.001681885, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.002082922, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.002499778, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.003236134, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.002001820, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.003502611, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000262737, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000063932, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000180120, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.004612230, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.007319950, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.006206924, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.003034834, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.003051292, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.002979359, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000114059, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000341602, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.001119111, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000571305, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.006704170, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.002720119, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.001120647, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000198167, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.026543923, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.000565859, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.001056816, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000346964, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.003952459, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.002410585, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.004869107, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000924211, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.001488401, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.000153206, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.002488662, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000523789, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000074182, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.001080859, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.005163517, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000422727, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000635156, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000376161, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.004023276, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000901090, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000486862, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000159293, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.004190616, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000849755, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000203609, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000223823, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000178974, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000180416, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.003917566, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000370584, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000327088, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000055145, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000379119, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.001109717, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000626113, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000065925, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000745615, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000117470, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.003515530, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000422746, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000185173, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.004565554, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.002926988, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.002384372, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000278369, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.001516581, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.003807608, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000576530, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.000945218, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000612762, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000310916, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.001720181, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.001426142, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000053670, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.001066785, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000027265, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000412077, TrainingAccuracy: 99.60938\n",
            "Epoch : 190, Loss: 0.000561111, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000313012, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000268526, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000084493, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000778643, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000693604, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000484552, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000160983, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000205349, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.003260387, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000056792, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000089761, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000401396, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000812492, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000404242, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000352815, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.001391768, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000715170, TrainingAccuracy: 100.00000\n",
            "Epoch : 190, Loss: 0.000353813, TrainingAccuracy: 100.00000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-2a5a9040bd69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# print(_t)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mb_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mb_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mb_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HEXXtAxke1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtest = test_data.values.astype('float32')\n",
        "# print(Xtest.shape)\n",
        "testingX = torch.Tensor(Xtest)/255.\n",
        "# testingX = testingX.view(-1,1,28,28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5sW4EGnDEOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predictions = cnn(testingX.cuda())[0]\n",
        "# elems = torch.max(predictions,1)[1].data.squeeze()\n",
        "# print(elems)\n",
        "test_loader = Data.DataLoader(dataset=testingX, batch_size=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMdoWQhYaMGL",
        "colab_type": "code",
        "outputId": "bd524256-a7fd-4f78-e729-7ae3c6849ad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "yopred = []\n",
        "for i in range(1):\n",
        "  for _x in test_loader:\n",
        "    b_x = Variable(_x)\n",
        "    b_x = b_x.view(-1,1,28,28)\n",
        "    output = cnn(b_x.cuda())[0]\n",
        "    elems = torch.max(output,1)[1].data.squeeze()\n",
        "    print(elems.tolist())\n",
        "    yopred.extend(elems.tolist())\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 0, 9, 9, 3, 7, 0, 3, 0, 3, 5, 7, 4, 0, 4, 3, 3, 1, 9, 0, 9, 1, 1, 5, 7, 4, 2, 7, 4, 7, 7, 5, 4, 2, 6, 2, 5, 5, 1, 6, 7, 7, 4, 9, 8, 7, 8, 2, 6, 7, 6, 8, 8, 3, 8, 2, 1, 2, 2, 9, 4, 1, 7, 0, 0, 0, 1, 9, 0, 1, 6, 5, 8, 8, 2, 8, 9, 9, 2, 3, 5, 4, 1, 0, 9, 2, 4, 3, 6, 7, 2, 0, 6, 6, 1, 4, 3, 9, 7, 4, 0, 9, 2, 0, 7, 3, 0, 5, 0, 8, 0, 0, 4, 7, 1, 7, 1, 1, 3, 3, 3, 7, 2, 8, 6, 3, 8, 7, 8, 4, 3, 5, 6, 0, 0, 0, 3, 1, 3, 6, 4, 3, 4, 5, 5, 8, 7, 7, 2, 8, 4, 3, 5, 6, 5, 3, 7, 5, 7, 8, 3, 0, 4, 5, 1, 2, 7, 6, 3, 0, 2, 7, 8, 6, 1, 3, 7, 4, 1, 2, 4, 8, 5, 2, 4, 9, 2, 1, 6, 0, 6, 1, 4, 9, 6, 0, 9, 7, 6, 9, 1, 9, 0, 9, 9, 0, 8, 4, 6, 2, 0, 9, 3, 6, 3, 2, 1, 6, 3, 4, 2, 3, 1, 2, 2, 0, 4, 6, 1, 0, 0, 4, 9, 1, 7, 3, 2, 3, 8, 6, 8, 6, 2, 8, 5, 5, 4, 8, 3, 5, 9, 7, 1, 3, 8, 4]\n",
            "[5, 1, 4, 5, 6, 3, 3, 5, 7, 0, 6, 8, 3, 1, 6, 0, 6, 3, 9, 5, 1, 5, 8, 4, 0, 9, 2, 0, 5, 3, 7, 1, 9, 9, 5, 7, 7, 9, 9, 6, 3, 0, 3, 3, 6, 9, 8, 2, 6, 3, 7, 1, 4, 5, 8, 5, 9, 0, 0, 3, 8, 4, 1, 8, 4, 1, 1, 9, 8, 4, 5, 1, 5, 3, 6, 3, 1, 3, 0, 9, 0, 0, 6, 0, 6, 3, 1, 8, 6, 0, 6, 5, 2, 2, 6, 7, 7, 2, 5, 8, 3, 9, 2, 7, 8, 6, 3, 8, 4, 2, 3, 8, 1, 6, 4, 8, 7, 9, 7, 6, 9, 5, 3, 7, 6, 5, 5, 4, 2, 6, 2, 1, 3, 7, 1, 7, 9, 9, 6, 1, 1, 1, 7, 3, 9, 7, 6, 1, 1, 1, 9, 3, 8, 5, 5, 0, 4, 1, 2, 3, 1, 1, 3, 5, 9, 6, 6, 5, 3, 1, 4, 7, 4, 7, 4, 8, 5, 2, 6, 1, 3, 9, 5, 0, 8, 4, 7, 4, 4, 4, 1, 5, 3, 9, 5, 7, 6, 9, 5, 9, 2, 3, 5, 6, 6, 7, 5, 0, 5, 1, 7, 4, 4, 1, 1, 4, 9, 5, 6, 0, 1, 3, 1, 0, 4, 8, 1, 2, 7, 9, 4, 8, 3, 7, 7, 4, 2, 4, 6, 7, 6, 3, 2, 0, 6, 5, 9, 4, 1, 8, 3, 3, 0, 2, 7, 5]\n",
            "[8, 7, 5, 3, 5, 7, 4, 3, 6, 9, 0, 7, 7, 1, 0, 1, 1, 7, 0, 5, 3, 8, 3, 5, 6, 5, 7, 3, 0, 2, 8, 2, 0, 3, 0, 9, 2, 1, 1, 3, 0, 5, 0, 0, 7, 5, 6, 2, 0, 3, 8, 1, 6, 5, 4, 1, 1, 4, 6, 5, 3, 6, 0, 4, 8, 2, 4, 2, 5, 1, 7, 6, 9, 1, 7, 3, 8, 0, 8, 8, 4, 5, 3, 6, 6, 6, 0, 3, 5, 1, 7, 1, 6, 2, 8, 5, 6, 4, 7, 4, 3, 3, 2, 4, 7, 0, 0, 9, 8, 5, 9, 4, 0, 8, 8, 5, 6, 2, 6, 1, 8, 6, 1, 4, 7, 7, 8, 3, 0, 9, 9, 6, 7, 2, 4, 8, 1, 8, 4, 8, 0, 2, 8, 2, 4, 3, 3, 7, 2, 3, 4, 0, 4, 8, 1, 3, 3, 6, 3, 9, 4, 3, 8, 7, 7, 2, 6, 0, 6, 9, 8, 8, 1, 3, 4, 6, 9, 9, 2, 6, 0, 1, 8, 4, 3, 9, 8, 8, 4, 0, 5, 0, 6, 0, 4, 4, 6, 5, 1, 8, 1, 5, 3, 6, 2, 3, 7, 8, 9, 3, 1, 0, 1, 0, 6, 4, 7, 5, 7, 1, 3, 2, 7, 7, 1, 5, 1, 5, 4, 4, 3, 4, 3, 9, 0, 7, 8, 6, 4, 9, 4, 4, 1, 4, 7, 1, 1, 8, 3, 0, 4, 0, 4, 0, 0, 5]\n",
            "[1, 8, 6, 5, 0, 1, 5, 3, 4, 6, 3, 1, 1, 6, 9, 8, 3, 5, 5, 4, 8, 8, 5, 0, 4, 0, 4, 3, 1, 6, 9, 9, 1, 1, 3, 3, 1, 4, 9, 6, 9, 1, 5, 4, 2, 3, 2, 4, 0, 9, 7, 4, 3, 0, 5, 0, 1, 9, 0, 4, 5, 2, 8, 0, 5, 9, 3, 9, 6, 1, 5, 5, 1, 9, 0, 8, 8, 6, 7, 2, 8, 5, 8, 9, 7, 7, 2, 8, 1, 3, 4, 5, 0, 4, 1, 4, 2, 3, 6, 9, 2, 3, 4, 5, 4, 2, 3, 3, 1, 1, 0, 1, 4, 9, 1, 1, 2, 7, 1, 5, 4, 9, 1, 7, 6, 0, 4, 2, 9, 9, 1, 1, 5, 3, 5, 7, 4, 7, 8, 3, 2, 7, 2, 0, 4, 7, 1, 6, 4, 6, 1, 5, 7, 3, 5, 9, 4, 7, 9, 6, 6, 3, 3, 2, 1, 4, 5, 3, 7, 7, 9, 5, 6, 2, 6, 1, 0, 9, 3, 2, 9, 2, 6, 7, 5, 2, 3, 2, 8, 3, 0, 2, 7, 9, 4, 0, 9, 5, 1, 8, 8, 5, 3, 2, 9, 6, 7, 0, 8, 0, 7, 4, 5, 8, 7, 9, 7, 7, 0, 5, 3, 2, 1, 9, 0, 6, 8, 3, 6, 2, 2, 9, 0, 7, 0, 7, 1, 3, 4, 6, 3, 9, 2, 6, 3, 7, 3, 7, 2, 3, 4, 9, 5, 9, 9, 6]\n",
            "[2, 6, 1, 5, 5, 1, 9, 1, 8, 9, 4, 5, 9, 5, 2, 0, 1, 6, 1, 9, 2, 2, 7, 7, 6, 6, 2, 6, 3, 5, 9, 1, 1, 3, 6, 3, 0, 0, 6, 0, 9, 4, 7, 0, 5, 9, 0, 8, 7, 6, 9, 2, 6, 1, 2, 9, 3, 0, 2, 3, 7, 7, 6, 6, 3, 1, 3, 1, 0, 1, 7, 6, 3, 3, 3, 3, 4, 2, 9, 1, 8, 2, 0, 6, 4, 6, 7, 2, 4, 1, 0, 5, 2, 6, 4, 9, 8, 5, 4, 1, 6, 3, 8, 6, 1, 2, 0, 8, 8, 0, 3, 6, 8, 7, 7, 7, 6, 0, 2, 1, 2, 8, 4, 5, 5, 3, 0, 7, 8, 4, 7, 4, 4, 1, 8, 0, 9, 1, 9, 0, 6, 4, 1, 2, 4, 5, 8, 2, 9, 1, 8, 2, 2, 7, 2, 5, 3, 8, 9, 4, 0, 7, 0, 3, 5, 9, 7, 3, 3, 8, 8, 9, 3, 2, 5, 4, 4, 8, 3, 0, 1, 7, 9, 6, 4, 0, 4, 7, 8, 4, 5, 9, 6, 7, 8, 2, 0, 0, 5, 0, 5, 9, 9, 9, 9, 5, 4, 3, 7, 5, 4, 1, 9, 5, 4, 9, 9, 5, 7, 8, 2, 4, 7, 4, 3, 8, 6, 6, 0, 4, 5, 5, 7, 6, 5, 5, 1, 9, 4, 2, 2, 1, 9, 9, 8, 1, 1, 8, 1, 0, 0, 4, 0, 2, 7, 6]\n",
            "[1, 4, 7, 0, 7, 1, 0, 3, 3, 1, 9, 8, 4, 6, 5, 9, 8, 6, 3, 6, 6, 6, 1, 1, 4, 0, 7, 4, 0, 4, 6, 7, 9, 5, 9, 6, 2, 4, 7, 5, 9, 8, 5, 1, 8, 0, 3, 6, 8, 1, 3, 0, 3, 1, 9, 1, 4, 5, 8, 2, 2, 9, 1, 3, 3, 0, 5, 6, 1, 8, 3, 6, 7, 2, 3, 2, 9, 2, 1, 5, 9, 8, 7, 3, 8, 4, 5, 8, 2, 1, 6, 7, 6, 1, 1, 0, 5, 0, 9, 1, 7, 4, 0, 8, 7, 5, 9, 8, 8, 2, 5, 4, 3, 7, 9, 4, 7, 2, 7, 4, 1, 5, 9, 2, 3, 5, 9, 8, 4, 5, 9, 1, 5, 1, 1, 3, 7, 5, 1, 7, 9, 2, 3, 6, 8, 8, 5, 0, 8, 8, 4, 7, 1, 9, 6, 8, 9, 4, 9, 9, 6, 3, 2, 7, 4, 8, 0, 4, 9, 0, 8, 8, 7, 0, 9, 0, 8, 7, 0, 8, 5, 3, 3, 6, 2, 5, 3, 1, 3, 3, 1, 0, 6, 5, 9, 3, 2, 9, 4, 8, 8, 7, 6, 4, 4, 0, 7, 5, 9, 6, 7, 3, 8, 9, 5, 0, 8, 6, 0, 3, 0, 1, 8, 2, 8, 6, 0, 1, 2, 0, 7, 3, 6, 9, 2, 3, 1, 7, 3, 9, 5, 9, 9, 1, 1, 5, 8, 3, 2, 5, 4, 1, 8, 4, 0, 7]\n",
            "[0, 4, 0, 0, 7, 1, 3, 5, 5, 8, 9, 7, 9, 4, 6, 0, 1, 9, 2, 7, 4, 8, 5, 0, 5, 9, 8, 7, 5, 0, 8, 9, 9, 6, 3, 0, 8, 7, 5, 2, 6, 1, 7, 2, 3, 8, 8, 1, 4, 6, 1, 4, 0, 2, 3, 6, 3, 3, 2, 9, 1, 3, 2, 5, 8, 7, 7, 6, 2, 0, 3, 2, 8, 1, 5, 4, 3, 3, 1, 9, 3, 2, 1, 1, 3, 6, 1, 3, 4, 4, 9, 6, 6, 7, 5, 9, 6, 6, 1, 0, 7, 8, 8, 8, 3, 7, 7, 7, 1, 4, 6, 1, 0, 0, 1, 7, 7, 8, 8, 9, 8, 2, 4, 8, 1, 3, 6, 1, 3, 3, 6, 6, 5, 8, 8, 5, 4, 5, 9, 8, 2, 0, 1, 3, 3, 5, 6, 3, 3, 6, 9, 3, 3, 7, 7, 5, 6, 5, 1, 7, 4, 5, 9, 0, 2, 8, 0, 9, 5, 3, 0, 8, 0, 7, 7, 1, 5, 4, 4, 9, 7, 0, 3, 1, 3, 3, 6, 2, 4, 2, 1, 6, 5, 9, 3, 4, 1, 9, 4, 0, 3, 5, 1, 0, 0, 5, 3, 9, 4, 9, 1, 0, 0, 5, 7, 1, 6, 8, 3, 7, 0, 3, 8, 2, 8, 6, 7, 9, 1, 8, 4, 5, 3, 1, 3, 2, 2, 5, 3, 8, 8, 2, 7, 4, 8, 5, 7, 0, 6, 6, 2, 3, 2, 2, 9, 1]\n",
            "[9, 6, 9, 2, 2, 6, 0, 4, 0, 0, 0, 0, 3, 0, 4, 3, 6, 7, 8, 6, 0, 5, 1, 8, 5, 6, 0, 2, 7, 6, 1, 3, 9, 9, 3, 0, 3, 5, 9, 6, 8, 3, 1, 0, 0, 9, 0, 6, 6, 2, 4, 3, 0, 2, 7, 1, 5, 8, 5, 8, 8, 4, 7, 4, 3, 6, 5, 7, 3, 1, 6, 7, 1, 3, 1, 8, 8, 1, 5, 2, 2, 6, 9, 0, 2, 7, 2, 7, 4, 4, 9, 3, 0, 4, 5, 1, 4, 6, 9, 7, 6, 5, 0, 6, 1, 3, 8, 4, 0, 0, 0, 3, 7, 9, 8, 5, 9, 9, 1, 5, 0, 9, 1, 7, 9, 0, 8, 9, 0, 6, 9, 2, 4, 2, 1, 9, 4, 4, 8, 8, 6, 5, 6, 1, 3, 5, 9, 3, 9, 7, 0, 7, 6, 5, 8, 6, 6, 0, 7, 4, 5, 1, 7, 7, 8, 5, 5, 5, 5, 3, 6, 8, 3, 6, 1, 9, 8, 0, 9, 4, 4, 5, 8, 4, 0, 9, 3, 0, 9, 4, 6, 4, 0, 2, 0, 1, 7, 5, 9, 8, 7, 8, 6, 2, 0, 0, 3, 7, 8, 6, 1, 6, 7, 2, 5, 9, 7, 1, 1, 4, 1, 6, 6, 7, 0, 8, 4, 7, 0, 9, 4, 6, 2, 6, 7, 3, 2, 9, 6, 5, 2, 5, 8, 5, 6, 3, 2, 2, 7, 7, 3, 4, 9, 2, 8, 0]\n",
            "[2, 4, 0, 9, 4, 5, 8, 8, 9, 3, 3, 5, 9, 0, 7, 0, 5, 5, 2, 9, 1, 9, 9, 4, 6, 4, 6, 8, 9, 0, 0, 8, 2, 1, 6, 8, 2, 3, 0, 2, 5, 5, 7, 3, 3, 3, 9, 6, 2, 3, 4, 3, 7, 7, 9, 2, 6, 6, 9, 5, 8, 0, 6, 7, 4, 2, 2, 4, 0, 6, 2, 1, 4, 2, 6, 7, 5, 2, 7, 0, 6, 8, 2, 4, 4, 5, 7, 6, 8, 1, 4, 6, 6, 1, 5, 2, 5, 0, 0, 1, 1, 4, 7, 0, 3, 6, 5, 0, 5, 2, 0, 8, 9, 1, 5, 7, 3, 3, 6, 1, 6, 5, 9, 5, 2, 0, 7, 4, 0, 2, 7, 4, 4, 6, 0, 4, 6, 8, 9, 1, 7, 4, 7, 9, 4, 7, 4, 8, 5, 9, 5, 5, 1, 9, 3, 2, 4, 0, 2, 6, 6, 8, 0, 4, 3, 1, 2, 6, 7, 3, 7, 7, 1, 5, 5, 4, 0, 1, 2, 2, 1, 1, 4, 2, 2, 1, 1, 7, 9, 4, 8, 0, 8, 9, 3, 8, 9, 4, 6, 3, 3, 3, 9, 4, 3, 6, 9, 1, 4, 6, 0, 6, 0, 5, 9, 0, 1, 8, 0, 4, 2, 0, 1, 5, 3, 4, 5, 7, 6, 8, 8, 7, 9, 0, 3, 2, 6, 0, 5, 5, 9, 6, 5, 4, 2, 1, 4, 3, 6, 4, 8, 7, 2, 8, 0, 3]\n",
            "[4, 5, 3, 3, 1, 6, 4, 5, 9, 7, 0, 1, 2, 5, 3, 2, 6, 4, 2, 5, 9, 3, 4, 6, 3, 5, 8, 2, 8, 9, 8, 7, 5, 9, 9, 9, 4, 6, 7, 3, 6, 9, 9, 6, 6, 0, 9, 4, 9, 7, 4, 1, 7, 2, 8, 8, 0, 5, 6, 7, 1, 8, 0, 8, 0, 9, 4, 2, 4, 2, 1, 1, 6, 7, 6, 7, 5, 3, 6, 6, 3, 4, 8, 7, 8, 8, 7, 0, 0, 7, 7, 1, 6, 0, 3, 9, 9, 3, 5, 1, 7, 0, 1, 9, 5, 7, 9, 0, 1, 9, 0, 9, 8, 4, 2, 2, 5, 5, 0, 0, 5, 9, 4, 3, 4, 2, 5, 0, 0, 3, 3, 3, 5, 9, 0, 1, 1, 5, 9, 2, 2, 3, 3, 4, 4, 1, 0, 8, 3, 5, 5, 6, 9, 1, 9, 8, 7, 0, 3, 3, 8, 7, 0, 3, 3, 9, 7, 3, 1, 9, 6, 3, 3, 4, 0, 2, 1, 3, 9, 5, 1, 7, 9, 7, 9, 6, 1, 5, 6, 6, 9, 0, 4, 2, 2, 4, 3, 7, 6, 4, 1, 4, 2, 4, 1, 0, 2, 2, 1, 0, 2, 7, 2, 6, 8, 2, 0, 2, 0, 0, 5, 0, 3, 9, 0, 6, 6, 4, 1, 5, 9, 2, 4, 2, 9, 1, 1, 3, 0, 1, 1, 5, 0, 2, 4, 7, 3, 6, 8, 7, 8, 8, 7, 2, 6, 9]\n",
            "[4, 5, 7, 1, 3, 6, 0, 9, 9, 4, 6, 8, 6, 4, 1, 0, 3, 3, 0, 1, 8, 9, 8, 5, 7, 7, 3, 4, 6, 2, 9, 3, 0, 7, 4, 8, 8, 2, 4, 0, 2, 9, 8, 3, 9, 9, 0, 1, 6, 7, 7, 8, 4, 6, 8, 7, 6, 6, 3, 3, 5, 2, 1, 6, 4, 1, 9, 9, 6, 4, 6, 4, 5, 9, 4, 9, 9, 3, 2, 5, 1, 6, 2, 2, 7, 2, 1, 4, 7, 4, 1, 0, 1, 9, 0, 7, 4, 9, 0, 9, 7, 4, 0, 9, 6, 7, 4, 9, 7, 0, 2, 8, 5, 2, 4, 2, 4, 5, 2, 6, 6, 8, 8, 6, 7, 4, 1, 4, 8, 3, 2, 5, 4, 0, 9, 0, 1, 4, 9, 7, 7, 3, 9, 5, 3, 1, 9, 2, 6, 7, 9, 1, 0, 5, 1, 6, 8, 8, 6, 7, 3, 7, 2, 8, 5, 5, 0, 8, 1, 5, 6, 8, 9, 9, 1, 6, 9, 8, 5, 3, 7, 7, 8, 7, 4, 7, 0, 4, 0, 5, 4, 3, 1, 9, 6, 3, 0, 0, 2, 8, 9, 9, 1, 1, 8, 1, 3, 2, 3, 1, 0, 3, 8, 5, 0, 7, 2, 0, 6, 1, 8, 1, 1, 8, 2, 2, 6, 1, 7, 9, 7, 6, 7, 5, 1, 9, 6, 3, 7, 6, 4, 4, 4, 0, 8, 2, 0, 8, 6, 4, 8, 1, 9, 2, 9, 5]\n",
            "[1, 5, 1, 1, 4, 7, 0, 1, 2, 4, 6, 1, 4, 2, 9, 2, 7, 2, 6, 4, 5, 5, 5, 8, 9, 6, 1, 1, 6, 1, 2, 1, 9, 4, 7, 4, 7, 1, 0, 6, 4, 6, 5, 3, 3, 4, 0, 1, 1, 6, 0, 5, 1, 2, 7, 6, 4, 3, 9, 0, 4, 0, 3, 1, 4, 9, 2, 1, 7, 0, 9, 6, 8, 5, 8, 6, 0, 8, 7, 9, 9, 3, 1, 3, 2, 3, 1, 1, 2, 0, 0, 7, 2, 8, 1, 6, 0, 6, 7, 4, 3, 6, 7, 2, 2, 8, 9, 9, 4, 2, 7, 7, 3, 5, 1, 7, 7, 3, 7, 8, 4, 2, 5, 6, 1, 9, 7, 7, 7, 8, 9, 9, 7, 8, 9, 5, 7, 9, 5, 0, 7, 6, 1, 6, 5, 2, 7, 2, 5, 6, 9, 5, 8, 2, 2, 2, 9, 7, 9, 5, 1, 1, 1, 4, 5, 6, 1, 7, 0, 7, 9, 2, 7, 2, 3, 1, 5, 7, 1, 5, 1, 6, 0, 2, 6, 9, 9, 7, 9, 8, 7, 7, 7, 5, 6, 2, 9, 8, 8, 8, 7, 3, 1, 3, 4, 8, 2, 0, 2, 6, 3, 1, 0, 9, 9, 1, 6, 8, 8, 6, 6, 2, 2, 6, 1, 6, 6, 2, 0, 6, 0, 8, 2, 2, 8, 6, 4, 8, 5, 0, 4, 0, 0, 9, 7, 9, 2, 9, 2, 8, 5, 3, 5, 8, 7, 9]\n",
            "[5, 7, 3, 0, 2, 8, 0, 5, 9, 6, 9, 9, 3, 9, 2, 2, 3, 3, 7, 4, 5, 8, 5, 8, 6, 9, 3, 1, 2, 6, 8, 5, 5, 2, 7, 4, 1, 9, 3, 6, 8, 8, 2, 5, 8, 3, 9, 1, 6, 9, 6, 7, 5, 8, 1, 6, 8, 6, 7, 5, 1, 2, 8, 9, 3, 8, 8, 3, 9, 4, 8, 7, 6, 9, 5, 3, 0, 9, 9, 6, 8, 7, 9, 1, 2, 3, 2, 1, 5, 2, 3, 4, 4, 4, 3, 0, 0, 3, 1, 3, 1, 1, 8, 5, 6, 2, 7, 6, 0, 4, 4, 7, 0, 7, 0, 8, 7, 1, 3, 7, 8, 9, 0, 9, 0, 0, 1, 8, 8, 7, 4, 8, 3, 5, 9, 0, 3, 6, 3, 6, 5, 0, 4, 2, 6, 9, 3, 0, 9, 4, 5, 7, 7, 4, 2, 3, 9, 2, 8, 8, 0, 1, 9, 4, 2, 2, 1, 8, 2, 7, 3, 5, 1, 3, 0, 2, 2, 1, 7, 9, 1, 8, 4, 1, 6, 9, 7, 1, 8, 9, 9, 2, 0, 6, 1, 5, 2, 0, 9, 2, 5, 5, 3, 4, 0, 4, 0, 9, 4, 0, 4, 3, 7, 8, 0, 4, 0, 2, 4, 8, 2, 1, 5, 2, 5, 8, 5, 6, 1, 4, 8, 6, 2, 1, 3, 9, 8, 3, 7, 8, 7, 8, 2, 1, 5, 6, 4, 7, 5, 5, 4, 0, 8, 1, 6, 0]\n",
            "[3, 3, 7, 8, 8, 4, 3, 4, 3, 2, 1, 7, 0, 9, 4, 2, 8, 6, 8, 5, 2, 8, 4, 8, 1, 4, 3, 7, 1, 2, 1, 5, 3, 5, 7, 2, 4, 7, 6, 3, 1, 2, 8, 6, 8, 2, 6, 2, 0, 1, 8, 0, 6, 3, 9, 7, 3, 1, 9, 4, 6, 9, 7, 2, 7, 8, 1, 3, 5, 1, 2, 7, 6, 6, 5, 0, 4, 5, 9, 6, 3, 9, 1, 2, 4, 1, 3, 4, 0, 1, 8, 0, 2, 9, 2, 7, 7, 9, 1, 4, 7, 3, 3, 9, 9, 1, 3, 7, 8, 4, 9, 7, 9, 7, 1, 5, 4, 0, 0, 0, 5, 5, 8, 3, 0, 4, 1, 2, 8, 1, 0, 8, 8, 3, 4, 9, 9, 3, 2, 7, 2, 6, 8, 1, 0, 1, 8, 1, 3, 7, 4, 9, 9, 3, 5, 0, 3, 5, 4, 8, 6, 1, 6, 9, 6, 6, 6, 1, 9, 0, 3, 9, 8, 4, 6, 3, 6, 8, 9, 9, 5, 1, 8, 0, 2, 0, 8, 9, 5, 2, 0, 1, 1, 9, 2, 8, 1, 8, 2, 3, 7, 9, 6, 7, 9, 5, 7, 4, 6, 4, 9, 6, 0, 0, 4, 3, 5, 7, 1, 7, 1, 9, 2, 1, 3, 1, 9, 1, 8, 5, 8, 7, 9, 3, 2, 3, 6, 1, 7, 5, 2, 2, 6, 3, 7, 0, 5, 6, 7, 9, 6, 8, 6, 0, 9, 5]\n",
            "[9, 4, 1, 9, 5, 0, 7, 6, 2, 5, 5, 6, 6, 0, 4, 3, 8, 4, 3, 5, 0, 2, 6, 5, 0, 2, 6, 0, 6, 0, 5, 3, 6, 1, 9, 3, 8, 4, 3, 3, 2, 5, 4, 4, 0, 6, 1, 2, 0, 3, 5, 5, 0, 4, 1, 1, 3, 3, 9, 3, 3, 6, 4, 9, 0, 6, 9, 7, 9, 8, 5, 7, 9, 1, 4, 6, 8, 6, 8, 4, 9, 7, 1, 6, 8, 6, 7, 9, 4, 2, 0, 9, 9, 9, 1, 6, 6, 8, 0, 6, 3, 7, 7, 6, 7, 0, 1, 6, 5, 4, 5, 6, 2, 5, 3, 9, 5, 1, 3, 9, 6, 9, 7, 0, 6, 2, 7, 6, 9, 0, 3, 8, 1, 2, 9, 3, 0, 8, 1, 3, 9, 8, 6, 5, 1, 3, 6, 7, 1, 5, 1, 8, 1, 7, 3, 7, 9, 5, 2, 4, 9, 6, 8, 6, 6, 0, 8, 1, 7, 7, 1, 9, 0, 1, 4, 9, 1, 7, 3, 1, 6, 2, 2, 7, 2, 4, 1, 5, 6, 1, 3, 3, 2, 2, 9, 1, 7, 4, 8, 5, 5, 6, 3, 8, 1, 3, 9, 5, 6, 7, 5, 3, 3, 7, 7, 1, 8, 0, 6, 8, 9, 3, 3, 6, 8, 2, 0, 1, 0, 1, 1, 3, 2, 2, 9, 0, 3, 8, 8, 0, 5, 9, 8, 3, 3, 1, 3, 6, 5, 2, 7, 7, 9, 8, 5, 7]\n",
            "[1, 7, 4, 3, 9, 4, 4, 3, 2, 0, 0, 0, 3, 1, 1, 4, 3, 4, 2, 2, 2, 8, 4, 7, 4, 9, 4, 9, 1, 0, 7, 1, 2, 1, 6, 2, 4, 0, 4, 6, 0, 5, 1, 4, 1, 6, 2, 9, 7, 3, 4, 3, 9, 0, 1, 4, 8, 6, 2, 1, 1, 7, 3, 2, 9, 2, 2, 5, 2, 1, 0, 2, 5, 0, 0, 0, 4, 2, 7, 3, 0, 2, 1, 9, 0, 8, 5, 3, 8, 2, 2, 0, 2, 7, 0, 4, 0, 3, 0, 2, 2, 8, 0, 9, 2, 3, 0, 2, 4, 8, 7, 1, 4, 2, 2, 1, 6, 7, 6, 6, 3, 3, 6, 7, 3, 9, 1, 2, 8, 5, 0, 1, 0, 9, 7, 9, 0, 8, 5, 1, 4, 7, 6, 4, 8, 1, 2, 2, 6, 4, 2, 9, 8, 2, 6, 5, 8, 3, 1, 7, 4, 6, 0, 1, 3, 8, 1, 4, 0, 8, 6, 6, 1, 6, 2, 3, 9, 1, 5, 6, 6, 1, 4, 0, 3, 6, 0, 5, 6, 8, 9, 4, 7, 7, 7, 8, 8, 7, 5, 2, 7, 8, 1, 1, 9, 5, 4, 1, 0, 1, 3, 2, 3, 6, 3, 3, 8, 2, 7, 1, 7, 7, 0, 0, 3, 0, 0, 2, 0, 0, 7, 1, 7, 8, 6, 6, 7, 1, 6, 6, 2, 4, 9, 1, 3, 4, 0, 4, 9, 2, 8, 6, 2, 7, 4, 7]\n",
            "[5, 0, 3, 7, 5, 6, 6, 9, 0, 3, 5, 2, 8, 9, 8, 2, 2, 9, 7, 1, 7, 7, 2, 7, 3, 2, 2, 8, 4, 0, 2, 2, 8, 1, 1, 2, 2, 2, 3, 0, 1, 6, 3, 9, 4, 3, 9, 7, 9, 0, 7, 3, 5, 2, 3, 0, 1, 9, 9, 7, 9, 2, 7, 4, 7, 0, 6, 5, 1, 9, 5, 2, 7, 2, 2, 5, 6, 8, 5, 8, 2, 3, 3, 1, 4, 7, 3, 8, 4, 5, 7, 4, 1, 9, 0, 4, 8, 0, 6, 5, 6, 5, 2, 0, 3, 3, 1, 6, 1, 4, 1, 1, 1, 1, 3, 9, 1, 0, 4, 2, 9, 3, 5, 9, 5, 5, 2, 5, 0, 8, 0, 4, 2, 4, 3, 8, 7, 9, 4, 0, 1, 4, 9, 1, 4, 3, 2, 0, 8, 4, 1, 0, 9, 3, 2, 4, 6, 9, 0, 6, 1, 1, 7, 4, 7, 8, 7, 5, 7, 0, 1, 8, 4, 2, 5, 4, 8, 9, 1, 0, 2, 8, 7, 8, 4, 4, 7, 6, 9, 4, 1, 7, 8, 8, 3, 4, 2, 4, 7, 8, 7, 8, 7, 4, 9, 4, 7, 3, 6, 9, 1, 5, 1, 0, 1, 8, 1, 6, 4, 3, 3, 6, 5, 5, 8, 1, 9, 2, 3, 7, 9, 9, 2, 9, 8, 3, 4, 5, 1, 4, 9, 6, 1, 3, 5, 6, 9, 6, 5, 3, 5, 4, 5, 0, 2, 6]\n",
            "[8, 9, 9, 9, 6, 6, 7, 5, 8, 2, 0, 9, 5, 0, 1, 9, 7, 2, 3, 3, 0, 4, 9, 3, 1, 3, 9, 0, 3, 8, 4, 9, 4, 6, 8, 9, 6, 9, 0, 8, 6, 5, 0, 4, 8, 6, 0, 0, 9, 1, 4, 2, 5, 6, 3, 8, 8, 8, 8, 2, 4, 2, 7, 6, 4, 7, 8, 6, 9, 8, 6, 3, 5, 4, 3, 9, 9, 3, 0, 8, 2, 9, 1, 6, 9, 1, 0, 1, 8, 7, 6, 5, 5, 4, 1, 7, 3, 9, 1, 1, 2, 3, 9, 0, 7, 2, 2, 4, 1, 7, 7, 7, 8, 3, 5, 1, 6, 2, 1, 0, 8, 7, 2, 5, 1, 1, 8, 6, 9, 6, 6, 9, 8, 1, 7, 4, 9, 8, 6, 7, 8, 0, 7, 6, 1, 6, 8, 1, 3, 9, 0, 7, 5, 3, 2, 7, 0, 8, 1, 4, 0, 8, 7, 0, 6, 5, 1, 7, 0, 1, 6, 6, 1, 4, 8, 6, 8, 9, 5, 1, 0, 2, 2, 0, 7, 8, 3, 5, 1, 8, 3, 7, 6, 9, 8, 4, 9, 1, 0, 3, 3, 5, 9, 2, 7, 6, 3, 3, 8, 0, 0, 9, 7, 5, 5, 0, 3, 0, 7, 2, 1, 0, 7, 1, 5, 7, 0, 2, 5, 4, 2, 0, 1, 3, 1, 1, 3, 6, 6, 8, 4, 2, 3, 0, 1, 4, 4, 1, 8, 8, 9, 7, 6, 2, 5, 1]\n",
            "[9, 7, 5, 9, 1, 4, 3, 9, 4, 6, 9, 8, 5, 0, 8, 4, 7, 0, 0, 8, 0, 4, 7, 0, 2, 2, 7, 9, 6, 9, 5, 6, 1, 1, 1, 4, 8, 7, 9, 6, 2, 2, 2, 8, 5, 7, 1, 1, 1, 2, 9, 1, 8, 1, 9, 2, 1, 0, 6, 4, 7, 6, 5, 9, 1, 2, 8, 8, 4, 4, 3, 7, 1, 7, 9, 2, 8, 8, 6, 1, 3, 4, 5, 6, 8, 7, 0, 0, 1, 5, 4, 5, 5, 7, 3, 2, 0, 9, 9, 4, 9, 5, 0, 3, 6, 3, 3, 1, 7, 4, 0, 0, 2, 7, 7, 8, 8, 7, 4, 5, 0, 1, 9, 7, 4, 5, 0, 9, 8, 6, 3, 3, 1, 6, 8, 8, 0, 9, 9, 1, 1, 3, 7, 4, 0, 3, 0, 4, 9, 9, 8, 8, 0, 9, 0, 1, 6, 0, 2, 0, 2, 5, 7, 0, 6, 9, 9, 2, 2, 5, 3, 6, 4, 3, 2, 5, 9, 3, 5, 2, 9, 5, 4, 1, 7, 2, 5, 3, 9, 7, 2, 4, 0, 8, 7, 9, 7, 8, 4, 6, 6, 3, 2, 6, 7, 0, 6, 0, 2, 2, 3, 0, 0, 3, 3, 4, 1, 1, 4, 3, 3, 0, 0, 3, 2, 4, 1, 5, 9, 2, 4, 9, 5, 8, 9, 9, 9, 1, 8, 0, 0, 9, 0, 8, 2, 0, 9, 8, 6, 2, 3, 2, 0, 6, 3, 8]\n",
            "[1, 9, 2, 0, 4, 2, 8, 9, 4, 3, 6, 0, 2, 0, 4, 5, 3, 4, 1, 2, 2, 4, 9, 4, 3, 2, 1, 9, 1, 6, 1, 0, 3, 4, 0, 1, 9, 4, 0, 0, 4, 8, 1, 9, 2, 3, 3, 4, 3, 7, 0, 7, 9, 7, 4, 5, 9, 7, 7, 0, 4, 2, 2, 9, 8, 5, 0, 4, 9, 8, 8, 2, 4, 1, 4, 1, 4, 1, 0, 9, 9, 5, 6, 4, 9, 2, 2, 6, 0, 3, 0, 2, 3, 0, 4, 0, 1, 0, 8, 4, 9, 3, 7, 1, 4, 1, 7, 6, 0, 7, 7, 1, 5, 0, 3, 6, 0, 2, 8, 8, 8, 5, 7, 7, 2, 9, 6, 7, 8, 8, 8, 7, 3, 1, 7, 3, 1, 8, 0, 1, 0, 4, 3, 7, 2, 9, 7, 9, 3, 6, 2, 3, 4, 1, 3, 0, 9, 9, 2, 6, 4, 0, 0, 7, 5, 1, 8, 3, 8, 1, 6, 5, 8, 9, 3, 2, 0, 7, 1, 6, 7, 1, 6, 8, 4, 3, 5, 9, 1, 3, 5, 3, 1, 9, 2, 5, 8, 6, 3, 6, 0, 9, 2, 5, 1, 3, 7, 4, 4, 4, 2, 0, 6, 3, 1, 0, 4, 3, 6, 1, 7, 6, 2, 7, 1, 7, 0, 6, 9, 6, 5, 1, 3, 6, 8, 1, 9, 8, 6, 6, 9, 3, 6, 8, 2, 4, 0, 6, 1, 8, 5, 1, 4, 0, 9, 9]\n",
            "[9, 4, 8, 4, 1, 6, 4, 9, 1, 8, 9, 2, 3, 4, 6, 1, 0, 1, 6, 7, 9, 0, 0, 8, 1, 4, 2, 5, 2, 8, 4, 6, 9, 7, 1, 8, 3, 5, 4, 9, 3, 3, 5, 3, 0, 0, 5, 9, 2, 5, 3, 7, 6, 5, 9, 6, 5, 0, 2, 1, 3, 8, 5, 7, 7, 0, 7, 7, 1, 5, 6, 7, 0, 4, 3, 0, 0, 0, 0, 7, 6, 8, 8, 6, 7, 1, 3, 1, 0, 2, 3, 5, 1, 8, 6, 1, 7, 6, 3, 6, 6, 8, 3, 8, 5, 1, 5, 2, 6, 5, 1, 5, 8, 3, 5, 5, 3, 2, 3, 8, 5, 8, 6, 7, 0, 3, 8, 8, 4, 2, 6, 4, 5, 8, 3, 0, 5, 1, 1, 3, 0, 9, 6, 7, 8, 2, 5, 3, 6, 2, 0, 6, 5, 1, 2, 9, 7, 0, 2, 5, 5, 6, 1, 4, 1, 3, 1, 5, 5, 0, 1, 9, 3, 9, 5, 0, 7, 9, 8, 3, 0, 1, 3, 5, 8, 1, 8, 5, 7, 0, 9, 6, 4, 8, 3, 0, 6, 0, 4, 5, 8, 2, 1, 5, 4, 0, 1, 4, 1, 7, 3, 9, 2, 9, 1, 2, 1, 7, 6, 6, 1, 5, 9, 8, 9, 0, 2, 3, 1, 7, 6, 1, 5, 2, 7, 3, 2, 5, 9, 9, 4, 0, 5, 1, 5, 9, 1, 0, 9, 4, 5, 4, 8, 7, 1, 3]\n",
            "[3, 2, 4, 1, 1, 8, 0, 3, 2, 8, 9, 0, 9, 7, 0, 9, 9, 2, 7, 6, 1, 7, 1, 6, 0, 2, 9, 9, 9, 7, 8, 2, 4, 0, 9, 3, 8, 9, 4, 2, 0, 3, 3, 0, 3, 9, 4, 8, 5, 5, 6, 9, 6, 8, 4, 7, 6, 7, 4, 9, 4, 2, 1, 0, 8, 1, 3, 6, 0, 1, 9, 9, 6, 5, 5, 0, 7, 1, 3, 6, 7, 3, 3, 4, 8, 4, 7, 9, 1, 2, 9, 5, 7, 4, 3, 9, 3, 9, 5, 0, 7, 9, 2, 2, 1, 8, 3, 2, 7, 8, 7, 1, 2, 8, 7, 4, 8, 0, 9, 4, 0, 0, 3, 3, 4, 2, 0, 7, 6, 3, 2, 7, 4, 1, 2, 7, 4, 9, 2, 3, 2, 5, 8, 0, 8, 7, 9, 7, 1, 3, 5, 4, 2, 4, 7, 9, 9, 6, 4, 5, 4, 9, 1, 9, 6, 5, 6, 2, 8, 6, 8, 8, 8, 9, 6, 8, 8, 6, 4, 0, 2, 5, 1, 3, 8, 9, 8, 7, 7, 7, 8, 0, 7, 9, 5, 4, 3, 7, 4, 6, 4, 7, 2, 9, 6, 4, 0, 4, 6, 8, 8, 4, 9, 4, 4, 3, 6, 9, 6, 4, 1, 8, 5, 7, 8, 5, 2, 8, 8, 7, 0, 5, 0, 7, 2, 5, 4, 7, 8, 1, 5, 5, 3, 5, 2, 5, 0, 5, 6, 4, 7, 4, 1, 1, 9, 1]\n",
            "[9, 9, 4, 8, 4, 3, 7, 6, 2, 0, 1, 8, 9, 6, 7, 4, 5, 7, 5, 3, 1, 6, 0, 3, 2, 4, 5, 1, 8, 1, 1, 8, 5, 8, 5, 8, 5, 2, 7, 0, 1, 5, 1, 9, 0, 9, 9, 2, 0, 7, 3, 1, 3, 4, 7, 8, 0, 1, 2, 9, 3, 1, 6, 2, 0, 5, 0, 1, 6, 1, 9, 7, 7, 8, 6, 8, 4, 0, 7, 1, 0, 1, 3, 4, 9, 0, 9, 4, 5, 1, 6, 9, 4, 6, 6, 6, 1, 1, 3, 5, 8, 2, 4, 8, 8, 9, 8, 1, 1, 1, 8, 5, 5, 6, 5, 5, 2, 8, 7, 9, 8, 1, 9, 9, 0, 6, 6, 2, 3, 8, 3, 0, 0, 5, 0, 9, 2, 1, 3, 3, 3, 8, 8, 9, 9, 9, 5, 6, 7, 1, 7, 2, 7, 1, 6, 3, 5, 0, 7, 7, 6, 5, 1, 8, 1, 3, 4, 5, 8, 2, 4, 2, 8, 0, 4, 5, 1, 9, 7, 4, 2, 8, 8, 5, 8, 6, 8, 7, 4, 9, 7, 4, 4, 2, 6, 9, 1, 9, 9, 0, 6, 8, 3, 3, 6, 4, 6, 6, 8, 1, 9, 4, 3, 7, 2, 8, 5, 1, 2, 6, 8, 0, 0, 1, 7, 8, 4, 9, 6, 0, 7, 3, 9, 9, 2, 7, 4, 2, 0, 5, 2, 6, 4, 1, 7, 3, 0, 4, 8, 1, 6, 1, 4, 7, 2, 1]\n",
            "[0, 3, 3, 9, 0, 9, 6, 6, 0, 2, 8, 3, 0, 5, 8, 8, 5, 3, 5, 0, 8, 0, 7, 3, 3, 2, 5, 1, 1, 6, 5, 4, 7, 2, 2, 9, 0, 8, 8, 0, 5, 0, 8, 0, 4, 1, 6, 7, 7, 8, 5, 0, 2, 6, 4, 6, 8, 9, 6, 6, 4, 9, 4, 3, 7, 6, 3, 1, 7, 6, 1, 4, 9, 0, 6, 6, 3, 2, 0, 8, 4, 3, 8, 8, 1, 3, 3, 0, 6, 6, 8, 6, 2, 3, 3, 4, 2, 0, 6, 0, 2, 1, 9, 6, 6, 1, 7, 7, 0, 2, 9, 4, 1, 5, 0, 7, 5, 8, 5, 6, 1, 7, 0, 6, 6, 5, 9, 3, 6, 4, 2, 1, 1, 7, 8, 5, 9, 3, 3, 7, 6, 1, 5, 2, 1, 2, 5, 7, 0, 5, 2, 6, 6, 9, 1, 0, 5, 5, 2, 4, 6, 3, 0, 9, 4, 9, 4, 7, 0, 0, 4, 0, 9, 2, 7, 1, 1, 2, 1, 1, 6, 3, 3, 5, 8, 1, 8, 2, 0, 3, 8, 4, 1, 6, 8, 5, 8, 4, 3, 5, 8, 6, 7, 1, 6, 1, 9, 8, 4, 3, 9, 3, 1, 7, 8, 8, 3, 1, 7, 8, 6, 5, 4, 6, 0, 9, 2, 0, 0, 0, 2, 6, 7, 5, 1, 0, 0, 0, 9, 3, 8, 0, 4, 5, 9, 4, 2, 3, 2, 7, 2, 0, 2, 6, 2, 2]\n",
            "[8, 8, 8, 5, 7, 2, 2, 6, 2, 0, 2, 2, 1, 4, 3, 4, 1, 9, 7, 0, 5, 6, 5, 1, 8, 2, 5, 3, 9, 0, 6, 6, 9, 2, 1, 0, 4, 8, 4, 5, 7, 9, 2, 2, 2, 1, 1, 4, 4, 7, 8, 6, 8, 6, 5, 5, 8, 1, 8, 2, 9, 1, 9, 7, 2, 4, 4, 4, 9, 9, 3, 5, 5, 9, 5, 5, 2, 7, 0, 0, 1, 3, 5, 3, 0, 0, 0, 3, 1, 4, 0, 2, 6, 9, 7, 6, 9, 6, 6, 2, 5, 2, 2, 4, 1, 9, 2, 7, 2, 5, 9, 4, 4, 2, 7, 6, 8, 9, 1, 8, 8, 0, 2, 4, 9, 8, 1, 7, 1, 9, 9, 2, 1, 5, 5, 2, 7, 6, 3, 0, 5, 0, 6, 6, 3, 0, 0, 3, 6, 8, 8, 0, 8, 6, 4, 5, 8, 1, 5, 0, 6, 6, 9, 5, 1, 6, 4, 3, 0, 7, 2, 5, 5, 8, 7, 5, 6, 9, 0, 1, 9, 2, 9, 1, 2, 4, 8, 7, 6, 2, 8, 0, 4, 1, 8, 2, 1, 3, 4, 1, 7, 7, 2, 9, 3, 8, 6, 3, 2, 2, 6, 3, 5, 7, 1, 1, 1, 7, 7, 8, 2, 9, 7, 3, 1, 5, 6, 4, 4, 4, 1, 9, 0, 8, 4, 7, 4, 6, 2, 3, 8, 6, 7, 4, 2, 5, 9, 0, 0, 0, 8, 6, 5, 2, 3, 0]\n",
            "[4, 2, 5, 4, 8, 6, 7, 6, 1, 4, 0, 1, 6, 1, 4, 4, 6, 1, 1, 4, 4, 5, 7, 5, 4, 2, 5, 1, 0, 6, 7, 1, 1, 4, 4, 0, 5, 6, 0, 8, 2, 7, 4, 9, 9, 0, 2, 2, 5, 3, 0, 3, 1, 0, 1, 1, 2, 8, 8, 6, 8, 6, 2, 0, 2, 9, 7, 3, 3, 8, 5, 0, 6, 6, 5, 8, 3, 2, 7, 3, 5, 7, 7, 5, 8, 1, 1, 6, 0, 5, 7, 5, 9, 5, 0, 4, 3, 7, 2, 3, 5, 4, 5, 1, 1, 9, 4, 8, 3, 7, 5, 0, 4, 4, 7, 8, 4, 8, 1, 1, 0, 5, 6, 7, 9, 5, 6, 8, 0, 6, 0, 2, 1, 7, 9, 0, 3, 2, 8, 7, 2, 1, 3, 9, 9, 0, 7, 6, 1, 3, 7, 2, 3, 6, 4, 1, 1, 7, 4, 4, 5, 3, 2, 8, 9, 6, 6, 5, 4, 0, 6, 7, 3, 5, 2, 8, 1, 9, 0, 5, 3, 3, 9, 2, 9, 1, 7, 4, 5, 0, 5, 1, 9, 1, 1, 9, 9, 4, 6, 6, 1, 4, 5, 4, 8, 7, 6, 1, 1, 2, 4, 6, 2, 9, 9, 5, 3, 6, 4, 8, 3, 8, 2, 2, 1, 5, 8, 7, 5, 2, 8, 0, 7, 2, 5, 5, 6, 4, 8, 7, 3, 8, 2, 1, 3, 9, 1, 0, 4, 0, 6, 5, 5, 0, 0, 6]\n",
            "[7, 7, 1, 8, 7, 5, 6, 6, 8, 1, 2, 9, 8, 0, 5, 9, 1, 3, 7, 4, 6, 9, 3, 0, 0, 7, 0, 0, 8, 8, 0, 8, 8, 1, 1, 4, 0, 9, 0, 9, 5, 3, 0, 1, 7, 1, 1, 4, 4, 0, 4, 1, 7, 1, 5, 5, 4, 6, 6, 8, 3, 3, 1, 1, 8, 0, 9, 8, 2, 7, 2, 9, 8, 8, 5, 4, 8, 2, 8, 3, 2, 6, 3, 9, 1, 1, 2, 5, 9, 1, 7, 2, 7, 9, 1, 2, 9, 7, 5, 5, 5, 7, 4, 3, 5, 2, 7, 8, 0, 5, 1, 4, 8, 2, 3, 1, 8, 2, 4, 7, 7, 7, 3, 3, 2, 9, 2, 7, 6, 1, 9, 9, 2, 3, 2, 5, 8, 1, 6, 3, 0, 9, 1, 2, 6, 3, 5, 8, 4, 2, 6, 1, 6, 1, 0, 4, 9, 0, 1, 4, 1, 2, 1, 6, 0, 7, 6, 1, 0, 0, 1, 8, 3, 0, 6, 7, 0, 3, 2, 0, 1, 7, 8, 4, 4, 6, 1, 6, 2, 3, 0, 3, 9, 9, 8, 7, 5, 8, 0, 1, 0, 0, 0, 5, 6, 2, 7, 5, 3, 8, 8, 1, 9, 2, 3, 4, 0, 5, 3, 8, 3, 6, 8, 9, 3, 4, 8, 9, 4, 3, 2, 9, 2, 3, 7, 3, 7, 7, 7, 0, 4, 9, 5, 2, 3, 6, 6, 7, 5, 3, 3, 7, 1, 4, 9, 0]\n",
            "[9, 9, 8, 0, 0, 2, 9, 2, 3, 9, 2, 4, 9, 2, 1, 9, 7, 6, 9, 1, 9, 6, 4, 7, 7, 7, 2, 7, 6, 2, 9, 6, 6, 7, 3, 9, 8, 3, 0, 9, 2, 8, 0, 3, 1, 9, 5, 2, 8, 9, 4, 4, 1, 0, 9, 1, 9, 7, 4, 5, 4, 3, 8, 5, 7, 0, 1, 4, 1, 8, 1, 6, 6, 9, 4, 8, 8, 1, 2, 2, 7, 8, 0, 2, 0, 4, 4, 3, 8, 1, 7, 6, 5, 4, 5, 0, 2, 2, 1, 5, 7, 2, 4, 6, 4, 4, 9, 2, 2, 7, 6, 1, 7, 1, 1, 3, 9, 7, 5, 1, 7, 4, 2, 2, 5, 7, 3, 5, 4, 6, 2, 8, 7, 2, 8, 9, 9, 2, 9, 2, 4, 4, 1, 6, 0, 6, 8, 6, 5, 6, 9, 8, 1, 2, 2, 5, 0, 9, 4, 1, 9, 7, 3, 6, 5, 6, 5, 7, 0, 3, 0, 0, 2, 7, 0, 7, 8, 7, 2, 9, 5, 8, 0, 7, 2, 7, 6, 2, 0, 9, 7, 3, 5, 0, 3, 9, 0, 4, 6, 9, 1, 9, 1, 0, 0, 8, 8, 9, 8, 3, 9, 9, 7, 8, 2, 5, 4, 2, 5, 5, 3, 1, 1, 9, 2, 7, 9, 5, 7, 6, 1, 2, 2, 9, 1, 4, 6, 6, 4, 4, 8, 4, 7, 1, 2, 0, 7, 6, 7, 6, 7, 1, 5, 2, 9, 2]\n",
            "[9, 6, 6, 6, 2, 1, 4, 5, 7, 4, 8, 1, 0, 5, 1, 5, 7, 4, 6, 2, 3, 5, 2, 5, 9, 1, 9, 3, 8, 0, 1, 6, 5, 9, 7, 7, 0, 9, 6, 3, 0, 9, 3, 1, 2, 8, 1, 3, 5, 9, 9, 8, 7, 1, 4, 9, 3, 5, 7, 1, 4, 4, 7, 4, 3, 3, 1, 9, 1, 3, 9, 3, 1, 4, 7, 2, 5, 6, 5, 6, 1, 8, 9, 4, 7, 1, 1, 8, 9, 6, 4, 6, 6, 0, 6, 2, 5, 3, 4, 3, 5, 6, 8, 2, 4, 3, 2, 0, 1, 4, 9, 3, 4, 2, 3, 0, 8, 5, 8, 1, 7, 8, 0, 9, 7, 7, 7, 1, 0, 4, 0, 4, 1, 6, 2, 4, 4, 6, 0, 7, 2, 2, 3, 9, 1, 1, 2, 2, 9, 3, 8, 0, 5, 2, 6, 2, 1, 1, 8, 7, 8, 2, 3, 8, 7, 1, 6, 3, 7, 0, 5, 0, 6, 0, 4, 2, 2, 1, 7, 8, 4, 8, 9, 8, 8, 0, 2, 3, 4, 1, 3, 6, 3, 8, 7, 9, 2, 6, 3, 6, 9, 2, 2, 5, 7, 8, 7, 2, 3, 6, 9, 1, 9, 6, 4, 5, 6, 6, 0, 7, 3, 9, 4, 1, 6, 9, 1, 6, 9, 3, 5, 2, 2, 7, 9, 7, 2, 9, 0, 8, 8, 2, 1, 9, 1, 2, 5, 0, 9, 0, 5, 6, 8, 9, 5, 8]\n",
            "[5, 1, 9, 4, 1, 6, 4, 4, 6, 3, 7, 3, 8, 2, 4, 5, 1, 6, 4, 7, 1, 2, 3, 2, 3, 5, 2, 5, 3, 2, 1, 5, 3, 0, 4, 9, 3, 4, 6, 2, 1, 9, 9, 5, 8, 0, 3, 0, 0, 6, 6, 2, 6, 2, 0, 7, 1, 2, 8, 2, 9, 1, 6, 4, 3, 9, 0, 9, 5, 4, 3, 1, 0, 2, 5, 6, 2, 4, 4, 3, 4, 4, 7, 6, 6, 2, 4, 0, 3, 3, 8, 4, 1, 8, 2, 5, 5, 2, 4, 0, 0, 4, 1, 5, 7, 7, 8, 3, 6, 2, 6, 5, 1, 7, 3, 1, 7, 7, 4, 8, 7, 3, 3, 3, 1, 6, 1, 5, 5, 9, 3, 0, 5, 2, 0, 8, 0, 0, 2, 5, 5, 8, 5, 4, 7, 5, 4, 1, 5, 3, 7, 7, 7, 3, 1, 4, 3, 8, 4, 0, 7, 0, 0, 0, 9, 8, 1, 5, 8, 9, 6, 8, 7, 4, 1, 4, 4, 0, 2, 0, 4, 5, 5, 8, 6, 8, 9, 6, 6, 5, 1, 5, 7, 3, 5, 2, 3, 2, 3, 8, 6, 4, 8, 0, 1, 2, 7, 5, 5, 0, 4, 6, 6, 8, 4, 4, 6, 5, 5, 5, 9, 4, 6, 1, 8, 0, 2, 7, 5, 1, 3, 3, 2, 8, 1, 3, 6, 3, 4, 6, 4, 6, 3, 0, 0, 5, 5, 0, 7, 9, 1, 3, 1, 4, 8, 7]\n",
            "[5, 8, 0, 0, 0, 0, 6, 9, 7, 8, 4, 9, 6, 7, 4, 0, 7, 6, 8, 1, 4, 1, 3, 0, 8, 7, 8, 1, 3, 4, 1, 5, 2, 3, 0, 7, 1, 0, 3, 8, 5, 0, 3, 1, 5, 4, 5, 3, 8, 6, 6, 6, 1, 4, 7, 3, 7, 8, 6, 0, 5, 6, 6, 9, 5, 5, 2, 2, 6, 1, 5, 6, 0, 3, 2, 6, 6, 1, 5, 9, 5, 4, 6, 1, 1, 7, 2, 0, 5, 8, 1, 0, 4, 8, 6, 1, 9, 5, 1, 7, 6, 6, 7, 6, 7, 3, 8, 1, 1, 6, 4, 8, 1, 4, 4, 1, 4, 1, 1, 7, 9, 6, 3, 8, 6, 5, 6, 2, 5, 9, 4, 3, 1, 6, 6, 3, 0, 7, 4, 4, 6, 1, 1, 5, 5, 4, 1, 6, 9, 2, 7, 7, 5, 1, 9, 3, 9, 3, 9, 4, 9, 8, 1, 7, 1, 8, 6, 9, 5, 3, 6, 8, 8, 8, 9, 2, 8, 3, 4, 0, 8, 4, 6, 5, 0, 6, 7, 8, 9, 7, 4, 2, 7, 2, 8, 0, 0, 4, 2, 9, 0, 1, 7, 9, 7, 1, 7, 0, 7, 0, 3, 1, 2, 8, 1, 4, 4, 0, 7, 0, 9, 8, 1, 8, 8, 1, 2, 5, 5, 1, 0, 8, 8, 0, 3, 7, 0, 5, 3, 7, 7, 0, 5, 5, 2, 5, 2, 2, 7, 2, 7, 5, 6, 7, 6, 2]\n",
            "[4, 0, 1, 8, 0, 6, 9, 9, 6, 6, 2, 4, 4, 0, 1, 7, 9, 8, 2, 3, 3, 1, 4, 5, 2, 2, 7, 4, 1, 7, 9, 8, 9, 6, 8, 7, 8, 7, 0, 4, 4, 9, 5, 5, 0, 3, 6, 9, 4, 1, 0, 1, 2, 3, 1, 6, 0, 1, 2, 4, 3, 3, 2, 0, 6, 9, 2, 1, 3, 2, 2, 8, 0, 6, 1, 1, 2, 7, 2, 8, 3, 1, 9, 5, 5, 1, 8, 5, 0, 3, 7, 7, 5, 4, 5, 9, 3, 5, 7, 8, 0, 2, 1, 4, 0, 9, 1, 7, 9, 1, 6, 7, 1, 3, 5, 9, 2, 4, 0, 3, 5, 1, 4, 2, 1, 4, 0, 1, 1, 7, 3, 7, 1, 3, 3, 0, 4, 9, 4, 6, 8, 2, 9, 5, 1, 9, 5, 0, 7, 2, 3, 4, 8, 6, 7, 2, 5, 5, 8, 0, 1, 4, 7, 3, 6, 6, 5, 1, 9, 3, 0, 3, 8, 9, 7, 1, 3, 0, 5, 7, 4, 0, 4, 9, 9, 8, 2, 8, 3, 1, 5, 8, 3, 7, 5, 0, 3, 5, 4, 4, 2, 5, 9, 6, 6, 0, 2, 4, 1, 9, 8, 5, 0, 3, 8, 3, 0, 1, 1, 2, 9, 6, 1, 1, 0, 7, 2, 3, 2, 7, 7, 1, 4, 1, 8, 6, 7, 7, 6, 3, 2, 4, 1, 4, 5, 8, 3, 6, 4, 8, 4, 6, 6, 1, 7, 5]\n",
            "[8, 1, 3, 2, 2, 9, 0, 0, 2, 9, 1, 3, 3, 3, 3, 9, 3, 4, 1, 2, 6, 8, 1, 9, 5, 4, 7, 9, 0, 7, 2, 9, 9, 1, 4, 0, 6, 7, 8, 7, 9, 7, 2, 4, 4, 4, 6, 3, 1, 9, 3, 6, 6, 3, 2, 8, 2, 8, 2, 4, 0, 6, 0, 3, 5, 5, 0, 1, 6, 5, 2, 3, 0, 3, 0, 0, 4, 4, 5, 0, 5, 3, 0, 2, 3, 1, 2, 4, 3, 0, 2, 0, 7, 9, 3, 3, 9, 6, 5, 9, 8, 1, 8, 0, 6, 5, 1, 4, 5, 1, 7, 8, 7, 6, 2, 1, 1, 0, 5, 0, 4, 1, 9, 5, 7, 4, 5, 3, 8, 8, 3, 7, 8, 2, 6, 9, 8, 3, 6, 6, 7, 6, 2, 8, 6, 9, 1, 5, 7, 2, 1, 2, 3, 9, 4, 1, 9, 2, 8, 4, 6, 7, 8, 6, 9, 8, 4, 5, 1, 2, 0, 2, 9, 6, 1, 5, 0, 8, 5, 2, 7, 5, 8, 1, 5, 1, 1, 0, 5, 4, 2, 0, 0, 9, 0, 2, 7, 7, 5, 2, 5, 4, 6, 3, 9, 5, 4, 0, 5, 6, 3, 2, 3, 1, 6, 2, 4, 4, 4, 0, 5, 1, 8, 0, 3, 4, 5, 0, 2, 2, 0, 1, 1, 6, 1, 4, 3, 1, 5, 9, 9, 2, 5, 0, 0, 2, 4, 7, 8, 2, 8, 4, 4, 4, 4, 8]\n",
            "[0, 5, 8, 5, 4, 7, 4, 4, 9, 2, 4, 8, 3, 0, 9, 8, 7, 4, 2, 4, 2, 6, 3, 2, 7, 5, 1, 0, 2, 9, 9, 0, 4, 7, 7, 0, 5, 4, 4, 1, 5, 2, 6, 8, 1, 2, 8, 3, 3, 2, 9, 7, 1, 4, 4, 6, 9, 0, 2, 4, 4, 5, 7, 8, 9, 4, 3, 4, 1, 7, 8, 2, 8, 2, 1, 2, 9, 7, 7, 0, 1, 2, 0, 9, 4, 2, 1, 4, 5, 0, 8, 6, 1, 9, 5, 1, 6, 2, 1, 8, 0, 5, 1, 9, 9, 6, 6, 5, 1, 1, 7, 9, 4, 2, 7, 3, 4, 6, 0, 6, 3, 0, 6, 3, 0, 1, 3, 2, 6, 3, 2, 0, 5, 9, 1, 3, 9, 0, 2, 0, 5, 8, 9, 6, 6, 5, 2, 4, 7, 2, 0, 7, 9, 1, 3, 9, 9, 2, 6, 4, 9, 7, 6, 0, 0, 4, 8, 4, 9, 8, 3, 5, 1, 7, 7, 1, 4, 1, 6, 3, 9, 7, 6, 6, 1, 9, 4, 0, 0, 4, 4, 8, 3, 1, 7, 5, 7, 3, 7, 4, 1, 0, 3, 2, 4, 3, 2, 2, 6, 0, 9, 9, 2, 3, 1, 8, 6, 4, 2, 2, 1, 7, 3, 1, 4, 5, 5, 6, 8, 1, 7, 8, 3, 7, 6, 7, 7, 3, 7, 2, 4, 5, 7, 7, 9, 0, 9, 1, 8, 1, 8, 4, 4, 1, 9, 9]\n",
            "[6, 1, 7, 5, 3, 5, 3, 7, 8, 0, 0, 1, 0, 3, 6, 6, 1, 9, 4, 0, 1, 0, 2, 0, 6, 7, 7, 5, 3, 1, 8, 9, 9, 0, 4, 6, 2, 5, 0, 6, 5, 6, 8, 3, 4, 1, 8, 4, 6, 8, 7, 1, 8, 6, 8, 1, 2, 3, 3, 2, 3, 3, 6, 8, 2, 7, 6, 8, 8, 0, 9, 2, 7, 7, 5, 3, 1, 2, 3, 1, 4, 3, 6, 4, 8, 3, 1, 3, 6, 9, 6, 9, 0, 3, 9, 0, 7, 7, 3, 0, 0, 9, 3, 5, 7, 9, 8, 6, 0, 7, 7, 2, 8, 7, 9, 1, 2, 3, 6, 0, 7, 8, 1, 0, 3, 6, 9, 9, 5, 0, 5, 0, 1, 1, 8, 2, 5, 9, 5, 4, 0, 3, 5, 1, 2, 7, 6, 5, 3, 0, 5, 6, 9, 0, 7, 8, 1, 7, 1, 8, 5, 2, 2, 9, 7, 3, 2, 1, 2, 5, 4, 9, 2, 1, 3, 1, 8, 5, 6, 2, 7, 3, 9, 9, 4, 3, 6, 3, 1, 1, 7, 5, 3, 5, 2, 9, 9, 7, 9, 3, 9, 1, 1, 1, 8, 1, 6, 2, 6, 6, 5, 8, 2, 9, 7, 0, 3, 5, 7, 8, 7, 8, 8, 9, 3, 7, 1, 8, 5, 4, 7, 5, 8, 0, 5, 9, 7, 0, 7, 7, 4, 4, 5, 8, 9, 2, 4, 7, 5, 1, 4, 4, 9, 6, 4, 2]\n",
            "[0, 2, 6, 2, 2, 8, 4, 1, 6, 1, 2, 2, 1, 3, 1, 2, 4, 6, 4, 3, 5, 5, 5, 1, 0, 1, 1, 7, 1, 7, 2, 6, 9, 5, 5, 2, 5, 2, 8, 9, 3, 2, 8, 9, 7, 3, 5, 6, 8, 9, 8, 3, 7, 0, 4, 5, 1, 0, 1, 6, 4, 2, 1, 9, 7, 0, 9, 3, 1, 6, 3, 6, 0, 8, 2, 6, 5, 7, 9, 0, 7, 0, 8, 4, 0, 9, 4, 6, 0, 7, 5, 2, 1, 9, 6, 1, 1, 2, 7, 0, 3, 3, 8, 9, 4, 8, 4, 8, 4, 9, 9, 8, 6, 9, 8, 3, 0, 9, 6, 7, 8, 3, 5, 8, 1, 2, 7, 8, 7, 1, 6, 8, 3, 1, 6, 8, 7, 6, 9, 1, 5, 9, 0, 7, 4, 3, 2, 3, 4, 8, 9, 3, 0, 5, 2, 0, 6, 1, 6, 7, 9, 0, 4, 5, 4, 3, 1, 9, 4, 8, 7, 2, 8, 2, 6, 7, 9, 7, 0, 4, 6, 3, 7, 5, 4, 4, 2, 2, 9, 6, 7, 0, 5, 0, 0, 3, 3, 5, 9, 7, 6, 2, 2, 4, 9, 0, 5, 3, 1, 8, 5, 9, 9, 7, 1, 4, 3, 6, 7, 8, 1, 6, 4, 1, 4, 9, 7, 1, 3, 0, 8, 7, 8, 7, 1, 6, 9, 4, 8, 3, 7, 6, 9, 3, 0, 8, 4, 1, 6, 8, 1, 9, 4, 3, 8, 4]\n",
            "[0, 9, 4, 4, 9, 3, 2, 2, 8, 0, 4, 3, 7, 4, 4, 6, 5, 3, 0, 5, 3, 1, 4, 6, 3, 5, 9, 3, 5, 1, 3, 8, 0, 9, 2, 3, 7, 9, 2, 4, 3, 1, 0, 7, 7, 5, 6, 6, 4, 8, 8, 2, 0, 7, 7, 7, 0, 8, 5, 8, 5, 3, 0, 9, 5, 7, 2, 0, 1, 0, 3, 9, 2, 4, 4, 1, 4, 3, 2, 9, 1, 1, 9, 0, 2, 7, 9, 7, 8, 6, 7, 7, 7, 6, 7, 9, 4, 7, 1, 1, 8, 1, 1, 1, 1, 6, 3, 1, 1, 5, 6, 1, 3, 8, 1, 0, 9, 3, 9, 7, 5, 0, 5, 9, 6, 3, 0, 3, 2, 2, 4, 2, 0, 6, 7, 7, 0, 4, 7, 3, 5, 8, 7, 4, 0, 7, 4, 2, 4, 2, 9, 2, 6, 0, 4, 4, 1, 8, 0, 9, 9, 6, 1, 6, 6, 7, 7, 1, 3, 8, 0, 9, 4, 4, 9, 0, 0, 7, 1, 1, 0, 2, 5, 2, 0, 9, 2, 3, 6, 2, 0, 5, 7, 2, 9, 4, 1, 5, 1, 4, 1, 6, 4, 2, 1, 5, 9, 6, 0, 4, 4, 1, 3, 3, 3, 0, 4, 1, 5, 6, 1, 2, 0, 7, 8, 6, 4, 8, 2, 8, 4, 4, 8, 2, 1, 1, 9, 5, 1, 4, 0, 2, 7, 1, 4, 0, 9, 4, 4, 4, 5, 1, 7, 4, 6, 4]\n",
            "[5, 8, 7, 1, 4, 7, 9, 7, 8, 0, 8, 6, 9, 8, 3, 1, 2, 8, 1, 1, 9, 5, 8, 8, 6, 0, 7, 6, 4, 6, 3, 2, 6, 0, 9, 1, 6, 5, 2, 7, 3, 4, 3, 1, 0, 6, 8, 7, 6, 4, 0, 5, 0, 9, 7, 5, 3, 6, 4, 4, 9, 7, 7, 4, 2, 2, 1, 1, 5, 3, 5, 4, 7, 7, 3, 4, 8, 7, 7, 1, 1, 9, 4, 4, 4, 3, 0, 3, 7, 8, 1, 6, 4, 0, 6, 2, 9, 0, 6, 3, 6, 6, 6, 8, 1, 9, 9, 3, 6, 3, 8, 0, 7, 2, 0, 3, 2, 5, 7, 9, 6, 4, 8, 4, 4, 1, 9, 8, 8, 9, 1, 5, 7, 1, 6, 7, 0, 2, 8, 2, 4, 5, 5, 2, 6, 1, 1, 4, 0, 9, 4, 3, 7, 9, 3, 0, 2, 9, 6, 3, 3, 3, 2, 3, 4, 6, 7, 9, 3, 6, 7, 8, 3, 9, 1, 2, 4, 5, 9, 9, 4, 1, 4, 7, 6, 8, 2, 8, 0, 6, 2, 9, 6, 7, 1, 2, 7, 8, 6, 0, 8, 8, 1, 7, 7, 3, 5, 3, 7, 4, 7, 0, 4, 1, 9, 1, 5, 2, 1, 6, 6, 0, 9, 6, 6, 0, 2, 1, 7, 9, 5, 8, 2, 7, 2, 3, 0, 2, 1, 9, 9, 9, 1, 3, 3, 6, 9, 3, 3, 7, 4, 1, 8, 1, 7, 5]\n",
            "[4, 2, 8, 0, 6, 4, 6, 4, 7, 4, 6, 7, 8, 0, 2, 3, 3, 8, 7, 2, 3, 4, 4, 9, 6, 8, 6, 6, 1, 2, 8, 1, 7, 6, 7, 1, 8, 7, 6, 2, 9, 7, 5, 8, 4, 6, 8, 0, 1, 7, 3, 2, 0, 8, 8, 3, 5, 4, 1, 8, 6, 4, 1, 0, 1, 1, 0, 2, 4, 5, 6, 4, 3, 8, 6, 2, 6, 9, 8, 4, 6, 5, 6, 2, 5, 7, 4, 9, 1, 3, 8, 2, 8, 4, 9, 5, 8, 8, 4, 2, 6, 1, 5, 5, 3, 6, 7, 0, 3, 4, 6, 6, 5, 6, 1, 3, 7, 7, 2, 7, 3, 3, 3, 9, 1, 2, 1, 5, 1, 1, 6, 0, 2, 9, 6, 9, 6, 6, 5, 1, 0, 0, 7, 6, 9, 5, 1, 7, 6, 9, 7, 4, 8, 2, 3, 6, 8, 6, 3, 2, 1, 0, 8, 9, 2, 4, 4, 0, 0, 9, 6, 8, 0, 3, 9, 3, 9, 7, 9, 7, 3, 7, 2, 8, 2, 3, 8, 4, 1, 2, 7, 2, 1, 2, 7, 1, 4, 0, 5, 3, 5, 5, 3, 3, 8, 6, 9, 9, 0, 2, 5, 7, 4, 6, 8, 6, 2, 3, 3, 7, 8, 8, 4, 9, 7, 0, 3, 8, 7, 4, 8, 2, 8, 7, 7, 5, 7, 8, 0, 7, 5, 1, 5, 9, 9, 0, 4, 9, 7, 4, 7, 9, 0, 6, 4, 3]\n",
            "[5, 9, 0, 9, 4, 4, 8, 6, 1, 2, 1, 1, 9, 2, 7, 7, 0, 1, 5, 1, 6, 9, 8, 3, 4, 0, 3, 1, 0, 5, 3, 9, 8, 1, 7, 8, 5, 6, 8, 1, 1, 7, 1, 4, 8, 0, 8, 5, 6, 0, 7, 7, 1, 6, 8, 0, 6, 2, 1, 0, 5, 4, 5, 1, 2, 1, 1, 2, 7, 3, 3, 6, 5, 2, 8, 5, 9, 8, 4, 3, 5, 3, 4, 0, 6, 6, 3, 5, 4, 6, 8, 1, 2, 7, 9, 0, 3, 4, 9, 6, 8, 6, 9, 3, 8, 2, 8, 4, 1, 1, 9, 3, 8, 1, 2, 3, 3, 9, 4, 7, 2, 4, 0, 1, 4, 3, 6, 2, 4, 1, 5, 9, 7, 1, 7, 4, 6, 1, 6, 7, 4, 8, 2, 1, 7, 9, 2, 2, 5, 5, 3, 9, 0, 6, 2, 5, 6, 0, 3, 4, 3, 6, 7, 6, 0, 3, 5, 5, 8, 4, 0, 6, 9, 5, 6, 0, 1, 7, 5, 7, 5, 6, 4, 3, 4, 4, 6, 2, 2, 4, 7, 7, 3, 2, 0, 7, 4, 9, 2, 4, 2, 1, 3, 9, 4, 0, 1, 2, 9, 7, 7, 9, 3, 4, 5, 5, 1, 5, 5, 6, 1, 2, 8, 8, 4, 6, 7, 9, 6, 1, 0, 5, 4, 0, 3, 1, 1, 5, 5, 3, 1, 2, 4, 6, 9, 2, 4, 1, 7, 9, 8, 5, 1, 1, 4, 3]\n",
            "[6, 2, 2, 1, 6, 7, 7, 1, 7, 3, 0, 1, 1, 5, 3, 1, 1, 3, 2, 7, 1, 2, 1, 8, 8, 0, 7, 5, 5, 4, 0, 8, 7, 7, 3, 4, 5, 8, 2, 0, 7, 4, 1, 1, 8, 1, 5, 4, 2, 1, 0, 2, 4, 7, 0, 2, 8, 0, 2, 1, 9, 7, 3, 3, 4, 4, 1, 1, 4, 2, 3, 1, 0, 9, 8, 5, 9, 8, 6, 7, 3, 1, 6, 3, 7, 6, 1, 7, 3, 3, 5, 7, 7, 6, 0, 8, 1, 7, 3, 3, 3, 2, 1, 3, 9, 4, 3, 1, 9, 7, 7, 2, 3, 4, 8, 0, 9, 4, 1, 1, 7, 2, 5, 6, 4, 1, 0, 4, 2, 1, 3, 7, 4, 0, 2, 8, 5, 8, 9, 4, 2, 5, 6, 8, 2, 9, 7, 0, 1, 7, 3, 3, 6, 9, 4, 5, 3, 1, 7, 0, 8, 1, 4, 1, 1, 1, 8, 7, 4, 7, 9, 6, 9, 6, 2, 4, 4, 2, 1, 8, 7, 5, 4, 6, 2, 1, 6, 7, 1, 5, 0, 0, 5, 8, 4, 7, 2, 0, 5, 9, 2, 2, 4, 2, 4, 3, 0, 1, 8, 5, 1, 3, 2, 1, 3, 2, 4, 0, 4, 1, 8, 3, 7, 9, 5, 8, 8, 6, 4, 3, 7, 4, 9, 6, 8, 8, 6, 6, 5, 7, 8, 4, 4, 2, 3, 6, 6, 0, 0, 6, 6, 9, 1, 4, 4, 7]\n",
            "[3, 7, 8, 2, 3, 8, 4, 5, 6, 4, 0, 3, 9, 2, 0, 0, 7, 8, 8, 3, 5, 8, 6, 3, 7, 5, 0, 2, 7, 8, 6, 1, 5, 5, 4, 4, 3, 4, 5, 3, 2, 8, 2, 1, 5, 7, 1, 7, 4, 9, 3, 1, 7, 3, 3, 6, 8, 9, 5, 2, 2, 8, 8, 8, 7, 2, 9, 7, 4, 1, 7, 8, 2, 0, 3, 1, 3, 6, 9, 6, 4, 9, 6, 7, 8, 3, 1, 6, 7, 9, 4, 9, 6, 8, 9, 8, 1, 4, 8, 9, 3, 1, 8, 0, 5, 2, 7, 1, 0, 5, 2, 4, 0, 3, 8, 9, 6, 6, 2, 8, 6, 7, 0, 0, 3, 3, 6, 5, 1, 1, 7, 9, 3, 1, 5, 8, 3, 2, 6, 8, 3, 8, 7, 4, 2, 9, 7, 3, 9, 8, 2, 3, 5, 1, 0, 9, 9, 2, 3, 7, 7, 9, 7, 8, 6, 0, 5, 4, 3, 7, 4, 1, 3, 4, 8, 7, 0, 0, 5, 6, 4, 5, 1, 4, 9, 2, 2, 7, 9, 2, 9, 8, 2, 1, 8, 2, 3, 5, 5, 3, 2, 0, 9, 8, 6, 1, 2, 0, 1, 1, 5, 6, 8, 8, 3, 3, 9, 0, 0, 3, 2, 4, 8, 9, 8, 4, 1, 9, 0, 9, 9, 2, 9, 4, 4, 7, 9, 9, 1, 2, 0, 5, 3, 9, 6, 7, 2, 5, 4, 4, 0, 1, 0, 9, 4, 0]\n",
            "[1, 9, 6, 0, 2, 1, 4, 5, 7, 8, 7, 7, 9, 2, 8, 7, 5, 6, 4, 9, 8, 7, 0, 3, 1, 6, 8, 6, 3, 2, 6, 8, 5, 5, 5, 2, 8, 3, 6, 3, 6, 9, 0, 5, 2, 5, 5, 8, 7, 4, 4, 7, 0, 2, 5, 4, 0, 1, 1, 0, 6, 2, 5, 0, 9, 0, 8, 5, 4, 6, 5, 3, 8, 7, 0, 9, 1, 4, 1, 5, 2, 2, 4, 2, 9, 8, 7, 1, 8, 3, 4, 7, 1, 9, 0, 9, 8, 7, 9, 4, 1, 9, 7, 2, 0, 8, 2, 4, 3, 5, 5, 4, 2, 8, 5, 5, 7, 1, 6, 3, 3, 8, 0, 9, 4, 0, 1, 6, 8, 5, 6, 2, 3, 4, 4, 2, 3, 6, 2, 1, 6, 8, 5, 9, 1, 7, 9, 0, 7, 9, 4, 2, 6, 0, 6, 4, 1, 7, 2, 8, 0, 6, 0, 1, 9, 9, 3, 7, 0, 7, 4, 6, 2, 1, 2, 1, 7, 6, 9, 0, 9, 1, 4, 8, 7, 3, 8, 6, 9, 3, 8, 3, 7, 9, 6, 0, 1, 7, 1, 1, 4, 1, 6, 6, 3, 1, 8, 1, 9, 6, 2, 1, 0, 1, 2, 7, 9, 0, 5, 1, 3, 2, 6, 1, 4, 9, 4, 9, 5, 2, 6, 6, 3, 4, 3, 4, 7, 0, 7, 0, 8, 2, 0, 0, 7, 7, 1, 0, 5, 6, 2, 3, 7, 1, 7, 6]\n",
            "[8, 3, 2, 0, 1, 5, 8, 2, 6, 0, 0, 5, 4, 0, 9, 6, 6, 4, 2, 7, 1, 2, 9, 5, 8, 7, 4, 4, 6, 8, 9, 8, 3, 3, 7, 3, 2, 0, 4, 9, 0, 3, 7, 6, 2, 0, 0, 7, 2, 1, 7, 1, 8, 8, 5, 9, 5, 7, 8, 8, 7, 5, 1, 9, 6, 3, 2, 0, 6, 8, 7, 0, 3, 9, 9, 0, 9, 5, 7, 6, 2, 2, 5, 3, 8, 5, 7, 1, 1, 5, 4, 6, 0, 2, 7, 2, 0, 7, 5, 1, 1, 7, 9, 0, 8, 9, 0, 8, 1, 7, 3, 2, 7, 1, 9, 3, 3, 7, 9, 4, 2, 7, 3, 7, 2, 5, 9, 0, 2, 6, 0, 1, 8, 8, 7, 0, 2, 9, 7, 0, 1, 9, 6, 7, 2, 3, 7, 6, 9, 9, 0, 3, 6, 4, 4, 2, 3, 5, 4, 6, 3, 0, 7, 0, 2, 7, 7, 7, 0, 0, 1, 9, 0, 6, 9, 7, 8, 1, 3, 1, 1, 2, 3, 9, 0, 0, 5, 2, 2, 3, 8, 3, 4, 9, 1, 2, 5, 1, 1, 5, 2, 8, 8, 5, 1, 8, 5, 3, 6, 7, 9, 1, 8, 8, 2, 1, 8, 8, 0, 9, 0, 2, 3, 5, 6, 0, 0, 0, 8, 0, 6, 3, 3, 7, 2, 5, 6, 2, 8, 5, 8, 0, 2, 7, 4, 0, 1, 3, 1, 8, 0, 8, 9, 5, 3, 0]\n",
            "[3, 7, 0, 6, 8, 3, 2, 6, 9, 7, 3, 1, 8, 7, 6, 3, 2, 6, 4, 9, 5, 8, 2, 7, 3, 2, 4, 8, 4, 4, 4, 1, 1, 6, 8, 8, 5, 1, 7, 3, 5, 0, 1, 8, 4, 5, 6, 2, 7, 9, 9, 9, 6, 7, 0, 1, 6, 8, 4, 3, 5, 4, 1, 6, 4, 5, 1, 2, 6, 9, 2, 4, 7, 0, 2, 1, 8, 1, 7, 7, 5, 3, 2, 8, 7, 5, 1, 4, 5, 9, 1, 7, 9, 7, 0, 6, 0, 2, 8, 2, 9, 4, 3, 0, 3, 8, 8, 4, 3, 5, 4, 2, 9, 1, 8, 1, 6, 0, 4, 8, 0, 9, 1, 0, 5, 9, 7, 7, 5, 8, 4, 7, 9, 7, 9, 6, 9, 5, 8, 4, 0, 0, 5, 9, 6, 5, 1, 6, 0, 2, 1, 8, 5, 7, 4, 4, 1, 4, 6, 2, 8, 9, 5, 5, 6, 1, 1, 3, 1, 7, 0, 3, 3, 5, 8, 7, 2, 3, 3, 7, 3, 9, 9, 8, 6, 6, 0, 5, 5, 4, 3, 0, 6, 1, 1, 3, 2, 6, 1, 9, 3, 7, 3, 8, 0, 0, 0, 1, 5, 2, 8, 7, 1, 0, 4, 3, 2, 3, 9, 5, 4, 4, 9, 2, 9, 9, 3, 9, 2, 1, 0, 6, 4, 1, 9, 4, 0, 9, 5, 0, 8, 8, 9, 4, 3, 1, 5, 5, 0, 6, 6, 6, 5, 6, 4, 4]\n",
            "[0, 4, 8, 5, 9, 4, 6, 4, 5, 8, 5, 7, 4, 1, 1, 2, 8, 3, 1, 6, 3, 5, 3, 7, 7, 1, 7, 9, 7, 3, 5, 9, 4, 2, 3, 2, 2, 2, 6, 5, 0, 7, 7, 3, 9, 8, 5, 0, 5, 9, 0, 6, 3, 3, 5, 7, 2, 6, 1, 7, 1, 8, 8, 1, 2, 0, 3, 5, 0, 1, 8, 3, 3, 3, 9, 8, 4, 1, 1, 3, 5, 1, 7, 4, 1, 5, 9, 9, 0, 7, 7, 6, 4, 1, 6, 7, 7, 8, 2, 1, 9, 4, 4, 9, 5, 3, 4, 9, 4, 7, 3, 9, 7, 1, 6, 5, 7, 8, 0, 1, 9, 0, 2, 6, 1, 0, 2, 4, 4, 6, 1, 1, 2, 8, 1, 6, 4, 7, 7, 1, 6, 8, 2, 9, 2, 7, 8, 6, 6, 4, 2, 5, 5, 2, 5, 7, 6, 7, 9, 9, 2, 0, 8, 9, 4, 5, 3, 8, 2, 3, 0, 4, 5, 1, 7, 8, 6, 3, 5, 9, 1, 5, 9, 7, 8, 0, 4, 5, 0, 6, 0, 6, 5, 1, 2, 6, 0, 2, 2, 9, 8, 1, 6, 2, 1, 9, 4, 8, 4, 2, 9, 9, 7, 1, 6, 7, 9, 9, 2, 4, 4, 3, 5, 3, 8, 6, 8, 6, 7, 2, 4, 6, 1, 4, 1, 9, 1, 6, 5, 2, 8, 5, 8, 9, 6, 0, 6, 9, 2, 5, 7, 6, 4, 2, 7, 7]\n",
            "[3, 5, 6, 6, 5, 9, 4, 5, 4, 0, 5, 5, 1, 8, 1, 2, 1, 1, 2, 3, 6, 8, 2, 1, 2, 5, 4, 2, 1, 2, 8, 6, 8, 8, 6, 0, 9, 7, 6, 2, 4, 3, 2, 9, 7, 3, 4, 6, 8, 1, 8, 8, 7, 1, 4, 3, 2, 9, 8, 8, 0, 5, 7, 3, 1, 8, 3, 3, 7, 0, 3, 7, 1, 1, 8, 3, 0, 4, 9, 6, 1, 8, 9, 0, 6, 7, 2, 9, 0, 2, 3, 3, 1, 9, 7, 6, 6, 3, 0, 2, 3, 2, 6, 5, 9, 7, 1, 7, 1, 5, 5, 1, 6, 1, 4, 2, 9, 7, 8, 4, 7, 5, 1, 4, 5, 2, 5, 1, 9, 0, 7, 1, 7, 3, 0, 6, 0, 6, 8, 5, 4, 1, 1, 1, 0, 7, 3, 3, 7, 4, 6, 7, 3, 1, 6, 5, 8, 7, 7, 4, 9, 1, 3, 4, 9, 1, 4, 1, 8, 2, 3, 6, 7, 1, 3, 4, 1, 0, 0, 8, 9, 6, 5, 0, 5, 5, 4, 0, 6, 4, 4, 0, 2, 8, 9, 1, 9, 7, 3, 2, 3, 3, 7, 4, 8, 8, 2, 5, 2, 8, 6, 0, 1, 6, 3, 9, 5, 0, 6, 7, 3, 8, 5, 5, 9, 8, 8, 5, 5, 1, 3, 7, 5, 2, 9, 5, 4, 6, 7, 3, 2, 0, 9, 5, 0, 2, 4, 0, 1, 1, 0, 8, 5, 3, 6, 9]\n",
            "[6, 1, 1, 7, 3, 0, 6, 7, 5, 0, 1, 1, 1, 5, 4, 5, 2, 4, 2, 8, 9, 1, 3, 5, 1, 7, 4, 5, 1, 1, 9, 4, 0, 7, 2, 5, 9, 2, 9, 2, 1, 5, 2, 0, 4, 3, 9, 8, 7, 0, 4, 9, 8, 2, 0, 7, 0, 1, 3, 4, 5, 7, 0, 3, 4, 0, 6, 4, 3, 7, 3, 7, 4, 9, 9, 7, 7, 1, 3, 6, 5, 8, 1, 0, 8, 9, 0, 1, 0, 8, 7, 5, 4, 4, 1, 3, 2, 7, 1, 2, 0, 3, 0, 6, 8, 7, 1, 3, 3, 1, 3, 8, 0, 5, 8, 1, 1, 8, 9, 1, 1, 7, 2, 2, 3, 4, 0, 1, 5, 6, 3, 3, 3, 9, 7, 1, 0, 5, 8, 7, 3, 9, 1, 9, 2, 3, 8, 9, 6, 5, 2, 2, 6, 2, 9, 2, 2, 8, 2, 9, 5, 1, 9, 8, 8, 5, 7, 1, 8, 4, 1, 4, 3, 1, 8, 8, 6, 4, 2, 0, 1, 8, 7, 2, 7, 8, 8, 1, 7, 1, 2, 4, 3, 1, 6, 5, 0, 2, 9, 1, 5, 9, 7, 5, 3, 9, 7, 2, 2, 2, 6, 1, 1, 3, 9, 0, 0, 7, 6, 5, 6, 4, 2, 8, 5, 3, 6, 6, 1, 1, 2, 6, 1, 6, 7, 2, 0, 1, 8, 9, 1, 7, 8, 7, 3, 7, 0, 0, 1, 5, 5, 8, 4, 4, 4, 4]\n",
            "[9, 9, 2, 0, 3, 1, 7, 1, 5, 2, 7, 2, 4, 3, 3, 3, 3, 8, 0, 8, 9, 7, 1, 9, 0, 8, 6, 6, 5, 9, 0, 2, 1, 4, 9, 8, 5, 7, 1, 8, 5, 1, 0, 4, 2, 4, 7, 3, 1, 9, 6, 0, 9, 9, 1, 2, 4, 1, 6, 9, 6, 1, 6, 4, 3, 9, 9, 0, 2, 7, 6, 6, 6, 0, 7, 4, 8, 4, 3, 4, 0, 0, 4, 7, 1, 5, 3, 0, 1, 6, 6, 7, 1, 2, 0, 9, 2, 4, 1, 5, 4, 7, 1, 4, 1, 7, 2, 1, 5, 2, 7, 1, 3, 2, 1, 1, 8, 4, 9, 5, 4, 0, 4, 6, 2, 0, 9, 6, 4, 4, 5, 3, 2, 5, 9, 1, 7, 5, 0, 0, 8, 3, 0, 0, 0, 3, 1, 3, 9, 5, 3, 3, 7, 2, 9, 0, 8, 2, 8, 0, 7, 1, 7, 6, 3, 0, 6, 4, 3, 7, 6, 7, 4, 2, 0, 9, 2, 2, 6, 2, 8, 6, 4, 5, 2, 3, 6, 9, 8, 5, 5, 2, 4, 2, 1, 5, 3, 8, 6, 9, 2, 6, 1, 4, 6, 5, 1, 1, 7, 3, 8, 3, 8, 8, 1, 9, 8, 1, 6, 8, 4, 2, 2, 8, 3, 3, 4, 5, 2, 7, 0, 3, 9, 5, 4, 7, 4, 8, 0, 2, 9, 3, 1, 8, 4, 8, 0, 3, 7, 0, 9, 5, 3, 8, 0, 5]\n",
            "[1, 3, 6, 9, 6, 5, 4, 7, 1, 5, 6, 5, 2, 1, 0, 6, 2, 2, 9, 9, 1, 0, 3, 3, 3, 7, 2, 9, 8, 5, 0, 1, 6, 6, 0, 1, 1, 8, 7, 4, 4, 9, 9, 0, 8, 8, 6, 7, 1, 4, 3, 6, 8, 8, 1, 1, 6, 9, 8, 1, 1, 1, 6, 1, 6, 9, 3, 3, 0, 5, 7, 7, 5, 7, 5, 5, 5, 0, 0, 1, 3, 4, 8, 8, 8, 7, 7, 2, 8, 6, 4, 6, 4, 8, 0, 6, 6, 9, 5, 1, 0, 6, 1, 6, 7, 1, 3, 2, 4, 0, 7, 9, 3, 4, 4, 3, 2, 5, 0, 4, 5, 5, 6, 8, 5, 6, 4, 4, 8, 6, 0, 9, 4, 1, 7, 3, 1, 7, 9, 9, 9, 2, 8, 0, 5, 1, 4, 3, 2, 4, 8, 1, 5, 8, 1, 4, 4, 1, 7, 7, 5, 6, 3, 2, 0, 3, 9, 1, 9, 4, 5, 1, 3, 9, 9, 4, 3, 2, 8, 1, 8, 6, 7, 1, 9, 0, 2, 0, 9, 0, 6, 1, 5, 0, 8, 0, 9, 3, 8, 1, 8, 7, 1, 8, 6, 6, 4, 0, 8, 6, 3, 7, 9, 2, 2, 5, 1, 4, 3, 3, 6, 9, 1, 0, 7, 2, 5, 4, 7, 5, 1, 9, 9, 3, 4, 3, 3, 8, 8, 7, 0, 8, 3, 7, 2, 1, 8, 6, 1, 2, 7, 9, 1, 0, 6, 5]\n",
            "[0, 2, 3, 9, 1, 7, 0, 8, 6, 2, 4, 9, 5, 7, 2, 9, 2, 3, 8, 2, 1, 7, 5, 1, 4, 5, 1, 8, 1, 7, 4, 4, 1, 3, 7, 0, 5, 2, 9, 2, 6, 5, 1, 1, 5, 1, 8, 4, 2, 5, 5, 8, 7, 6, 4, 0, 7, 9, 8, 6, 0, 8, 2, 4, 9, 8, 6, 4, 7, 2, 8, 8, 3, 9, 9, 1, 4, 0, 2, 1, 0, 0, 0, 9, 2, 3, 8, 3, 1, 9, 3, 0, 2, 8, 6, 0, 8, 7, 4, 5, 6, 2, 8, 4, 3, 0, 0, 0, 7, 7, 8, 4, 8, 6, 4, 2, 1, 2, 0, 6, 7, 4, 3, 5, 2, 0, 0, 4, 4, 9, 8, 5, 1, 4, 1, 2, 1, 5, 4, 9, 9, 5, 1, 8, 1, 5, 7, 4, 5, 6, 7, 6, 3, 8, 3, 4, 2, 3, 6, 3, 6, 8, 3, 4, 2, 4, 0, 1, 9, 1, 7, 7, 2, 7, 2, 4, 1, 0, 4, 6, 2, 5, 6, 0, 3, 1, 4, 1, 2, 1, 5, 7, 7, 4, 3, 0, 3, 7, 0, 2, 8, 6, 1, 8, 4, 0, 9, 0, 4, 1, 5, 3, 9, 4, 6, 5, 0, 5, 0, 1, 4, 8, 1, 0, 5, 8, 9, 6, 5, 4, 5, 5, 8, 3, 1, 9, 9, 2, 0, 3, 9, 3, 4, 3, 0, 6, 6, 5, 9, 3, 9, 2, 5, 9, 6, 3]\n",
            "[6, 9, 8, 2, 6, 8, 4, 1, 1, 3, 5, 8, 0, 4, 5, 4, 0, 2, 0, 6, 2, 1, 2, 3, 1, 1, 0, 5, 4, 4, 0, 6, 7, 1, 7, 2, 3, 6, 4, 8, 1, 8, 3, 7, 0, 2, 9, 5, 1, 3, 8, 6, 9, 7, 8, 0, 2, 9, 9, 9, 1, 0, 1, 5, 5, 4, 2, 4, 5, 3, 8, 6, 7, 9, 8, 2, 5, 1, 1, 2, 5, 0, 6, 9, 8, 8, 7, 1, 8, 9, 9, 2, 1, 3, 9, 2, 3, 4, 6, 1, 0, 9, 4, 1, 2, 3, 7, 9, 7, 6, 7, 6, 3, 4, 9, 6, 6, 9, 0, 4, 7, 7, 8, 9, 3, 0, 3, 2, 2, 4, 3, 0, 7, 9, 6, 1, 0, 8, 3, 3, 5, 2, 1, 2, 2, 2, 7, 1, 8, 3, 5, 5, 7, 6, 2, 2, 0, 1, 7, 5, 3, 7, 0, 1, 3, 9, 4, 8, 1, 1, 4, 3, 7, 2, 7, 3, 4, 7, 1, 0, 5, 6, 9, 7, 9, 0, 5, 9, 3, 4, 4, 5, 9, 9, 9, 4, 5, 2, 7, 3, 0, 3, 3, 8, 1, 4, 8, 1, 6, 0, 1, 6, 8, 0, 7, 7, 3, 6, 1, 0, 6, 3, 9, 3, 4, 7, 5, 6, 4, 2, 2, 5, 5, 3, 9, 8, 0, 0, 6, 1, 6, 4, 4, 0, 4, 0, 5, 5, 1, 7, 1, 4, 1, 8, 4, 9]\n",
            "[8, 0, 3, 5, 7, 4, 4, 6, 5, 8, 6, 9, 3, 8, 5, 6, 1, 9, 9, 2, 7, 7, 2, 7, 2, 2, 0, 6, 7, 0, 1, 5, 6, 2, 6, 7, 5, 5, 7, 6, 9, 7, 9, 4, 1, 3, 2, 6, 1, 5, 9, 9, 7, 8, 7, 0, 5, 4, 5, 7, 6, 5, 6, 0, 4, 7, 5, 1, 0, 1, 1, 9, 4, 8, 3, 5, 1, 7, 4, 4, 2, 9, 9, 5, 1, 7, 5, 9, 6, 2, 1, 4, 1, 5, 3, 9, 7, 7, 4, 3, 2, 6, 9, 1, 3, 5, 7, 0, 3, 4, 3, 5, 9, 1, 6, 5, 7, 2, 0, 0, 5, 2, 1, 8, 4, 4, 4, 4, 2, 4, 5, 9, 3, 9, 6, 7, 4, 0, 3, 4, 8, 7, 6, 1, 8, 7, 6, 0, 3, 0, 3, 5, 3, 4, 2, 8, 8, 0, 2, 8, 3, 9, 2, 9, 7, 8, 2, 6, 1, 2, 4, 1, 3, 4, 3, 2, 0, 8, 8, 4, 6, 8, 0, 7, 0, 5, 1, 2, 2, 0, 7, 6, 4, 1, 8, 7, 8, 2, 4, 6, 0, 2, 3, 5, 0, 5, 7, 4, 1, 7, 3, 9, 9, 1, 5, 0, 2, 0, 3, 3, 6, 6, 9, 4, 8, 6, 5, 2, 9, 0, 8, 1, 9, 8, 2, 5, 6, 7, 4, 8, 3, 4, 5, 2, 6, 4, 1, 5, 0, 2, 9, 2, 7, 2, 2, 6]\n",
            "[6, 0, 1, 4, 6, 1, 0, 2, 8, 0, 6, 1, 1, 9, 5, 6, 7, 6, 2, 5, 0, 3, 8, 9, 2, 6, 2, 9, 7, 9, 3, 2, 7, 4, 1, 4, 8, 7, 8, 4, 5, 8, 5, 6, 0, 8, 9, 3, 1, 5, 4, 6, 6, 5, 1, 8, 6, 8, 3, 7, 1, 1, 3, 6, 0, 4, 5, 0, 3, 9, 9, 6, 3, 7, 4, 3, 4, 1, 7, 2, 5, 6, 4, 6, 6, 5, 9, 4, 1, 8, 2, 3, 6, 0, 7, 7, 7, 3, 5, 0, 1, 4, 6, 0, 6, 8, 5, 5, 1, 9, 2, 5, 3, 3, 3, 7, 1, 0, 2, 2, 3, 2, 9, 3, 1, 8, 0, 5, 3, 8, 5, 0, 1, 7, 8, 1, 0, 1, 2, 6, 8, 2, 7, 4, 7, 7, 0, 5, 9, 9, 6, 1, 6, 7, 7, 3, 5, 3, 9, 0, 8, 2, 5, 4, 9, 2, 6, 1, 7, 4, 9, 0, 9, 7, 1, 9, 2, 7, 4, 6, 3, 3, 9, 7, 8, 1, 1, 0, 2, 9, 2, 5, 5, 5, 6, 5, 0, 9, 5, 5, 0, 0, 1, 7, 0, 1, 6, 7, 6, 2, 2, 9, 0, 0, 5, 3, 4, 6, 4, 2, 0, 7, 1, 2, 6, 2, 2, 6, 7, 5, 0, 2, 8, 4, 0, 8, 2, 6, 5, 9, 7, 8, 9, 5, 3, 9, 1, 1, 3, 5, 9, 4, 2, 5, 0, 1]\n",
            "[4, 0, 3, 6, 6, 0, 7, 8, 9, 7, 5, 3, 8, 9, 9, 1, 1, 6, 3, 3, 4, 0, 1, 1, 7, 8, 5, 7, 6, 5, 5, 9, 5, 0, 5, 1, 5, 6, 0, 4, 8, 2, 6, 7, 9, 5, 9, 6, 9, 7, 1, 8, 8, 4, 7, 2, 3, 7, 9, 0, 0, 1, 9, 5, 3, 8, 9, 6, 4, 5, 7, 8, 5, 5, 6, 0, 6, 8, 4, 2, 2, 9, 8, 8, 7, 7, 3, 7, 2, 7, 1, 4, 6, 8, 4, 9, 5, 3, 1, 8, 6, 4, 5, 1, 6, 6, 4, 3, 3, 0, 9, 0, 3, 1, 6, 2, 6, 1, 6, 7, 6, 0, 6, 4, 8, 4, 6, 7, 4, 8, 8, 7, 4, 3, 1, 0, 8, 4, 0, 1, 8, 9, 6, 0, 6, 9, 9, 1, 9, 4, 2, 0, 9, 9, 1, 2, 4, 6, 3, 8, 1, 7, 5, 7, 2, 5, 8, 0, 0, 6, 3, 9, 3, 5, 4, 0, 3, 4, 3, 6, 7, 0, 0, 5, 8, 4, 6, 2, 2, 2, 3, 4, 6, 1, 6, 4, 4, 6, 6, 4, 0, 0, 4, 6, 4, 9, 9, 3, 5, 3, 1, 2, 1, 5, 1, 8, 4, 5, 3, 1, 9, 8, 2, 0, 2, 9, 2, 8, 3, 7, 6, 9, 6, 1, 3, 0, 1, 3, 7, 7, 9, 6, 0, 4, 5, 5, 6, 8, 3, 8, 3, 5, 7, 6, 3, 7]\n",
            "[7, 3, 4, 8, 1, 2, 8, 8, 8, 1, 5, 6, 5, 2, 5, 5, 1, 6, 6, 1, 4, 3, 0, 0, 3, 4, 2, 9, 0, 3, 2, 9, 3, 0, 6, 3, 2, 9, 6, 1, 8, 5, 7, 0, 1, 4, 1, 0, 8, 2, 9, 8, 0, 1, 4, 8, 7, 6, 3, 8, 4, 5, 0, 6, 6, 0, 5, 9, 0, 7, 4, 8, 8, 5, 9, 7, 9, 9, 1, 1, 1, 2, 0, 7, 5, 0, 2, 0, 8, 7, 1, 9, 8, 5, 2, 6, 1, 6, 9, 2, 3, 9, 8, 8, 9, 0, 2, 9, 4, 8, 5, 1, 0, 9, 0, 1, 7, 9, 4, 0, 1, 3, 9, 8, 7, 4, 5, 0, 1, 5, 8, 8, 1, 6, 9, 7, 0, 1, 7, 5, 5, 4, 6, 1, 8, 4, 9, 3, 9, 6, 9, 0, 0, 1, 2, 9, 3, 3, 2, 1, 1, 2, 9, 3, 1, 3, 5, 2, 3, 2, 5, 4, 8, 0, 5, 3, 6, 9, 3, 5, 8, 5, 6, 6, 0, 8, 9, 8, 0, 4, 1, 0, 1, 3, 1, 8, 6, 3, 1, 8, 0, 3, 8, 6, 9, 3, 1, 6, 1, 1, 6, 4, 3, 8, 6, 9, 4, 2, 8, 6, 7, 2, 7, 7, 6, 8, 3, 2, 0, 2, 0, 7, 5, 0, 9, 9, 6, 4, 5, 6, 1, 2, 0, 3, 9, 7, 6, 0, 3, 4, 1, 7, 7, 7, 1, 0]\n",
            "[0, 6, 0, 4, 5, 9, 7, 8, 2, 5, 1, 8, 8, 3, 8, 8, 9, 1, 2, 6, 6, 6, 9, 5, 3, 8, 6, 1, 3, 8, 6, 4, 3, 4, 9, 6, 0, 1, 0, 9, 7, 2, 1, 7, 5, 4, 1, 6, 0, 3, 8, 9, 9, 7, 8, 2, 5, 8, 5, 5, 2, 1, 8, 4, 1, 6, 9, 3, 9, 9, 1, 8, 7, 4, 1, 2, 2, 5, 6, 5, 8, 7, 3, 6, 1, 2, 6, 8, 1, 8, 6, 7, 4, 1, 9, 3, 4, 0, 9, 1, 1, 0, 1, 8, 1, 3, 9, 0, 2, 8, 5, 5, 0, 8, 8, 7, 7, 1, 9, 9, 0, 3, 4, 4, 6, 3, 0, 2, 4, 4, 7, 1, 4, 1, 9, 3, 8, 2, 0, 4, 7, 3, 2, 6, 7, 1, 5, 1, 1, 2, 4, 0, 0, 4, 8, 8, 5, 2, 5, 8, 5, 9, 0, 3, 2, 4, 8, 2, 0, 2, 4, 5, 1, 6, 8, 9, 1, 0, 3, 2, 6, 1, 1, 6, 8, 2, 9, 0, 0, 0, 8, 2, 4, 3, 2, 8, 2, 6, 7, 4, 6, 4, 3, 2, 0, 9, 8, 6, 4, 3, 0, 3, 0, 3, 0, 2, 9, 2, 1, 8, 4, 7, 7, 2, 7, 3, 1, 3, 7, 0, 3, 7, 2, 0, 2, 0, 7, 9, 1, 2, 0, 5, 6, 2, 3, 6, 2, 4, 9, 4, 5, 8, 9, 3, 7, 4]\n",
            "[2, 9, 4, 8, 6, 7, 0, 3, 8, 7, 1, 3, 1, 6, 5, 0, 6, 0, 1, 9, 6, 4, 0, 8, 8, 7, 4, 0, 9, 9, 6, 8, 0, 2, 4, 8, 4, 4, 1, 7, 1, 1, 9, 2, 2, 7, 6, 8, 0, 2, 9, 6, 0, 6, 9, 0, 3, 7, 7, 7, 9, 5, 0, 3, 8, 9, 8, 0, 1, 4, 6, 7, 9, 7, 7, 9, 7, 6, 2, 8, 2, 1, 4, 9, 7, 5, 8, 1, 2, 1, 1, 7, 1, 9, 3, 0, 1, 9, 9, 6, 0, 1, 8, 5, 0, 7, 4, 6, 6, 2, 9, 2, 1, 3, 5, 1, 9, 3, 8, 9, 3, 4, 1, 1, 8, 9, 9, 7, 5, 4, 1, 6, 0, 8, 2, 6, 0, 9, 0, 6, 8, 7, 2, 0, 3, 4, 7, 8, 4, 6, 0, 0, 5, 8, 2, 3, 3, 5, 1, 2, 1, 3, 8, 7, 2, 8, 2, 1, 0, 4, 4, 4, 2, 3, 6, 1, 4, 4, 1, 1, 6, 5, 7, 1, 5, 4, 1, 5, 9, 4, 3, 3, 3, 4, 0, 7, 4, 1, 3, 8, 1, 1, 6, 5, 7, 3, 9, 5, 4, 5, 6, 4, 3, 5, 7, 5, 9, 3, 8, 0, 8, 9, 6, 8, 5, 7, 9, 0, 9, 7, 2, 9, 1, 3, 8, 1, 4, 7, 3, 8, 1, 5, 7, 5, 0, 2, 7, 3, 1, 0, 1, 3, 2, 2, 2, 4]\n",
            "[0, 0, 4, 9, 5, 9, 1, 7, 0, 1, 4, 5, 8, 3, 0, 4, 0, 9, 6, 9, 0, 2, 0, 7, 3, 5, 6, 8, 2, 9, 1, 6, 1, 5, 1, 9, 1, 9, 5, 8, 9, 9, 6, 3, 8, 7, 9, 3, 3, 9, 3, 7, 1, 8, 7, 9, 3, 3, 9, 9, 0, 2, 3, 9, 4, 7, 6, 4, 3, 5, 1, 9, 7, 4, 4, 1, 5, 1, 0, 5, 9, 9, 1, 6, 5, 6, 4, 8, 3, 3, 3, 7, 9, 7, 5, 1, 2, 2, 0, 9, 9, 1, 5, 5, 7, 9, 4, 2, 1, 2, 8, 4, 0, 2, 8, 3, 2, 8, 8, 3, 4, 4, 1, 8, 1, 2, 0, 4, 4, 6, 9, 6, 1, 9, 0, 3, 5, 5, 5, 2, 8, 5, 8, 1, 4, 8, 9, 4, 4, 0, 8, 8, 2, 3, 4, 2, 7, 2, 0, 7, 6, 8, 9, 9, 0, 5, 9, 2, 3, 1, 9, 2, 9, 2, 0, 6, 9, 3, 7, 9, 7, 5, 2, 5, 8, 2, 1, 1, 2, 1, 4, 7, 4, 8, 7, 4, 9, 4, 0, 3, 9, 0, 2, 6, 1, 0, 8, 5, 5, 2, 2, 2, 1, 3, 5, 9, 3, 3, 6, 7, 3, 6, 4, 3, 8, 6, 2, 7, 9, 8, 2, 7, 3, 9, 7, 8, 1, 9, 8, 3, 8, 4, 2, 2, 6, 2, 8, 4, 2, 7, 8, 4, 6, 6, 9, 3]\n",
            "[4, 1, 0, 4, 3, 8, 2, 5, 0, 6, 1, 1, 9, 2, 7, 1, 5, 7, 3, 9, 9, 1, 3, 9, 7, 7, 2, 1, 8, 3, 8, 3, 9, 4, 2, 1, 4, 6, 7, 4, 6, 2, 6, 4, 1, 9, 7, 1, 6, 6, 3, 8, 4, 5, 8, 7, 3, 9, 8, 4, 6, 9, 0, 2, 9, 8, 1, 7, 2, 5, 3, 3, 7, 9, 3, 4, 5, 9, 9, 2, 8, 8, 6, 1, 1, 8, 9, 2, 9, 6, 8, 8, 5, 1, 8, 1, 8, 0, 6, 0, 3, 4, 3, 3, 6, 9, 3, 2, 0, 8, 3, 0, 1, 9, 6, 0, 8, 5, 1, 5, 7, 1, 3, 5, 5, 8, 0, 6, 5, 9, 6, 8, 2, 0, 7, 1, 2, 3, 1, 2, 4, 3, 8, 7, 3, 5, 0, 9, 4, 7, 2, 2, 9, 5, 9, 6, 8, 2, 2, 2, 1, 1, 2, 2, 8, 8, 5, 3, 9, 9, 0, 3, 1, 5, 3, 3, 0, 3, 8, 4, 5, 6, 0, 7, 7, 7, 6, 1, 5, 1, 2, 1, 4, 0, 4, 7, 0, 3, 7, 9, 8, 9, 6, 3, 1, 8, 8, 1, 5, 1, 0, 6, 6, 2, 5, 6, 1, 7, 1, 7, 0, 3, 3, 7, 9, 2, 0, 5, 8, 0, 1, 1, 1, 7, 7, 3, 3, 2, 4, 6, 8, 6, 5, 5, 1, 3, 5, 6, 7, 2, 1, 7, 5, 7, 4, 6]\n",
            "[7, 8, 1, 6, 3, 1, 5, 5, 9, 9, 9, 4, 6, 6, 1, 7, 8, 4, 4, 1, 3, 2, 9, 6, 8, 5, 9, 0, 2, 2, 7, 1, 3, 0, 6, 2, 6, 7, 9, 9, 3, 3, 4, 2, 1, 6, 5, 4, 0, 2, 4, 6, 2, 8, 6, 7, 3, 1, 4, 9, 5, 9, 4, 1, 5, 8, 1, 3, 5, 2, 7, 5, 2, 7, 1, 3, 4, 6, 8, 4, 4, 0, 4, 6, 4, 0, 8, 5, 9, 0, 3, 3, 3, 6, 8, 9, 0, 5, 9, 7, 6, 7, 2, 7, 7, 7, 5, 4, 5, 9, 6, 0, 2, 1, 5, 7, 9, 9, 0, 2, 0, 0, 4, 3, 6, 0, 2, 3, 2, 9, 1, 9, 2, 5, 4, 0, 9, 2, 4, 3, 1, 0, 2, 7, 6, 2, 3, 3, 7, 5, 3, 4, 0, 8, 4, 8, 7, 1, 1, 3, 5, 7, 3, 3, 3, 5, 7, 1, 7, 7, 5, 1, 5, 2, 5, 9, 8, 1, 8, 6, 7, 7, 2, 8, 3, 1, 7, 5, 4, 2, 6, 7, 3, 5, 4, 0, 7, 2, 4, 8, 2, 5, 1, 9, 8, 5, 1, 6, 3, 4, 9, 2, 6, 8, 4, 7, 1, 4, 4, 7, 6, 9, 4, 4, 2, 6, 3, 2, 7, 7, 2, 7, 1, 1, 7, 4, 0, 6, 2, 3, 9, 9, 9, 2, 7, 1, 6, 4, 1, 6, 7, 4, 6, 8, 7, 5]\n",
            "[4, 9, 2, 1, 2, 6, 6, 2, 3, 9, 3, 3, 7, 4, 8, 5, 7, 4, 5, 6, 8, 1, 3, 5, 6, 6, 2, 8, 2, 6, 8, 5, 3, 0, 0, 9, 9, 0, 1, 2, 9, 5, 3, 0, 9, 2, 7, 6, 1, 9, 7, 5, 8, 8, 0, 6, 3, 5, 3, 7, 0, 0, 4, 1, 6, 3, 1, 1, 5, 8, 4, 0, 3, 3, 1, 2, 8, 2, 7, 8, 9, 9, 7, 9, 1, 8, 8, 4, 4, 8, 7, 8, 5, 5, 2, 4, 8, 0, 3, 6, 8, 3, 4, 6, 2, 1, 1, 0, 7, 1, 5, 9, 3, 0, 5, 6, 7, 6, 1, 5, 2, 1, 3, 3, 7, 0, 8, 2, 4, 2, 5, 0, 8, 5, 9, 1, 3, 9, 5, 0, 0, 3, 6, 9, 0, 4, 9, 9, 1, 6, 2, 8, 1, 1, 4, 3, 8, 0, 2, 4, 6, 8, 5, 8, 5, 5, 6, 8, 4, 1, 2, 0, 3, 9, 6, 7, 8, 8, 9, 7, 8, 9, 6, 1, 3, 3, 4, 8, 3, 0, 1, 9, 1, 3, 0, 8, 6, 5, 4, 2, 7, 8, 3, 1, 9, 7, 8, 2, 1, 5, 0, 4, 0, 3, 5, 2, 9, 8, 1, 9, 2, 5, 2, 0, 4, 8, 3, 9, 0, 0, 6, 6, 7, 2, 7, 3, 3, 7, 9, 8, 3, 8, 8, 4, 6, 1, 8, 7, 2, 9, 6, 6, 4, 3, 8, 1]\n",
            "[4, 2, 4, 7, 5, 4, 9, 9, 2, 4, 5, 9, 4, 7, 1, 6, 6, 6, 2, 8, 4, 1, 5, 3, 3, 8, 3, 1, 2, 5, 3, 3, 6, 1, 7, 9, 7, 5, 0, 2, 5, 7, 8, 4, 7, 3, 7, 6, 6, 8, 3, 1, 4, 2, 2, 4, 9, 5, 1, 6, 6, 6, 7, 3, 8, 9, 0, 3, 4, 5, 0, 1, 6, 2, 1, 0, 9, 3, 8, 5, 5, 8, 8, 7, 0, 5, 7, 9, 5, 5, 6, 2, 2, 5, 2, 8, 5, 2, 9, 4, 3, 3, 8, 4, 4, 6, 6, 0, 4, 1, 5, 5, 1, 3, 9, 6, 2, 4, 5, 8, 1, 2, 7, 3, 6, 4, 2, 2, 4, 0, 1, 6, 6, 1, 7, 7, 2, 6, 5, 7, 4, 2, 8, 4, 4, 9, 3, 6, 1, 8, 1, 3, 9, 9, 3, 4, 2, 9, 9, 8, 3, 3, 4, 6, 9, 2, 6, 3, 3, 4, 4, 1, 1, 9, 5, 5, 1, 4, 1, 0, 0, 2, 7, 1, 1, 3, 8, 5, 2, 2, 6, 7, 8, 2, 9, 9, 6, 8, 2, 3, 6, 6, 2, 9, 0, 3, 6, 9, 5, 7, 1, 3, 7, 8, 2, 9, 7, 7, 9, 9, 5, 6, 8, 9, 1, 5, 3, 1, 8, 0, 7, 8, 0, 5, 9, 6, 8, 6, 2, 0, 6, 7, 7, 0, 5, 8, 1, 7, 1, 1, 3, 1, 7, 5, 5, 8]\n",
            "[3, 2, 3, 2, 9, 4, 6, 3, 3, 1, 5, 7, 8, 4, 8, 3, 0, 3, 4, 8, 0, 2, 8, 7, 4, 6, 3, 4, 9, 8, 6, 1, 7, 5, 9, 4, 6, 9, 2, 1, 7, 5, 7, 6, 4, 8, 6, 6, 9, 6, 5, 1, 5, 2, 6, 5, 0, 4, 1, 4, 2, 7, 8, 9, 8, 8, 0, 5, 2, 4, 9, 9, 9, 3, 3, 5, 3, 1, 0, 2, 7, 4, 1, 1, 8, 2, 7, 7, 2, 5, 0, 6, 8, 1, 5, 8, 4, 4, 8, 5, 3, 2, 1, 5, 7, 4, 4, 9, 2, 5, 8, 5, 3, 7, 7, 3, 3, 5, 7, 0, 7, 9, 4, 7, 6, 1, 9, 1, 9, 9, 7, 2, 2, 4, 7, 8, 0, 9, 4, 0, 7, 3, 5, 7, 7, 5, 9, 9, 0, 7, 8, 0, 6, 5, 5, 6, 8, 5, 4, 8, 5, 2, 8, 6, 8, 6, 7, 7, 9, 4, 4, 4, 1, 0, 6, 4, 6, 9, 5, 1, 6, 1, 7, 3, 7, 2, 6, 2, 4, 9, 8, 3, 3, 7, 6, 0, 9, 9, 1, 9, 2, 2, 6, 0, 3, 3, 6, 6, 1, 6, 1, 2, 8, 0, 0, 4, 3, 3, 7, 9, 3, 3, 5, 9, 8, 1, 8, 5, 8, 6, 2, 0, 6, 8, 0, 0, 2, 6, 5, 1, 1, 1, 8, 2, 4, 2, 8, 7, 9, 2, 9, 5, 2, 8, 2, 6]\n",
            "[5, 5, 8, 5, 8, 0, 0, 3, 2, 7, 7, 7, 8, 2, 1, 8, 1, 4, 4, 2, 7, 6, 8, 4, 7, 2, 7, 7, 5, 5, 8, 5, 5, 9, 3, 9, 7, 6, 0, 4, 5, 3, 6, 2, 4, 8, 3, 4, 5, 0, 9, 9, 0, 3, 5, 1, 1, 1, 9, 4, 8, 0, 8, 9, 2, 5, 2, 5, 8, 7, 0, 0, 2, 8, 1, 0, 4, 3, 4, 2, 5, 0, 7, 3, 6, 7, 7, 5, 3, 3, 2, 1, 6, 2, 4, 5, 6, 0, 6, 2, 1, 4, 7, 4, 0, 3, 1, 3, 5, 3, 7, 4, 0, 2, 4, 0, 2, 4, 2, 4, 3, 5, 3, 7, 6, 2, 6, 0, 1, 7, 6, 6, 4, 3, 1, 8, 2, 7, 5, 2, 5, 6, 0, 3, 0, 3, 5, 1, 5, 2, 9, 4, 3, 8, 8, 1, 5, 8, 4, 1, 5, 0, 4, 4, 1, 8, 7, 7, 4, 8, 3, 6, 3, 4, 2, 2, 8, 3, 1, 7, 3, 1, 4, 5, 4, 0, 8, 2, 8, 8, 3, 2, 8, 8, 9, 6, 3, 3, 3, 7, 1, 9, 6, 6, 7, 5, 9, 0, 2, 1, 4, 2, 4, 5, 1, 8, 6, 8, 7, 6, 2, 6, 9, 8, 9, 7, 4, 1, 4, 6, 7, 4, 5, 8, 8, 9, 7, 6, 3, 9, 8, 6, 3, 9, 0, 9, 6, 4, 2, 5, 4, 3, 5, 2, 0, 5]\n",
            "[9, 3, 9, 5, 5, 0, 0, 4, 5, 1, 9, 1, 1, 1, 4, 8, 6, 4, 4, 3, 0, 8, 5, 1, 4, 2, 4, 0, 1, 0, 3, 9, 0, 8, 8, 7, 0, 8, 8, 8, 6, 8, 5, 6, 6, 5, 9, 4, 6, 4, 2, 1, 5, 5, 2, 7, 0, 1, 0, 0, 9, 3, 2, 1, 6, 5, 7, 7, 5, 5, 2, 8, 3, 3, 2, 5, 8, 3, 3, 9, 9, 6, 4, 6, 2, 0, 4, 3, 6, 7, 5, 3, 2, 7, 7, 5, 6, 2, 3, 3, 6, 4, 6, 1, 3, 1, 7, 8, 2, 6, 6, 4, 4, 8, 6, 7, 5, 8, 5, 2, 8, 9, 8, 0, 9, 2, 9, 3, 2, 4, 0, 6, 6, 2, 4, 7, 8, 1, 3, 8, 1, 2, 7, 1, 8, 7, 9, 9, 4, 9, 4, 3, 7, 1, 2, 6, 8, 5, 1, 2, 1, 1, 0, 1, 6, 5, 2, 6, 2, 2, 3, 6, 9, 7, 4, 9, 0, 1, 1, 1, 1, 3, 5, 1, 1, 2, 3, 1, 2, 6, 1, 4, 0, 8, 0, 2, 1, 4, 4, 5, 7, 0, 8, 7, 8, 1, 3, 7, 2, 2, 2, 4, 2, 9, 2, 9, 1, 8, 2, 2, 5, 9, 4, 3, 7, 1, 0, 4, 4, 2, 9, 2, 0, 0, 5, 0, 1, 6, 0, 3, 7, 5, 0, 7, 4, 9, 9, 3, 6, 2, 4, 1, 3, 2, 3, 0]\n",
            "[0, 4, 5, 8, 7, 0, 6, 2, 0, 9, 9, 1, 5, 3, 5, 8, 9, 0, 7, 1, 5, 0, 1, 0, 0, 6, 4, 7, 7, 4, 9, 3, 8, 8, 9, 6, 7, 0, 0, 3, 3, 8, 7, 7, 4, 2, 1, 5, 7, 1, 7, 8, 2, 8, 0, 8, 3, 1, 0, 1, 5, 5, 6, 6, 6, 6, 1, 0, 8, 3, 7, 0, 5, 9, 6, 0, 2, 2, 5, 6, 1, 7, 5, 1, 7, 8, 1, 0, 4, 4, 3, 0, 2, 1, 3, 8, 3, 5, 7, 2, 8, 2, 9, 0, 9, 4, 5, 6, 7, 3, 8, 5, 2, 3, 3, 8, 8, 4, 4, 8, 8, 3, 9, 6, 1, 1, 6, 6, 4, 4, 5, 3, 2, 4, 2, 5, 9, 6, 8, 8, 5, 9, 5, 3, 0, 9, 2, 6, 3, 9, 3, 9, 6, 8, 9, 8, 3, 7, 2, 7, 7, 7, 4, 6, 7, 4, 6, 1, 8, 7, 9, 5, 8, 1, 2, 9, 3, 1, 8, 5, 1, 5, 1, 1, 8, 5, 8, 2, 2, 9, 2, 7, 5, 3, 6, 8, 8, 4, 6, 6, 1, 9, 9, 0, 0, 2, 3, 4, 7, 5, 5, 6, 9, 9, 2, 3, 9, 7, 3, 5, 6, 0, 0, 0, 7, 8, 2, 3, 6, 6, 6, 0, 7, 7, 3, 8, 1, 9, 6, 7, 9, 9, 7, 0, 1, 6, 4, 2, 4, 8, 5, 3, 8, 5, 8, 2]\n",
            "[8, 3, 2, 4, 7, 4, 2, 6, 0, 7, 5, 2, 0, 3, 4, 5, 2, 8, 9, 1, 4, 8, 8, 8, 1, 5, 2, 6, 7, 7, 4, 6, 5, 4, 6, 0, 0, 7, 9, 5, 8, 3, 6, 3, 8, 8, 3, 6, 1, 7, 9, 9, 1, 8, 8, 1, 4, 1, 9, 5, 9, 1, 9, 8, 2, 6, 2, 8, 5, 1, 7, 9, 8, 1, 6, 8, 9, 6, 1, 1, 2, 1, 8, 7, 0, 7, 9, 4, 4, 2, 6, 3, 1, 9, 3, 6, 5, 5, 5, 7, 6, 5, 0, 7, 8, 3, 5, 4, 3, 4, 3, 7, 5, 6, 2, 6, 0, 3, 4, 1, 1, 1, 2, 2, 3, 9, 8, 8, 9, 4, 9, 5, 5, 5, 2, 0, 7, 7, 4, 7, 5, 3, 3, 3, 5, 1, 9, 5, 6, 9, 6, 5, 1, 4, 8, 2, 8, 4, 6, 6, 8, 3, 3, 4, 2, 2, 8, 0, 1, 8, 0, 7, 1, 9, 3, 7, 1, 0, 4, 3, 6, 7, 8, 3, 2, 7, 7, 6, 5, 4, 7, 6, 9, 1, 6, 1, 1, 2, 4, 6, 1, 3, 1, 8, 1, 9, 4, 3, 4, 3, 5, 4, 3, 7, 9, 9, 8, 0, 8, 2, 5, 8, 9, 0, 7, 1, 7, 4, 3, 6, 8, 5, 3, 4, 2, 7, 4, 0, 8, 9, 3, 7, 7, 5, 0, 2, 5, 2, 2, 8, 2, 0, 5, 4, 9, 3]\n",
            "[3, 4, 3, 0, 1, 2, 1, 1, 8, 1, 2, 4, 7, 3, 6, 2, 4, 9, 3, 7, 3, 6, 1, 5, 2, 5, 1, 5, 6, 8, 2, 2, 2, 1, 5, 6, 3, 9, 1, 7, 8, 0, 6, 7, 4, 6, 0, 3, 8, 6, 1, 6, 4, 7, 6, 7, 3, 4, 3, 7, 4, 4, 6, 6, 9, 3, 7, 9, 9, 8, 3, 5, 4, 5, 4, 0, 0, 9, 7, 7, 5, 7, 4, 5, 4, 7, 9, 7, 1, 8, 9, 9, 5, 7, 1, 2, 0, 6, 9, 6, 5, 9, 0, 4, 8, 0, 5, 9, 3, 3, 8, 7, 0, 7, 2, 5, 4, 3, 5, 7, 0, 3, 4, 8, 1, 0, 0, 9, 9, 6, 4, 4, 5, 1, 0, 0, 9, 9, 7, 4, 7, 2, 1, 8, 4, 2, 4, 5, 6, 6, 2, 1, 1, 4, 2, 1, 8, 7, 1, 7, 8, 3, 3, 3, 0, 0, 5, 1, 2, 9, 4, 0, 0, 8, 7, 6, 6, 1, 9, 7, 2, 8, 7, 8, 2, 4, 1, 5, 2, 8, 8, 9, 8, 3, 8, 8, 3, 3, 6, 8, 3, 2, 5, 1, 4, 9, 6, 7, 8, 4, 3, 1, 8, 9, 3, 4, 5, 6, 3, 1, 9, 2, 6, 5, 1, 4, 7, 5, 0, 0, 6, 1, 0, 7, 7, 3, 8, 7, 4, 7, 7, 0, 0, 8, 1, 3, 7, 2, 1, 4, 7, 7, 1, 6, 8, 2]\n",
            "[9, 0, 0, 3, 1, 7, 6, 6, 3, 6, 1, 4, 8, 9, 7, 9, 3, 6, 2, 8, 8, 8, 2, 8, 9, 3, 8, 3, 7, 0, 0, 4, 0, 7, 7, 4, 8, 8, 2, 8, 3, 3, 1, 8, 5, 6, 1, 5, 1, 9, 3, 3, 1, 4, 7, 1, 4, 7, 3, 5, 1, 6, 4, 5, 5, 8, 2, 8, 8, 0, 5, 6, 0, 6, 0, 0, 3, 6, 2, 2, 6, 8, 1, 7, 4, 5, 3, 4, 6, 2, 7, 6, 8, 1, 2, 4, 2, 2, 3, 5, 6, 7, 5, 9, 4, 4, 6, 2, 7, 8, 5, 1, 7, 1, 6, 2, 1, 1, 2, 2, 8, 4, 0, 7, 9, 1, 7, 6, 7, 5, 2, 2, 3, 5, 2, 4, 6, 9, 4, 9, 8, 0, 9, 3, 4, 3, 4, 1, 4, 7, 5, 9, 6, 9, 9, 9, 9, 4, 1, 4, 8, 8, 5, 2, 6, 0, 2, 9, 2, 0, 8, 9, 8, 9, 9, 6, 3, 8, 2, 1, 9, 6, 0, 0, 2, 8, 4, 4, 6, 7, 5, 2, 4, 8, 0, 5, 1, 8, 9, 9, 3, 0, 6, 8, 3, 4, 5, 5, 2, 4, 6, 7, 4, 2, 2, 8, 9, 4, 0, 6, 0, 2, 1, 8, 4, 1, 7, 2, 3, 2, 1, 9, 6, 0, 2, 8, 3, 3, 9, 2, 0, 7, 7, 2, 0, 8, 6, 1, 1, 1, 6, 1, 2, 4, 8, 2]\n",
            "[0, 1, 8, 3, 5, 0, 2, 1, 8, 8, 1, 3, 7, 8, 9, 7, 9, 9, 4, 3, 5, 5, 7, 0, 0, 7, 4, 7, 0, 4, 0, 5, 0, 0, 5, 7, 6, 3, 2, 4, 8, 2, 3, 7, 2, 8, 1, 4, 1, 4, 9, 0, 7, 6, 8, 2, 1, 9, 1, 7, 0, 5, 5, 3, 6, 2, 6, 5, 0, 6, 4, 0, 1, 6, 1, 2, 6, 4, 6, 4, 9, 2, 9, 5, 9, 8, 5, 6, 0, 0, 1, 4, 9, 1, 3, 2, 2, 6, 4, 5, 1, 9, 8, 9, 6, 4, 1, 8, 2, 3, 7, 2, 3, 3, 9, 1, 6, 3, 1, 4, 2, 2, 1, 6, 7, 9, 2, 0, 0, 7, 4, 5, 4, 4, 5, 8, 6, 1, 8, 1, 8, 4, 6, 4, 1, 2, 9, 9, 6, 6, 9, 7, 6, 4, 6, 3, 9, 5, 0, 0, 6, 2, 1, 7, 6, 4, 8, 3, 4, 1, 4, 6, 1, 9, 1, 8, 0, 6, 3, 1, 2, 0, 2, 8, 6, 2, 4, 4, 7, 7, 8, 8, 3, 7, 6, 3, 5, 5, 5, 2, 7, 4, 6, 7, 3, 3, 0, 1, 3, 8, 2, 8, 0, 0, 6, 8, 3, 8, 9, 2, 1, 6, 3, 6, 9, 3, 1, 9, 7, 4, 8, 7, 9, 4, 8, 0, 3, 8, 7, 1, 3, 0, 8, 4, 4, 2, 1, 9, 5, 4, 9, 9, 3, 9, 7, 6]\n",
            "[6, 7, 5, 2, 8, 7, 2, 4, 4, 5, 7, 8, 5, 7, 6, 7, 4, 3, 0, 4, 7, 5, 8, 5, 1, 0, 0, 4, 7, 7, 0, 7, 2, 8, 8, 0, 1, 9, 5, 9, 8, 5, 4, 7, 4, 9, 8, 7, 1, 3, 6, 4, 0, 3, 7, 7, 2, 0, 2, 4, 7, 2, 2, 1, 4, 4, 6, 8, 6, 3, 0, 3, 8, 4, 6, 7, 6, 2, 1, 8, 4, 5, 2, 1, 2, 5, 7, 4, 0, 9, 9, 1, 7, 2, 1, 5, 5, 1, 8, 9, 5, 5, 3, 6, 8, 9, 5, 6, 6, 1, 7, 5, 4, 3, 8, 6, 9, 2, 1, 1, 4, 9, 5, 8, 5, 0, 6, 0, 0, 4, 2, 3, 6, 7, 4, 1, 1, 4, 1, 6, 0, 8, 6, 1, 5, 2, 2, 5, 7, 4, 6, 9, 0, 1, 9, 0, 8, 9, 4, 4, 8, 1, 3, 3, 4, 8, 9, 5, 4, 5, 6, 4, 9, 4, 7, 0, 1, 2, 0, 1, 8, 0, 6, 6, 1, 7, 3, 7, 9, 0, 9, 6, 9, 7, 3, 0, 2, 1, 7, 7, 0, 2, 1, 1, 6, 6, 7, 0, 2, 1, 8, 5, 5, 4, 8, 6, 1, 4, 0, 2, 4, 0, 1, 8, 4, 1, 0, 8, 2, 7, 4, 3, 3, 3, 1, 4, 2, 0, 6, 0, 4, 7, 9, 3, 7, 9, 9, 5, 7, 1, 3, 2, 3, 1, 7, 2]\n",
            "[7, 3, 9, 3, 7, 1, 4, 9, 3, 1, 5, 3, 8, 4, 1, 0, 9, 7, 3, 2, 3, 7, 9, 1, 7, 9, 5, 4, 7, 2, 6, 5, 6, 4, 0, 4, 8, 1, 5, 9, 9, 0, 1, 2, 2, 5, 8, 3, 4, 0, 2, 4, 2, 3, 1, 0, 8, 4, 9, 4, 0, 9, 2, 8, 5, 0, 4, 9, 1, 0, 2, 1, 7, 3, 1, 6, 4, 7, 8, 7, 8, 5, 2, 7, 7, 7, 2, 2, 8, 4, 1, 7, 5, 3, 8, 1, 6, 5, 1, 4, 8, 1, 2, 6, 1, 8, 2, 5, 9, 2, 2, 4, 0, 2, 0, 2, 9, 4, 4, 4, 7, 7, 5, 8, 9, 1, 5, 0, 6, 5, 1, 0, 0, 4, 4, 9, 2, 5, 6, 2, 9, 1, 9, 1, 8, 3, 0, 6, 4, 9, 3, 1, 4, 5, 1, 2, 2, 1, 2, 0, 5, 0, 7, 8, 8, 8, 3, 2, 2, 6, 6, 8, 7, 0, 0, 4, 9, 5, 1, 5, 3, 2, 4, 2, 2, 9, 5, 8, 2, 0, 0, 7, 5, 3, 1, 5, 0, 8, 3, 2, 2, 8, 4, 6, 3, 2, 6, 5, 0, 7, 5, 2, 0, 2, 9, 4, 5, 0, 0, 9, 4, 9, 4, 7, 9, 5, 9, 2, 1, 6, 1, 5, 7, 4, 1, 1, 5, 9, 3, 4, 4, 0, 9, 0, 4, 9, 3, 2, 3, 0, 4, 7, 5, 1, 5, 6]\n",
            "[1, 7, 0, 3, 6, 1, 4, 0, 3, 5, 3, 1, 2, 9, 5, 8, 1, 9, 7, 0, 6, 3, 1, 8, 8, 7, 2, 1, 5, 5, 0, 2, 6, 0, 1, 3, 4, 4, 9, 7, 0, 4, 4, 1, 2, 0, 3, 1, 6, 8, 1, 4, 0, 7, 2, 8, 8, 8, 8, 1, 9, 4, 0, 6, 0, 5, 5, 7, 3, 8, 3, 7, 1, 6, 9, 9, 5, 5, 0, 4, 7, 7, 8, 4, 0, 6, 3, 5, 2, 6, 0, 0, 9, 7, 9, 2, 4, 5, 0, 6, 4, 1, 2, 9, 8, 9, 7, 8, 8, 9, 1, 7, 7, 6, 7, 3, 3, 7, 0, 3, 8, 8, 6, 2, 5, 7, 4, 7, 3, 4, 1, 2, 8, 1, 4, 8, 2, 2, 5, 7, 8, 2, 6, 7, 4, 0, 3, 2, 1, 4, 3, 5, 4, 0, 7, 6, 1, 3, 9, 8, 9, 1, 7, 9, 9, 3, 0, 6, 6, 6, 2, 2, 9, 5, 2, 4, 6, 5, 3, 9, 8, 5, 1, 7, 5, 6, 8, 5, 9, 6, 8, 3, 0, 5, 8, 2, 8, 9, 2, 9, 6, 0, 5, 3, 6, 3, 8, 2, 0, 9, 9, 0, 3, 2, 4, 7, 8, 2, 3, 5, 5, 2, 6, 0, 9, 7, 6, 2, 1, 8, 4, 4, 7, 7, 8, 9, 6, 5, 8, 9, 7, 9, 4, 0, 3, 2, 6, 3, 7, 4, 9, 5, 4, 4, 1, 9]\n",
            "[2, 0, 6, 8, 3, 9, 7, 4, 7, 9, 5, 3, 8, 0, 2, 3, 4, 4, 2, 4, 8, 0, 5, 8, 1, 2, 5, 3, 1, 6, 1, 6, 1, 6, 4, 3, 9, 4, 6, 3, 1, 1, 6, 9, 3, 7, 2, 3, 5, 3, 5, 6, 0, 6, 1, 7, 2, 8, 0, 8, 3, 1, 3, 9, 2, 7, 0, 8, 0, 0, 3, 0, 6, 5, 1, 3, 6, 2, 9, 7, 5, 6, 4, 3, 6, 2, 1, 7, 3, 5, 9, 4, 3, 6, 8, 1, 1, 3, 8, 3, 4, 2, 2, 1, 1, 4, 2, 8, 1, 8, 9, 0, 8, 1, 8, 1, 9, 9, 0, 0, 4, 7, 1, 0, 8, 1, 3, 9, 9, 7, 1, 2, 9, 3, 6, 1, 8, 8, 6, 1, 9, 3, 8, 2, 5, 3, 1, 9, 0, 0, 7, 3, 5, 8, 5, 6, 3, 2, 2, 4, 4, 9, 5, 8, 8, 5, 1, 9, 6, 7, 0, 4, 4, 5, 2, 9, 2, 1, 0, 9, 7, 7, 7, 6, 0, 1, 9, 4, 0, 8, 4, 1, 3, 9, 3, 1, 0, 3, 6, 5, 7, 6, 6, 8, 1, 8, 1, 7, 3, 3, 6, 1, 2, 5, 0, 1, 2, 9, 1, 4, 1, 9, 2, 1, 7, 5, 7, 6, 3, 2, 4, 8, 7, 8, 0, 2, 1, 6, 5, 4, 0, 0, 9, 1, 7, 1, 1, 4, 8, 7, 9, 2, 9, 1, 6, 4]\n",
            "[1, 2, 2, 1, 1, 7, 3, 9, 4, 7, 9, 9, 0, 0, 4, 1, 1, 3, 8, 5, 0, 1, 4, 6, 6, 7, 8, 9, 7, 5, 2, 6, 1, 1, 3, 6, 8, 0, 2, 5, 7, 8, 5, 0, 4, 4, 4, 3, 1, 2, 9, 1, 3, 7, 6, 9, 1, 9, 3, 7, 1, 7, 1, 8, 3, 6, 0, 1, 5, 6, 6, 2, 3, 9, 7, 6, 6, 9, 7, 6, 6, 2, 4, 5, 8, 1, 2, 3, 7, 9, 5, 9, 4, 1, 0, 3, 1, 2, 7, 9, 0, 2, 4, 1, 8, 5, 4, 2, 0, 0, 2, 7, 0, 8, 0, 4, 6, 3, 4, 0, 6, 7, 1, 7, 3, 3, 1, 6, 3, 5, 9, 9, 1, 6, 1, 1, 4, 0, 9, 2, 7, 7, 3, 2, 8, 3, 0, 6, 6, 1, 6, 4, 9, 8, 7, 5, 5, 7, 5, 0, 9, 4, 1, 8, 8, 1, 1, 4, 7, 8, 6, 8, 2, 9, 8, 1, 5, 3, 2, 7, 5, 1, 0, 1, 0, 3, 3, 1, 5, 8, 8, 9, 3, 1, 3, 8, 6, 5, 1, 6, 9, 3, 8, 7, 9, 0, 8, 8, 4, 9, 5, 7, 8, 9, 8, 4, 4, 9, 1, 0, 9, 6, 7, 0, 6, 1, 3, 0, 6, 8, 2, 0, 1, 5, 6, 4, 8, 2, 5, 3, 3, 8, 1, 3, 3, 2, 0, 5, 2, 5, 1, 1, 8, 3, 9, 3]\n",
            "[4, 7, 3, 4, 7, 6, 7, 9, 7, 7, 1, 5, 9, 2, 8, 6, 7, 7, 1, 5, 4, 4, 0, 9, 7, 1, 6, 3, 0, 2, 7, 2, 7, 1, 3, 9, 4, 2, 8, 6, 8, 5, 8, 0, 5, 2, 1, 7, 3, 9, 8, 0, 9, 2, 9, 9, 6, 6, 3, 2, 6, 9, 5, 5, 4, 1, 1, 4, 6, 0, 7, 5, 8, 0, 0, 3, 9, 8, 1, 0, 9, 2, 6, 2, 0, 2, 8, 2, 0, 7, 9, 7, 5, 1, 1, 5, 7, 7, 7, 3, 4, 1, 0, 6, 9, 9, 6, 9, 1, 5, 4, 5, 8, 9, 9, 1, 1, 7, 9, 1, 7, 7, 6, 5, 8, 2, 7, 1, 3, 6, 8, 5, 2, 7, 1, 4, 0, 8, 5, 8, 5, 1, 3, 4, 5, 5, 2, 1, 3, 5, 2, 2, 9, 4, 4, 9, 5, 9, 1, 3, 2, 9, 6, 2, 2, 0, 7, 5, 7, 3, 2, 9, 4, 6, 2, 9, 2, 2, 8, 1, 0, 0, 9, 0, 6, 2, 4, 1, 0, 4, 3, 1, 1, 4, 9, 0, 8, 2, 9, 5, 0, 2, 3, 0, 7, 2, 2, 2, 0, 1, 1, 1, 7, 6, 1, 7, 7, 8, 6, 5, 0, 9, 1, 0, 2, 3, 4, 9, 9, 2, 6, 5, 0, 5, 3, 7, 3, 3, 4, 4, 7, 8, 1, 9, 3, 4, 5, 2, 7, 4, 3, 5, 7, 4, 1, 8]\n",
            "[4, 3, 7, 6, 2, 3, 0, 7, 1, 4, 3, 9, 9, 1, 7, 5, 6, 8, 4, 1, 1, 5, 2, 2, 2, 8, 4, 0, 7, 6, 4, 3, 2, 3, 1, 7, 6, 7, 6, 8, 9, 0, 7, 3, 6, 9, 6, 9, 4, 6, 9, 5, 9, 7, 1, 5, 9, 3, 2, 7, 6, 7, 8, 1, 6, 1, 8, 9, 7, 7, 1, 6, 0, 5, 8, 5, 7, 1, 4, 7, 2, 1, 7, 6, 6, 2, 4, 2, 3, 5, 5, 2, 9, 0, 2, 8, 3, 7, 8, 2, 0, 7, 2, 7, 2, 9, 1, 2, 0, 2, 9, 3, 0, 6, 2, 8, 0, 3, 7, 4, 1, 4, 0, 3, 1, 4, 5, 7, 9, 3, 1, 9, 5, 0, 4, 7, 2, 2, 1, 9, 5, 7, 2, 6, 2, 6, 7, 7, 8, 0, 5, 2, 7, 0, 2, 0, 2, 0, 2, 4, 2, 5, 9, 2, 3, 2, 7, 5, 1, 4, 2, 5, 6, 1, 9, 8, 8, 9, 4, 5, 5, 8, 8, 6, 8, 6, 5, 0, 0, 6, 9, 5, 4, 4, 1, 2, 2, 2, 1, 7, 7, 8, 0, 0, 1, 6, 5, 4, 2, 0, 2, 5, 7, 8, 5, 3, 4, 4, 9, 4, 4, 6, 6, 4, 0, 3, 9, 1, 3, 2, 4, 0, 0, 1, 1, 7, 6, 2, 5, 1, 2, 7, 5, 1, 8, 0, 1, 5, 7, 8, 5, 9, 1, 2, 7, 7]\n",
            "[0, 0, 1, 7, 3, 0, 3, 1, 4, 1, 3, 8, 3, 7, 3, 9, 1, 7, 7, 1, 2, 6, 5, 8, 0, 3, 2, 0, 6, 5, 4, 6, 7, 0, 3, 4, 6, 3, 5, 2, 7, 7, 5, 5, 4, 9, 0, 3, 1, 5, 3, 1, 2, 0, 2, 4, 8, 9, 4, 2, 9, 2, 5, 9, 5, 3, 4, 2, 6, 6, 5, 8, 9, 9, 7, 7, 7, 7, 4, 4, 8, 8, 7, 6, 1, 4, 4, 9, 0, 9, 6, 7, 2, 9, 4, 1, 9, 6, 7, 5, 7, 6, 0, 6, 9, 9, 9, 4, 2, 5, 5, 3, 0, 3, 6, 1, 8, 4, 6, 2, 7, 2, 7, 9, 9, 3, 4, 7, 1, 7, 6, 6, 1, 5, 0, 1, 3, 0, 1, 3, 2, 6, 5, 3, 4, 3, 9, 9, 3, 3, 0, 7, 5, 9, 6, 6, 4, 6, 9, 7, 3, 6, 1, 6, 8, 6, 7, 7, 1, 6, 0, 4, 2, 2, 5, 8, 9, 1, 9, 2, 3, 3, 7, 9, 1, 5, 7, 1, 8, 8, 5, 6, 7, 6, 0, 7, 6, 3, 1, 0, 7, 9, 5, 7, 8, 1, 0, 9, 9, 4, 0, 0, 7, 7, 4, 4, 7, 1, 5, 7, 1, 3, 3, 0, 0, 9, 1, 7, 0, 2, 0, 1, 5, 0, 3, 7, 9, 2, 4, 4, 9, 8, 2, 0, 4, 3, 6, 1, 9, 4, 8, 9, 6, 8, 9, 4]\n",
            "[9, 8, 8, 9, 2, 3, 8, 6, 5, 4, 5, 0, 1, 9, 0, 5, 8, 5, 1, 5, 4, 8, 2, 5, 9, 5, 1, 1, 8, 8, 0, 8, 4, 1, 9, 3, 2, 0, 2, 4, 4, 0, 6, 0, 1, 9, 9, 9, 4, 1, 4, 9, 1, 6, 5, 1, 1, 3, 1, 7, 4, 6, 3, 9, 5, 7, 7, 5, 4, 8, 5, 5, 2, 4, 8, 8, 3, 1, 1, 3, 2, 9, 0, 4, 9, 4, 9, 0, 5, 3, 1, 4, 2, 0, 4, 1, 0, 7, 1, 9, 4, 8, 1, 4, 7, 8, 8, 1, 5, 4, 3, 0, 5, 9, 5, 9, 5, 0, 9, 5, 1, 7, 8, 8, 7, 2, 1, 9, 9, 6, 3, 8, 8, 7, 9, 7, 6, 3, 3, 5, 3, 2, 0, 1, 8, 1, 1, 9, 1, 3, 0, 6, 2, 0, 0, 6, 9, 0, 1, 7, 3, 2, 6, 7, 7, 7, 7, 2, 2, 8, 1, 0, 9, 0, 2, 0, 7, 3, 7, 4, 5, 7, 5, 1, 1, 6, 7, 6, 7, 2, 6, 1, 0, 8, 2, 9, 8, 4, 5, 2, 6, 2, 1, 9, 3, 1, 1, 6, 3, 8, 3, 6, 7, 6, 0, 9, 6, 2, 9, 6, 0, 5, 8, 0, 1, 0, 8, 7, 2, 9, 6, 4, 0, 2, 4, 1, 2, 0, 1, 4, 7, 6, 6, 9, 1, 7, 0, 7, 1, 1, 8, 8, 5, 2, 9, 1]\n",
            "[3, 0, 0, 7, 5, 9, 0, 3, 2, 6, 7, 5, 3, 2, 1, 9, 4, 6, 5, 9, 1, 8, 8, 8, 1, 8, 8, 3, 4, 1, 5, 6, 2, 1, 8, 6, 4, 6, 3, 6, 8, 1, 5, 0, 5, 0, 0, 9, 8, 1, 9, 0, 8, 8, 4, 2, 5, 4, 3, 1, 4, 2, 3, 4, 5, 0, 0, 3, 0, 6, 6, 1, 9, 1, 4, 9, 8, 2, 0, 4, 1, 5, 6, 4, 9, 4, 1, 0, 4, 1, 7, 0, 7, 3, 6, 7, 9, 6, 2, 6, 8, 5, 0, 8, 3, 1, 0, 2, 2, 5, 5, 1, 8, 1, 9, 1, 6, 9, 9, 9, 3, 2, 0, 7, 3, 1, 6, 2, 3, 8, 5, 1, 6, 7, 9, 3, 9, 5, 5, 5, 4, 3, 9, 4, 0, 3, 7, 8, 5, 3, 1, 5, 0, 7, 9, 0, 4, 0, 0, 4, 8, 5, 1, 8, 9, 0, 0, 7, 4, 5, 8, 6, 9, 4, 7, 7, 1, 6, 8, 3, 4, 7, 6, 3, 0, 1, 9, 6, 5, 3, 9, 2, 3, 0, 1, 2, 8, 9, 8, 3, 9, 3, 3, 8, 9, 2, 7, 9, 2, 9, 7, 5, 2, 4, 8, 5, 7, 4, 5, 9, 4, 7, 5, 6, 0, 3, 6, 5, 0, 4, 8, 3, 9, 2, 7, 0, 7, 7, 3, 9, 3, 2, 0, 6, 2, 4, 0, 1, 4, 0, 6, 7, 0, 0, 5, 5]\n",
            "[2, 1, 3, 7, 1, 2, 6, 3, 8, 7, 0, 2, 9, 5, 4, 2, 3, 2, 8, 0, 0, 7, 7, 3, 3, 5, 8, 2, 7, 8, 9, 5, 1, 1, 3, 6, 1, 2, 7, 5, 2, 2, 1, 3, 7, 3, 7, 5, 6, 9, 7, 4, 9, 0, 8, 8, 6, 7, 1, 5, 7, 4, 9, 0, 9, 3, 6, 1, 7, 2, 4, 3, 3, 9, 7, 3, 6, 0, 0, 1, 3, 0, 5, 2, 8, 9, 7, 5, 2, 5, 8, 0, 9, 7, 6, 7, 6, 2, 3, 3, 7, 7, 3, 2, 0, 3, 4, 6, 8, 2, 8, 1, 1, 6, 9, 3, 1, 8, 1, 8, 3, 0, 6, 3, 2, 4, 3, 9, 2, 0, 9, 5, 9, 5, 2, 7, 5, 8, 0, 3, 1, 9, 1, 0, 1, 9, 5, 9, 2, 2, 2, 1, 5, 9, 2, 2, 6, 8, 3, 9, 1, 9, 1, 0, 3, 2, 9, 7, 4, 4, 2, 2, 6, 1, 1, 9, 1, 5, 2, 8, 3, 0, 5, 6, 8, 3, 6, 2, 7, 9, 0, 8, 5, 7, 4, 6, 9, 8, 3, 7, 5, 2, 7, 6, 6, 7, 7, 8, 6, 2, 3, 8, 9, 8, 8, 7, 3, 5, 2, 8, 8, 8, 0, 6, 6, 0, 0, 0, 1, 0, 6, 3, 4, 2, 0, 6, 2, 0, 9, 8, 1, 6, 7, 5, 1, 9, 1, 8, 9, 0, 8, 1, 2, 4, 8, 5]\n",
            "[1, 5, 3, 6, 1, 4, 2, 6, 7, 5, 5, 4, 2, 7, 5, 5, 2, 4, 3, 1, 9, 5, 6, 1, 7, 1, 3, 4, 6, 7, 9, 7, 1, 3, 0, 1, 8, 5, 2, 1, 1, 9, 4, 9, 3, 4, 1, 5, 3, 0, 1, 0, 6, 7, 3, 7, 5, 0, 7, 7, 7, 7, 1, 4, 4, 6, 9, 9, 5, 7, 1, 8, 8, 9, 4, 1, 6, 7, 3, 4, 4, 8, 3, 2, 7, 4, 9, 1, 9, 0, 4, 8, 6, 3, 5, 3, 7, 1, 5, 7, 9, 7, 0, 3, 1, 7, 2, 7, 0, 1, 5, 2, 6, 7, 5, 7, 4, 6, 7, 2, 8, 2, 9, 6, 6, 5, 9, 7, 8, 2, 4, 9, 5, 4, 4, 9, 6, 7, 1, 8, 6, 0, 3, 2, 7, 5, 9, 5, 2, 3, 5, 5, 7, 9, 7, 9, 2, 2, 8, 5, 2, 7, 5, 0, 1, 1, 8, 0, 8, 5, 6, 3, 0, 8, 4, 9, 6, 4, 1, 0, 9, 3, 3, 4, 2, 8, 1, 1, 6, 5, 1, 2, 7, 8, 6, 2, 8, 7, 8, 9, 7, 7, 0, 2, 3, 0, 8, 9, 8, 4, 4, 3, 9, 7, 7, 9, 3, 3, 3, 3, 8, 0, 6, 2, 7, 7, 2, 5, 2, 7, 8, 0, 5, 3, 4, 4, 3, 2, 5, 2, 0, 9, 7, 2, 6, 1, 0, 4, 5, 3, 2, 7, 4, 4, 4, 6]\n",
            "[4, 7, 9, 2, 1, 8, 8, 3, 5, 2, 9, 1, 2, 7, 1, 4, 4, 6, 5, 7, 2, 6, 4, 9, 1, 6, 9, 0, 9, 8, 1, 1, 0, 0, 9, 6, 1, 1, 4, 0, 7, 3, 2, 1, 0, 3, 2, 3, 9, 7, 4, 0, 7, 5, 5, 4, 1, 4, 8, 7, 0, 0, 3, 1, 0, 6, 1, 1, 7, 7, 6, 8, 0, 5, 5, 9, 2, 2, 5, 9, 8, 5, 2, 9, 8, 6, 7, 1, 0, 7, 8, 5, 1, 9, 1, 3, 1, 8, 2, 5, 3, 4, 7, 3, 4, 5, 7, 0, 5, 6, 8, 3, 3, 4, 6, 3, 1, 3, 7, 1, 8, 1, 1, 9, 4, 1, 3, 6, 1, 2, 1, 5, 2, 7, 2, 6, 1, 8, 9, 4, 7, 1, 6, 6, 7, 4, 0, 2, 3, 3, 1, 7, 6, 0, 7, 8, 7, 8, 2, 3, 2, 6, 7, 2, 9, 8, 7, 6, 1, 6, 0, 3, 6, 4, 4, 9, 4, 7, 1, 5, 9, 9, 2, 6, 9, 1, 1, 9, 9, 4, 2, 7, 9, 2, 7, 2, 7, 8, 8, 6, 3, 6, 7, 6, 2, 1, 9, 8, 1, 2, 0, 8, 5, 9, 5, 9, 5, 1, 5, 1, 7, 3, 8, 4, 8, 5, 2, 9, 7, 7, 3, 1, 1, 8, 9, 1, 0, 3, 8, 4, 0, 0, 7, 4, 5, 3, 7, 9, 2, 1, 2, 2, 3, 4, 4, 7]\n",
            "[1, 7, 3, 3, 7, 7, 2, 9, 2, 4, 2, 0, 9, 5, 8, 2, 1, 3, 9, 5, 2, 0, 2, 4, 0, 9, 6, 5, 9, 1, 1, 9, 5, 0, 4, 5, 9, 5, 2, 0, 8, 6, 8, 9, 8, 2, 9, 5, 8, 0, 6, 0, 9, 9, 9, 7, 3, 4, 7, 8, 1, 4, 6, 7, 7, 0, 3, 1, 8, 4, 3, 2, 9, 6, 6, 7, 6, 4, 9, 4, 9, 8, 1, 3, 7, 7, 1, 8, 6, 9, 0, 7, 0, 3, 4, 0, 2, 0, 2, 7, 2, 8, 0, 9, 1, 4, 2, 0, 5, 1, 0, 6, 3, 5, 7, 9, 6, 6, 5, 1, 0, 3, 6, 4, 4, 4, 7, 9, 5, 3, 7, 7, 8, 4, 0, 4, 9, 6, 3, 9, 6, 6, 0, 9, 9, 4, 1, 9, 2, 8, 4, 5, 1, 3, 8, 1, 5, 6, 2, 2, 3, 6, 9, 4, 1, 2, 1, 6, 6, 5, 3, 0, 1, 7, 1, 4, 1, 9, 0, 2, 7, 8, 1, 4, 7, 7, 7, 3, 2, 5, 7, 6, 0, 3, 4, 7, 7, 9, 4, 2, 5, 0, 6, 7, 6, 0, 7, 4, 9, 0, 2, 9, 3, 2, 4, 8, 2, 1, 0, 7, 3, 3, 2, 1, 4, 0, 2, 7, 8, 6, 8, 1, 3, 1, 9, 1, 3, 9, 2, 6, 1, 1, 1, 7, 9, 6, 4, 6, 4, 0, 4, 6, 0, 5, 2, 7]\n",
            "[1, 3, 3, 3, 2, 4, 2, 6, 8, 8, 3, 4, 5, 3, 1, 6, 4, 5, 0, 6, 5, 1, 7, 8, 5, 1, 1, 8, 4, 8, 1, 9, 6, 9, 1, 5, 2, 4, 3, 8, 0, 8, 1, 9, 6, 9, 7, 4, 8, 2, 3, 2, 5, 5, 9, 1, 4, 8, 9, 4, 7, 9, 6, 3, 9, 7, 8, 2, 8, 1, 7, 1, 0, 4, 8, 8, 1, 4, 7, 0, 8, 4, 0, 5, 8, 6, 0, 7, 7, 5, 5, 6, 1, 4, 8, 0, 0, 3, 6, 1, 6, 0, 7, 2, 9, 1, 6, 9, 7, 5, 4, 3, 8, 4, 2, 2, 8, 6, 2, 8, 8, 1, 5, 4, 9, 1, 0, 2, 2, 0, 6, 1, 3, 5, 9, 0, 8, 0, 8, 9, 4, 4, 7, 9, 1, 7, 9, 8, 8, 7, 9, 8, 1, 2, 7, 4, 5, 3, 0, 5, 7, 4, 3, 1, 3, 0, 9, 8, 9, 6, 4, 1, 0, 6, 0, 1, 1, 0, 3, 4, 2, 2, 1, 9, 1, 1, 6, 4, 2, 1, 0, 7, 8, 1, 1, 4, 8, 4, 3, 7, 8, 7, 9, 9, 0, 1, 9, 1, 6, 0, 1, 4, 7, 8, 0, 2, 9, 3, 8, 1, 1, 2, 6, 7, 7, 0, 4, 5, 2, 1, 3, 1, 2, 1, 3, 9, 0, 8, 1, 4, 0, 8, 6, 0, 8, 2, 0, 0, 5, 7, 4, 6, 1, 1, 4, 3]\n",
            "[5, 9, 8, 7, 6, 8, 5, 2, 0, 3, 8, 8, 2, 0, 2, 4, 7, 2, 4, 2, 7, 8, 3, 7, 2, 8, 0, 5, 8, 7, 9, 7, 0, 9, 4, 2, 0, 7, 6, 3, 5, 1, 7, 7, 8, 2, 4, 6, 2, 3, 9, 3, 2, 9, 1, 5, 9, 8, 5, 9, 7, 6, 1, 7, 6, 3, 0, 4, 3, 8, 4, 7, 3, 6, 1, 5, 0, 5, 1, 6, 3, 9, 0, 1, 2, 0, 6, 7, 2, 0, 1, 2, 2, 2, 7, 6, 4, 0, 3, 7, 4, 2, 1, 1, 2, 9, 0, 0, 7, 3, 3, 2, 1, 7, 9, 0, 5, 1, 2, 6, 7, 4, 2, 2, 6, 1, 1, 4, 4, 1, 4, 3, 4, 8, 1, 7, 5, 7, 0, 8, 6, 1, 3, 0, 7, 3, 7, 1, 1, 7, 6, 9, 4, 3, 6, 0, 6, 2, 9, 2, 6, 1, 9, 1, 7, 0, 7, 3, 5, 3, 0, 7, 9, 8, 2, 6, 3, 9, 6, 4, 1, 2, 6, 6, 4, 1, 7, 1, 4, 8, 0, 9, 8, 9, 7, 4, 1, 5, 0, 2, 1, 8, 7, 3, 2, 6, 4, 8, 3, 1, 6, 9, 8, 2, 7, 0, 1, 9, 3, 7, 7, 7, 7, 9, 5, 2, 3, 6, 6, 0, 2, 9, 3, 7, 2, 1, 3, 8, 6, 7, 2, 0, 1, 8, 2, 5, 1, 9, 3, 6, 8, 8, 1, 1, 3, 1]\n",
            "[7, 9, 4, 1, 8, 1, 6, 6, 4, 1, 2, 6, 9, 3, 3, 1, 0, 5, 2, 8, 3, 5, 2, 4, 8, 6, 1, 1, 5, 5, 8, 7, 4, 7, 2, 0, 9, 7, 8, 1, 7, 9, 2, 1, 2, 1, 6, 4, 3, 1, 6, 9, 2, 2, 0, 1, 1, 0, 4, 6, 4, 8, 0, 9, 1, 4, 0, 2, 8, 5, 7, 2, 7, 3, 1, 8, 5, 2, 4, 8, 0, 4, 1, 6, 4, 8, 2, 6, 2, 4, 7, 9, 4, 7, 6, 8, 0, 2, 4, 8, 3, 1, 0, 8, 7, 5, 4, 0, 3, 8, 3, 4, 4, 6, 8, 6, 4, 0, 2, 6, 9, 8, 0, 3, 4, 3, 0, 8, 9, 1, 7, 1, 3, 0, 8, 4, 7, 0, 2, 6, 1, 3, 6, 0, 4, 6, 6, 7, 6, 1, 0, 9, 9, 0, 2, 8, 9, 3, 6, 1, 6, 2, 3, 7, 5, 8, 8, 3, 3, 0, 9, 6, 2, 7, 0, 9, 9, 1, 2, 6, 6, 1, 4, 8, 8, 9, 8, 9, 7, 1, 6, 2, 2, 9, 8, 8, 0, 1, 0, 0, 2, 4, 4, 9, 1, 0, 1, 6, 2, 5, 6, 8, 7, 6, 8, 0, 4, 7, 6, 7, 1, 5, 4, 7, 2, 7, 7, 7, 2, 3, 4, 4, 8, 0, 6, 6, 9, 4, 5, 2, 4, 6, 8, 1, 6, 9, 6, 5, 6, 2, 7, 6, 9, 6, 7, 1]\n",
            "[6, 8, 3, 7, 7, 8, 4, 4, 6, 1, 6, 0, 1, 8, 3, 1, 1, 7, 9, 3, 6, 8, 5, 2, 9, 1, 4, 8, 4, 5, 9, 6, 6, 5, 1, 3, 0, 1, 4, 2, 1, 5, 5, 0, 7, 3, 9, 2, 8, 8, 4, 8, 6, 7, 4, 6, 0, 7, 2, 8, 4, 3, 8, 1, 3, 9, 1, 0, 9, 5, 8, 0, 7, 1, 4, 7, 8, 7, 8, 3, 5, 0, 4, 4, 5, 3, 4, 9, 7, 1, 3, 5, 2, 5, 7, 0, 1, 2, 7, 9, 5, 8, 1, 1, 8, 0, 1, 6, 5, 1, 7, 5, 1, 5, 7, 5, 0, 9, 5, 7, 4, 2, 7, 3, 1, 8, 6, 3, 6, 5, 1, 6, 9, 7, 6, 2, 3, 1, 7, 9, 9, 5, 2, 2, 4, 0, 7, 6, 6, 1, 1, 1, 8, 7, 1, 7, 2, 7, 9, 2, 2, 4, 0, 0, 1, 2, 4, 9, 2, 7, 4, 2, 9, 8, 2, 4, 3, 4, 8, 8, 3, 4, 3, 3, 7, 6, 8, 5, 2, 9, 9, 1, 1, 3, 3, 0, 6, 4, 3, 8, 5, 0, 3, 9, 1, 1, 6, 4, 2, 9, 2, 3, 6, 4, 1, 9, 0, 3, 8, 5, 1, 5, 4, 3, 8, 1, 5, 0, 8, 3, 2, 9, 0, 9, 0, 9, 0, 0, 9, 4, 3, 1, 7, 7, 4, 0, 2, 6, 2, 4, 0, 1, 3, 0, 7, 8]\n",
            "[9, 9, 7, 1, 5, 2, 4, 8, 7, 1, 1, 6, 2, 3, 2, 8, 8, 9, 5, 9, 4, 4, 6, 2, 9, 7, 9, 5, 0, 6, 3, 0, 1, 5, 4, 8, 9, 9, 9, 4, 5, 3, 7, 3, 9, 7, 5, 0, 4, 4, 2, 9, 0, 8, 2, 3, 2, 2, 1, 7, 6, 3, 6, 9, 7, 2, 3, 4, 6, 6, 4, 5, 8, 1, 4, 4, 1, 3, 0, 6, 7, 6, 1, 1, 2, 6, 9, 8, 6, 9, 1, 0, 7, 5, 1, 9, 3, 1, 3, 8, 0, 8, 7, 2, 6, 2, 7, 8, 0, 1, 2, 4, 8, 2, 7, 0, 0, 3, 4, 7, 2, 9, 3, 8, 5, 1, 7, 9, 3, 3, 2, 5, 0, 1, 3, 5, 2, 8, 9, 4, 9, 2, 4, 1, 4, 1, 4, 6, 0, 8, 4, 9, 1, 6, 4, 9, 0, 1, 4, 7, 9, 3, 9, 9, 4, 4, 5, 6, 0, 0, 7, 7, 0, 6, 8, 1, 8, 8, 1, 4, 7, 4, 2, 9, 1, 5, 4, 7, 6, 7, 4, 2, 3, 9, 7, 1, 6, 5, 5, 1, 3, 7, 4, 1, 5, 8, 5, 6, 5, 0, 0, 8, 3, 9, 0, 5, 4, 6, 7, 4, 6, 9, 6, 4, 7, 8, 8, 0, 5, 2, 4, 6, 0, 6, 6, 5, 0, 5, 1, 5, 7, 7, 3, 7, 0, 3, 0, 3, 5, 3, 8, 7, 6, 0, 9, 3]\n",
            "[5, 0, 2, 7, 6, 6, 4, 7, 8, 7, 1, 1, 2, 9, 6, 1, 0, 2, 2, 8, 1, 3, 5, 2, 5, 9, 8, 8, 6, 6, 5, 0, 1, 6, 9, 5, 2, 7, 2, 3, 4, 1, 8, 9, 4, 0, 7, 2, 1, 0, 9, 5, 6, 8, 0, 3, 5, 7, 5, 5, 8, 7, 2, 3, 6, 1, 1, 9, 5, 3, 1, 3, 3, 6, 8, 3, 5, 0, 7, 1, 5, 8, 5, 6, 6, 1, 3, 2, 8, 1, 1, 9, 8, 5, 9, 5, 5, 1, 7, 1, 1, 6, 5, 7, 2, 3, 3, 5, 7, 3, 9, 2, 3, 5, 1, 6, 8, 7, 7, 0, 3, 6, 7, 1, 9, 6, 3, 7, 0, 6, 9, 4, 2, 1, 1, 2, 9, 8, 3, 2, 0, 2, 3, 7, 6, 9, 6, 6, 6, 4, 6, 1, 0, 2, 3, 0, 4, 7, 6, 8, 8, 7, 2, 6, 3, 2, 2, 4, 7, 0, 0, 1, 0, 0, 0, 3, 8, 1, 8, 0, 1, 9, 3, 0, 9, 5, 5, 5, 5, 1, 3, 8, 7, 3, 2, 0, 6, 6, 6, 7, 4, 1, 7, 5, 2, 1, 4, 7, 2, 4, 0, 6, 4, 4, 5, 1, 5, 8, 8, 7, 7, 7, 1, 5, 4, 6, 7, 2, 7, 1, 5, 9, 9, 7, 8, 2, 1, 8, 6, 6, 1, 4, 1, 0, 0, 2, 1, 2, 8, 9, 7, 2, 9, 5, 7, 0]\n",
            "[8, 0, 0, 0, 7, 3, 5, 4, 1, 4, 0, 2, 0, 0, 2, 2, 8, 3, 5, 6, 8, 7, 2, 4, 3, 9, 6, 4, 9, 5, 6, 1, 2, 3, 1, 1, 2, 2, 3, 2, 7, 0, 6, 9, 0, 1, 0, 8, 8, 6, 4, 2, 0, 9, 9, 6, 1, 6, 7, 9, 0, 1, 3, 1, 2, 7, 8, 9, 1, 9, 1, 0, 7, 6, 5, 0, 5, 3, 5, 5, 8, 7, 3, 3, 2, 3, 3, 6, 6, 3, 1, 1, 4, 6, 8, 5, 6, 9, 5, 4, 1, 6, 7, 0, 2, 0, 8, 1, 7, 5, 2, 8, 3, 3, 1, 1, 3, 2, 0, 8, 1, 6, 8, 3, 0, 3, 0, 4, 2, 4, 8, 1, 3, 2, 3, 6, 5, 8, 3, 7, 0, 1, 9, 8, 0, 8, 0, 5, 6, 1, 4, 8, 7, 1, 3, 4, 0, 3, 6, 3, 0, 3, 8, 4, 5, 8, 1, 2, 0, 4, 9, 3, 3, 3, 7, 3, 5, 3, 1, 6, 0, 5, 9, 5, 1, 5, 5, 6, 9, 7, 0, 1, 1, 6, 8, 5, 9, 0, 6, 5, 0, 8, 2, 1, 3, 0, 5, 6, 5, 6, 1, 8, 0, 0, 5, 9, 7, 9, 5, 2, 2, 9, 4, 8, 8, 3, 4, 7, 4, 8, 5, 3, 7, 7, 1, 6, 7, 2, 0, 1, 2, 2, 3, 5, 6, 1, 7, 7, 9, 3, 4, 2, 8, 0, 6, 8]\n",
            "[9, 8, 7, 8, 7, 2, 7, 1, 0, 9, 6, 3, 7, 5, 7, 2, 5, 5, 6, 6, 4, 8, 5, 7, 6, 6, 2, 6, 4, 1, 4, 5, 6, 2, 1, 6, 6, 1, 5, 8, 0, 7, 4, 6, 4, 6, 3, 1, 1, 6, 6, 9, 3, 9, 2, 6, 5, 9, 5, 7, 5, 3, 9, 6, 6, 8, 6, 5, 9, 6, 0, 6, 2, 4, 6, 2, 2, 9, 4, 6, 0, 7, 5, 3, 0, 5, 1, 3, 1, 8, 8, 9, 8, 4, 1, 4, 2, 3, 8, 8, 7, 1, 4, 1, 0, 0, 5, 0, 7, 9, 9, 2, 1, 6, 4, 4, 9, 1, 3, 8, 4, 0, 4, 5, 0, 4, 1, 6, 3, 4, 1, 5, 9, 1, 7, 5, 8, 2, 3, 5, 9, 8, 9, 2, 4, 6, 1, 9, 9, 0, 1, 4, 1, 7, 1, 5, 1, 1, 4, 5, 6, 7, 3, 5, 2, 0, 1, 7, 1, 6, 8, 6, 7, 7, 3, 8, 8, 7, 7, 1, 3, 2, 0, 5, 0, 4, 2, 8, 6, 4, 7, 8, 9, 4, 1, 7, 1, 4, 0, 5, 3, 6, 6, 0, 6, 8, 1, 1, 9, 8, 2, 0, 2, 7, 0, 3, 6, 1, 6, 6, 1, 2, 1, 0, 1, 3, 0, 5, 8, 2, 7, 6, 2, 1, 4, 0, 8, 1, 3, 1, 6, 1, 9, 6, 2, 8, 0, 2, 0, 0, 6, 3, 4, 8, 4, 0]\n",
            "[0, 5, 4, 0, 2, 8, 4, 0, 5, 6, 6, 8, 1, 2, 4, 4, 7, 2, 1, 5, 2, 6, 6, 3, 8, 8, 1, 8, 1, 5, 5, 0, 1, 9, 9, 9, 5, 3, 7, 7, 9, 8, 2, 3, 4, 8, 5, 4, 0, 7, 2, 1, 4, 4, 7, 3, 9, 7, 4, 5, 5, 4, 0, 2, 2, 6, 7, 5, 3, 7, 6, 1, 2, 8, 2, 0, 8, 9, 9, 6, 5, 4, 9, 6, 5, 1, 6, 2, 7, 9, 7, 6, 4, 1, 6, 3, 9, 2, 6, 1, 8, 8, 4, 0, 6, 9, 5, 9, 5, 6, 3, 3, 2, 0, 4, 2, 9, 4, 1, 3, 4, 7, 4, 5, 9, 4, 7, 7, 8, 6, 4, 4, 0, 0, 0, 7, 7, 0, 7, 0, 6, 0, 0, 0, 1, 5, 4, 6, 8, 5, 5, 4, 9, 1, 3, 1, 0, 2, 6, 5, 4, 2, 1, 9, 6, 7, 7, 8, 3, 8, 4, 4, 9, 3, 0, 7, 1, 1, 0, 5, 6, 8, 1, 0, 3, 3, 1, 2, 9, 9, 5, 1, 7, 3, 7, 7, 2, 7, 6, 6, 5, 3, 8, 1, 1, 1, 3, 4, 6, 6, 1, 5, 7, 4, 6, 8, 1, 7, 1, 5, 9, 0, 6, 3, 1, 2, 8, 3, 9, 8, 3, 9, 7, 2, 8, 4, 3, 9, 1, 1, 3, 1, 7, 5, 0, 2, 4, 5, 8, 4, 2, 8, 2, 5, 2, 3]\n",
            "[5, 7, 6, 8, 8, 5, 8, 1, 9, 9, 8, 7, 1, 9, 7, 8, 6, 6, 2, 1, 7, 3, 1, 5, 1, 6, 2, 0, 2, 0, 0, 2, 3, 4, 9, 0, 8, 6, 5, 8, 5, 0, 2, 7, 4, 4, 2, 1, 3, 4, 4, 5, 3, 8, 0, 1, 2, 0, 1, 8, 7, 0, 4, 3, 2, 3, 2, 3, 0, 3, 9, 3, 0, 3, 4, 9, 8, 7, 8, 4, 7, 9, 7, 6, 9, 6, 4, 7, 6, 1, 1, 1, 2, 7, 9, 5, 3, 1, 9, 0, 2, 9, 9, 7, 6, 7, 3, 7, 1, 4, 7, 7, 6, 1, 0, 5, 0, 7, 5, 4, 0, 8, 9, 2, 0, 0, 9, 0, 8, 2, 6, 2, 4, 7, 5, 3, 8, 0, 1, 4, 7, 4, 4, 5, 5, 9, 4, 9, 6, 3, 4, 9, 1, 1, 9, 1, 5, 4, 1, 8, 5, 2, 6, 3, 4, 6, 0, 6, 4, 4, 3, 3, 4, 4, 2, 8, 4, 0, 6, 1, 2, 9, 9, 6, 5, 4, 9, 3, 2, 5, 1, 3, 0, 9, 3, 0, 6, 2, 1, 6, 6, 2, 6, 5, 8, 7, 2, 4, 1, 9, 9, 7, 0, 6, 8, 3, 9, 0, 4, 4, 3, 8, 0, 0, 6, 7, 1, 1, 4, 9, 9, 8, 4, 8, 1, 0, 2, 5, 7, 4, 7, 6, 3, 7, 8, 2, 1, 3, 6, 8, 9, 6, 4, 5, 1, 2]\n",
            "[3, 1, 7, 6, 7, 9, 5, 3, 2, 4, 4, 3, 2, 8, 8, 0, 2, 7, 4, 6, 3, 3, 2, 3, 3, 0, 9, 4, 8, 5, 6, 6, 3, 8, 7, 1, 4, 0, 8, 5, 1, 0, 7, 1, 4, 2, 5, 4, 3, 6, 2, 3, 6, 5, 3, 2, 1, 3, 1, 9, 9, 4, 6, 9, 8, 0, 9, 2, 0, 3, 5, 9, 5, 9, 0, 2, 9, 4, 9, 3, 4, 8, 9, 3, 6, 0, 5, 1, 9, 1, 5, 2, 1, 2, 3, 9, 6, 2, 4, 6, 6, 0, 9, 1, 3, 7, 7, 4, 6, 8, 2, 1, 8, 3, 1, 2, 6, 2, 1, 0, 0, 6, 2, 5, 4, 6, 2, 8, 9, 8, 8, 7, 0, 5, 2, 9, 1, 1, 1, 6, 7, 2, 7, 8, 0, 5, 2, 0, 6, 2, 3, 8, 4, 0, 7, 1, 9, 6, 4, 0, 2, 3, 8, 7, 8, 6, 7, 1, 0, 3, 0, 9, 2, 9, 2, 8, 0, 5, 0, 3, 6, 1, 4, 9, 1, 5, 2, 3, 0, 7, 2, 9, 2, 6, 7, 9, 4, 3, 7, 3, 0, 4, 9, 6, 9, 9, 4, 5, 3, 3, 4, 1, 8, 8, 1, 4, 8, 7, 4, 3, 8, 4, 8, 6, 4, 3, 4, 8, 5, 6, 8, 4, 5, 3, 8, 7, 9, 3, 0, 0, 5, 3, 9, 8, 7, 3, 2, 7, 1, 0, 7, 1, 1, 7, 7, 0]\n",
            "[0, 5, 1, 8, 7, 7, 4, 2, 4, 7, 5, 0, 8, 9, 7, 9, 5, 0, 7, 0, 7, 7, 8, 3, 3, 4, 5, 1, 6, 9, 7, 1, 2, 2, 9, 6, 6, 1, 4, 2, 0, 5, 8, 1, 6, 5, 6, 5, 7, 7, 2, 7, 6, 9, 5, 3, 1, 1, 6, 4, 3, 6, 1, 4, 8, 4, 1, 6, 1, 9, 7, 7, 7, 1, 7, 9, 3, 7, 4, 6, 7, 7, 3, 7, 6, 2, 8, 8, 9, 3, 3, 4, 3, 2, 1, 9, 0, 7, 3, 5, 1, 5, 9, 0, 4, 2, 8, 6, 6, 3, 9, 0, 8, 4, 9, 9, 7, 8, 1, 8, 0, 9, 7, 1, 9, 2, 5, 1, 3, 0, 2, 7, 6, 2, 3, 9, 7, 2, 7, 0, 7, 7, 6, 0, 6, 8, 4, 7, 5, 3, 2, 3, 2, 2, 3, 4, 4, 4, 7, 4, 0, 7, 9, 6, 2, 3, 2, 5, 3, 9, 8, 6, 7, 5, 0, 6, 7, 9, 0, 2, 7, 9, 2, 5, 5, 3, 4, 5, 7, 1, 3, 5, 3, 8, 0, 0, 2, 4, 1, 7, 8, 8, 3, 1, 5, 2, 6, 8, 3, 5, 8, 0, 5, 6, 1, 5, 4, 3, 6, 6, 8, 0, 5, 4, 0, 6, 0, 5, 9, 3, 3, 0, 1, 1, 2, 2, 2, 8, 9, 0, 8, 5, 9, 8, 2, 9, 4, 3, 2, 9, 2, 9, 4, 1, 7, 2]\n",
            "[1, 3, 3, 7, 1, 1, 7, 7, 9, 9, 3, 5, 8, 3, 5, 1, 4, 6, 9, 4, 0, 3, 6, 3, 6, 6, 2, 9, 9, 9, 7, 8, 6, 6, 0, 5, 1, 3, 1, 4, 6, 2, 0, 2, 2, 2, 8, 3, 2, 0, 1, 0, 1, 7, 6, 9, 4, 9, 9, 4, 7, 8, 9, 7, 9, 6, 3, 9, 5, 0, 8, 7, 0, 6, 8, 8, 5, 7, 5, 4, 7, 8, 8, 3, 3, 2, 3, 6, 3, 8, 5, 5, 2, 5, 2, 4, 2, 9, 3, 9, 9, 2, 6, 9, 6, 0, 0, 9, 0, 8, 2, 1, 7, 6, 2, 0, 1, 6, 2, 3, 8, 9, 1, 2, 5, 8, 2, 0, 7, 7, 1, 1, 0, 8, 6, 7, 4, 4, 7, 3, 2, 0, 5, 4, 2, 7, 7, 1, 3, 4, 1, 3, 4, 3, 6, 6, 9, 5, 2, 4, 5, 1, 3, 6, 4, 4, 2, 0, 2, 7, 1, 9, 8, 2, 4, 6, 6, 3, 6, 8, 2, 8, 6, 1, 8, 7, 3, 6, 6, 5, 7, 0, 2, 1, 3, 4, 9, 4, 3, 9, 2, 7, 1, 3, 2, 0, 3, 3, 9, 0, 4, 0, 6, 9, 5, 3, 7, 4, 5, 0, 1, 5, 0, 4, 2, 3, 4, 0, 1, 0, 5, 8, 4, 0, 3, 5, 8, 6, 9, 4, 4, 7, 4, 3, 5, 0, 9, 2, 3, 6, 9, 8, 2, 5, 8, 7]\n",
            "[0, 2, 2, 5, 6, 7, 2, 2, 5, 1, 8, 5, 7, 2, 2, 3, 3, 7, 7, 5, 6, 4, 4, 1, 5, 8, 9, 0, 8, 8, 2, 3, 6, 2, 9, 8, 0, 2, 0, 5, 4, 8, 7, 4, 6, 6, 2, 5, 2, 2, 6, 2, 4, 0, 7, 6, 2, 1, 2, 6, 4, 4, 5, 2, 6, 7, 9, 6, 2, 4, 9, 8, 2, 4, 9, 6, 7, 8, 1, 0, 9, 8, 6, 4, 3, 8, 4, 7, 5, 1, 9, 1, 4, 3, 0, 4, 8, 0, 9, 0, 0, 3, 2, 7, 1, 4, 2, 8, 4, 7, 8, 4, 3, 1, 0, 3, 2, 4, 2, 2, 7, 9, 4, 1, 4, 2, 3, 9, 8, 2, 9, 1, 6, 6, 9, 6, 1, 4, 0, 9, 9, 3, 9, 6, 8, 4, 0, 7, 0, 0, 2, 8, 3, 1, 1, 3, 7, 0, 6, 7, 7, 0, 0, 6, 0, 3, 9, 5, 9, 6, 1, 7, 6, 3, 9, 8, 7, 8, 0, 4, 3, 8, 0, 1, 7, 7, 3, 0, 6, 2, 8, 2, 8, 4, 9, 6, 3, 4, 3, 9, 7, 1, 3, 2, 6, 2, 5, 5, 2, 9, 6, 8, 6, 7, 0, 8, 9, 4, 0, 2, 1, 5, 1, 6, 8, 1, 0, 2, 5, 2, 9, 8, 5, 3, 6, 8, 7, 2, 1, 8, 3, 2, 0, 4, 8, 0, 9, 5, 0, 2, 6, 0, 2, 6, 3, 3]\n",
            "[6, 2, 8, 1, 7, 6, 8, 1, 2, 5, 5, 4, 0, 0, 1, 8, 2, 0, 7, 9, 9, 2, 0, 4, 7, 0, 6, 0, 3, 1, 8, 2, 2, 6, 2, 7, 6, 0, 0, 5, 1, 6, 3, 7, 8, 1, 5, 5, 2, 0, 6, 4, 5, 8, 3, 7, 7, 1, 5, 8, 1, 8, 3, 3, 6, 8, 5, 0, 9, 8, 6, 2, 5, 1, 5, 0, 9, 8, 0, 9, 5, 8, 2, 0, 0, 4, 2, 2, 8, 3, 1, 3, 5, 8, 1, 0, 6, 8, 3, 1, 6, 0, 0, 2, 1, 8, 2, 6, 9, 6, 3, 7, 5, 3, 7, 2, 1, 9, 9, 0, 0, 3, 6, 2, 6, 9, 2, 1, 4, 3, 0, 3, 1, 8, 7, 8, 7, 1, 3, 5, 1, 1, 4, 2, 3, 4, 9, 2, 0, 1, 5, 3, 1, 4, 0, 6, 0, 7, 1, 7, 1, 2, 7, 4, 0, 9, 6, 2, 6, 3, 2, 4, 7, 5, 1, 0, 4, 3, 5, 9, 1, 4, 3, 1, 3, 5, 5, 7, 6, 9, 6, 7, 5, 6, 9, 8, 5, 1, 3, 0, 6, 7, 8, 7, 6, 7, 4, 7, 6, 3, 7, 3, 6, 1, 8, 2, 7, 8, 7, 9, 4, 1, 8, 8, 7, 3, 8, 8, 5, 0, 2, 7, 8, 9, 9, 7, 7, 2, 3, 1, 4, 8, 5, 9, 0, 4, 6, 1, 5, 3, 8, 3, 0, 1, 8, 1]\n",
            "[4, 6, 8, 7, 2, 8, 0, 5, 3, 4, 6, 3, 0, 2, 4, 4, 9, 1, 5, 1, 0, 2, 4, 4, 1, 2, 4, 5, 5, 9, 9, 2, 2, 2, 4, 4, 9, 6, 2, 5, 2, 2, 0, 2, 7, 9, 5, 0, 7, 0, 8, 0, 1, 7, 8, 2, 7, 4, 0, 8, 9, 4, 9, 3, 5, 0, 3, 3, 8, 0, 7, 0, 6, 7, 2, 0, 3, 6, 2, 1, 8, 6, 0, 1, 3, 8, 0, 3, 6, 3, 8, 1, 1, 2, 6, 8, 8, 9, 4, 9, 5, 7, 9, 6, 6, 4, 9, 0, 4, 0, 1, 3, 0, 0, 5, 9, 7, 2, 1, 6, 7, 2, 2, 1, 8, 8, 8, 9, 6, 2, 9, 9, 7, 4, 0, 9, 6, 8, 3, 4, 9, 7, 9, 5, 4, 7, 0, 4, 6, 4, 4, 4, 9, 7, 7, 8, 0, 0, 5, 6, 7, 2, 1, 3, 9, 8, 0, 1, 3, 8, 4, 3, 1, 2, 8, 4, 4, 5, 1, 4, 0, 3, 8, 8, 7, 1, 1, 6, 8, 2, 8, 6, 3, 4, 5, 9, 4, 2, 3, 1, 2, 0, 8, 3, 5, 8, 5, 2, 2, 3, 0, 1, 1, 4, 8, 2, 7, 6, 0, 6, 5, 8, 4, 3, 3, 3, 2, 9, 5, 7, 4, 7, 2, 5, 9, 5, 4, 7, 8, 4, 3, 2, 3, 6, 9, 2, 6, 3, 4, 4, 6, 1, 9, 5, 5, 2]\n",
            "[2, 9, 0, 8, 7, 8, 0, 8, 6, 2, 5, 5, 0, 5, 4, 2, 6, 0, 9, 8, 5, 9, 6, 1, 9, 3, 7, 1, 3, 7, 4, 1, 1, 9, 6, 9, 5, 8, 0, 8, 5, 3, 8, 0, 1, 4, 8, 6, 6, 9, 5, 8, 0, 7, 3, 4, 9, 2, 9, 4, 3, 1, 0, 8, 5, 3, 2, 4, 5, 2, 1, 3, 8, 8, 4, 5, 7, 9, 5, 7, 0, 7, 7, 5, 8, 8, 7, 1, 2, 0, 0, 0, 7, 6, 6, 8, 0, 1, 3, 0, 2, 6, 3, 6, 8, 0, 5, 6, 3, 0, 2, 7, 7, 0, 1, 4, 8, 5, 5, 1, 9, 5, 4, 4, 2, 0, 1, 7, 6, 6, 7, 0, 6, 4, 9, 8, 8, 9, 3, 3, 1, 0, 4, 4, 7, 0, 5, 7, 6, 7, 8, 1, 3, 4, 6, 7, 0, 4, 3, 2, 5, 3, 7, 3, 7, 1, 9, 1, 3, 4, 0, 1, 7, 4, 2, 4, 3, 5, 4, 0, 6, 2, 2, 6, 9, 3, 3, 9, 9, 8, 1, 5, 1, 7, 0, 3, 1, 9, 2, 8, 4, 8, 2, 1, 7, 0, 0, 1, 8, 7, 4, 9, 9, 7, 0, 5, 1, 5, 8, 6, 8, 5, 6, 3, 6, 1, 1, 9, 6, 4, 3, 6, 8, 8, 5, 3, 9, 7, 2, 7, 1, 5, 9, 1, 3, 9, 5, 0, 4, 6, 3, 5, 3, 3, 6, 1]\n",
            "[3, 2, 3, 2, 2, 6, 2, 0, 1, 2, 7, 2, 5, 6, 2, 8, 4, 6, 8, 8, 8, 2, 4, 8, 7, 1, 6, 7, 3, 7, 7, 4, 0, 1, 3, 9, 2, 0, 0, 5, 4, 7, 8, 6, 8, 7, 8, 4, 3, 3, 1, 3, 2, 5, 6, 0, 3, 5, 0, 3, 7, 7, 8, 6, 3, 6, 9, 5, 9, 2, 1, 2, 3, 5, 2, 2, 2, 1, 3, 3, 5, 8, 7, 9, 3, 4, 2, 7, 1, 7, 8, 2, 2, 3, 9, 5, 5, 7, 2, 3, 9, 0, 5, 5, 6, 6, 9, 3, 6, 5, 9, 2, 0, 7, 9, 7, 7, 1, 2, 0, 3, 2, 8, 0, 3, 3, 6, 3, 0, 5, 2, 6, 6, 7, 8, 0, 1, 8, 7, 1, 2, 9, 2, 5, 7, 6, 3, 6, 7, 0, 4, 5, 1, 9, 4, 6, 0, 5, 8, 4, 0, 4, 3, 3, 1, 5, 1, 5, 1, 2, 1, 0, 9, 6, 7, 5, 9, 9, 3, 4, 4, 7, 5, 6, 3, 9, 0, 4, 4, 0, 8, 5, 8, 1, 5, 5, 5, 7, 8, 5, 0, 7, 0, 4, 4, 4, 5, 6, 4, 2, 8, 2, 6, 8, 1, 2, 3, 8, 9, 8, 3, 9, 9, 6, 7, 1, 2, 7, 7, 3, 3, 1, 1, 9, 7, 2, 1, 8, 1, 2, 7, 8, 5, 0, 4, 3, 8, 8, 4, 3, 3, 2, 9, 0, 7, 7]\n",
            "[1, 9, 0, 4, 2, 2, 8, 7, 4, 3, 7, 4, 2, 3, 4, 0, 5, 3, 3, 0, 1, 2, 5, 0, 3, 5, 7, 3, 7, 8, 7, 4, 9, 1, 5, 0, 8, 2, 9, 2, 1, 0, 1, 2, 6, 9, 2, 8, 3, 5, 3, 5, 9, 1, 4, 7, 1, 8, 1, 8, 8, 9, 4, 6, 1, 9, 9, 3, 4, 1, 2, 2, 3, 5, 9, 0, 7, 2, 8, 2, 9, 9, 9, 9, 0, 7, 8, 2, 3, 3, 1, 9, 9, 8, 8, 3, 5, 1, 2, 1, 7, 2, 0, 7, 3, 8, 1, 7, 0, 6, 4, 0, 8, 1, 8, 7, 7, 4, 7, 3, 2, 9, 6, 7, 5, 9, 7, 4, 6, 2, 7, 6, 7, 1, 3, 7, 0, 3, 1, 4, 7, 5, 2, 0, 4, 4, 9, 7, 4, 9, 0, 9, 0, 2, 1, 6, 6, 3, 6, 4, 9, 2, 2, 3, 1, 1, 0, 7, 1, 2, 7, 9, 0, 4, 0, 6, 7, 1, 0, 9, 7, 5, 0, 8, 4, 8, 1, 0, 5, 0, 3, 6, 2, 0, 8, 2, 7, 6, 0, 8, 5, 5, 2, 6, 9, 4, 2, 0, 9, 3, 8, 1, 0, 6, 7, 2, 7, 0, 3, 1, 9, 2, 1, 9, 7, 3, 0, 6, 4, 2, 2, 5, 3, 7, 8, 8, 5, 7, 4, 2, 7, 4, 4, 0, 3, 8, 9, 9, 2, 8, 8, 8, 0, 3, 1, 1]\n",
            "[1, 0, 9, 0, 4, 1, 7, 4, 7, 6, 1, 1, 4, 3, 7, 1, 5, 0, 9, 5, 8, 9, 3, 2, 9, 1, 2, 3, 9, 6, 3, 6, 7, 9, 1, 7, 3, 2, 5, 2, 9, 7, 2, 6, 2, 8, 6, 5, 7, 7, 3, 5, 8, 0, 0, 4, 2, 2, 5, 1, 9, 5, 9, 6, 5, 0, 8, 3, 3, 7, 6, 1, 8, 3, 8, 8, 0, 8, 4, 0, 7, 8, 6, 1, 4, 6, 5, 0, 4, 9, 7, 1, 9, 6, 6, 6, 5, 4, 8, 8, 7, 2, 4, 5, 7, 5, 0, 0, 0, 8, 0, 7, 7, 0, 2, 6, 9, 3, 9, 8, 7, 2, 9, 7, 3, 9, 5, 9, 9, 0, 7, 5, 8, 4, 5, 8, 7, 8, 9, 1, 2, 2, 7, 7, 4, 7, 0, 6, 3, 9, 2, 2, 5, 0, 1, 2, 9, 1, 8, 4, 0, 6, 4, 9, 5, 3, 0, 2, 0, 1, 4, 9, 8, 0, 5, 7, 4, 4, 2, 0, 2, 4, 2, 1, 8, 3, 9, 0, 1, 0, 4, 7, 6, 5, 0, 5, 6, 1, 0, 0, 0, 7, 0, 3, 7, 7, 3, 7, 7, 8, 4, 4, 8, 3, 3, 0, 6, 4, 1, 0, 0, 2, 3, 2, 1, 1, 7, 3, 7, 6, 8, 6, 3, 4, 6, 4, 4, 3, 3, 4, 2, 3, 1, 3, 8, 5, 1, 2, 4, 0, 3, 6, 2, 2, 1, 2]\n",
            "[9, 0, 6, 1, 2, 4, 1, 3, 9, 7, 6, 0, 9, 5, 8, 3, 7, 2, 3, 4, 4, 8, 4, 6, 2, 1, 7, 7, 5, 8, 1, 2, 8, 3, 5, 1, 6, 9, 0, 9, 4, 7, 1, 0, 7, 0, 5, 3, 7, 5, 6, 9, 9, 4, 6, 0, 8, 9, 7, 9, 7, 1, 7, 1, 2, 6, 7, 8, 0, 8, 2, 5, 9, 7, 1, 2, 6, 0, 5, 6, 6, 1, 0, 0, 2, 4, 9, 8, 4, 6, 8, 0, 2, 8, 4, 9, 7, 4, 1, 1, 7, 4, 1, 5, 7, 6, 2, 2, 3, 0, 7, 4, 0, 7, 2, 6, 0, 3, 6, 1, 2, 3, 3, 5, 7, 0, 5, 6, 2, 3, 6, 1, 4, 4, 0, 9, 8, 9, 8, 7, 4, 8, 4, 3, 9, 7, 8, 3, 8, 3, 6, 7, 3, 0, 1, 2, 3, 8, 2, 0, 8, 0, 3, 4, 2, 2, 3, 4, 0, 7, 3, 2, 2, 9, 4, 5, 1, 0, 5, 9, 6, 1, 5, 0, 7, 6, 4, 2, 5, 3, 7, 9, 3, 9, 1, 8, 1, 6, 2, 3, 4, 8, 0, 9, 1, 9, 4, 4, 6, 2, 6, 0, 5, 7, 0, 8, 7, 8, 9, 9, 0, 7, 7, 3, 2, 6, 0, 2, 6, 3, 5, 2, 1, 1, 1, 0, 1, 0, 8, 0, 6, 6, 4, 2, 8, 1, 9, 3, 9, 7, 8, 8, 4, 6, 2, 1]\n",
            "[7, 6, 8, 0, 7, 7, 5, 7, 2, 4, 3, 3, 6, 7, 6, 5, 9, 2, 9, 4, 4, 1, 0, 1, 4, 5, 4, 4, 6, 8, 5, 2, 3, 5, 2, 8, 5, 5, 3, 0, 8, 3, 3, 3, 9, 0, 3, 0, 3, 0, 3, 2, 9, 7, 5, 4, 9, 2, 4, 0, 1, 0, 6, 3, 0, 2, 8, 1, 3, 5, 5, 8, 9, 2, 7, 1, 6, 4, 6, 7, 2, 0, 4, 9, 6, 1, 8, 0, 4, 9, 5, 1, 6, 1, 1, 0, 9, 5, 9, 7, 9, 1, 0, 0, 0, 1, 7, 5, 8, 9, 7, 9, 9, 4, 6, 7, 7, 3, 6, 8, 0, 2, 0, 3, 1, 6, 2, 9, 6, 1, 8, 8, 1, 2, 8, 6, 1, 4, 3, 5, 2, 6, 0, 1, 9, 7, 5, 7, 3, 1, 6, 1, 0, 7, 5, 4, 2, 7, 3, 7, 3, 6, 4, 9, 5, 5, 1, 4, 6, 3, 9, 7, 8, 1, 8, 5, 7, 0, 6, 8, 5, 2, 5, 4, 1, 5, 4, 7, 5, 8, 3, 2, 1, 9, 2, 2, 5, 6, 1, 4, 1, 1, 1, 8, 1, 4, 7, 9, 3, 6, 8, 1, 5, 3, 9, 2, 4, 2, 5, 0, 4, 2, 1, 8, 4, 5, 4, 1, 6, 5, 5, 8, 2, 2, 9, 0, 3, 3, 8, 2, 8, 8, 4, 7, 4, 6, 7, 4, 4, 1, 5, 7, 9, 2, 6, 1]\n",
            "[0, 7, 1, 0, 9, 3, 7, 6, 7, 7, 2, 6, 7, 4, 3, 1, 7, 0, 5, 6, 7, 6, 6, 5, 7, 3, 4, 6, 0, 0, 6, 4, 2, 1, 4, 6, 3, 0, 9, 9, 5, 4, 2, 6, 0, 2, 4, 0, 1, 1, 0, 5, 9, 1, 1, 9, 9, 2, 4, 1, 0, 8, 3, 1, 8, 7, 2, 9, 8, 8, 0, 7, 9, 7, 2, 4, 1, 6, 9, 4, 8, 3, 6, 1, 3, 2, 3, 7, 5, 4, 3, 4, 2, 0, 7, 1, 6, 8, 1, 8, 1, 3, 0, 1, 0, 4, 8, 4, 5, 5, 2, 1, 8, 3, 8, 7, 8, 4, 2, 3, 6, 4, 5, 3, 1, 8, 0, 2, 7, 3, 7, 8, 5, 7, 6, 6, 3, 8, 5, 7, 1, 9, 6, 0, 5, 0, 2, 7, 9, 7, 8, 5, 5, 2, 1, 8, 7, 1, 7, 3, 5, 0, 0, 9, 6, 7, 6, 6, 2, 4, 9, 8, 6, 8, 2, 5, 8, 9, 5, 6, 2, 7, 1, 7, 8, 5, 3, 1, 3, 8, 9, 6, 4, 9, 1, 8, 0, 8, 6, 2, 9, 4, 2, 1, 7, 6, 3, 1, 7, 7, 0, 8, 3, 4, 7, 2, 9, 5, 1, 0, 7, 6, 7, 8, 4, 5, 3, 0, 8, 2, 8, 0, 5, 0, 5, 0, 1, 9, 2, 3, 7, 3, 9, 9, 5, 8, 7, 0, 2, 9, 3, 3, 2, 6, 6, 8]\n",
            "[7, 7, 0, 9, 1, 7, 3, 3, 7, 5, 6, 0, 4, 9, 8, 2, 3, 9, 3, 3, 4, 3, 4, 5, 9, 1, 4, 0, 2, 7, 5, 3, 1, 6, 1, 8, 4, 8, 7, 5, 2, 5, 1, 7, 4, 8, 0, 5, 7, 4, 8, 2, 5, 9, 3, 4, 5, 6, 7, 5, 9, 8, 3, 7, 7, 3, 2, 8, 1, 2, 0, 1, 2, 0, 4, 1, 9, 0, 1, 4, 3, 1, 9, 4, 4, 5, 4, 5, 8, 0, 5, 0, 0, 9, 3, 2, 5, 9, 7, 4, 8, 7, 8, 0, 9, 4, 3, 3, 0, 7, 6, 6, 8, 8, 2, 1, 4, 9, 6, 9, 7, 5, 0, 4, 2, 9, 2, 8, 6, 6, 8, 3, 2, 0, 9, 1, 5, 3, 1, 0, 4, 9, 5, 9, 6, 3, 0, 9, 6, 7, 2, 7, 3, 0, 3, 3, 1, 8, 7, 2, 8, 7, 7, 0, 0, 6, 2, 8, 1, 0, 5, 9, 2, 5, 9, 2, 4, 0, 4, 0, 8, 4, 3, 1, 6, 4, 4, 1, 0, 9, 8, 8, 1, 1, 9, 8, 6, 4, 1, 8, 8, 1, 5, 1, 6, 3, 3, 5, 5, 4, 1, 2, 3, 6, 3, 8, 6, 1, 3, 4, 7, 7, 1, 5, 7, 3, 0, 6, 3, 4, 8, 2, 8, 6, 7, 5, 8, 8, 3, 2, 1, 6, 9, 8, 9, 0, 9, 1, 5, 9, 4, 6, 2, 2, 2, 5]\n",
            "[1, 9, 4, 0, 1, 1, 3, 4, 0, 6, 9, 8, 6, 7, 2, 4, 0, 6, 8, 0, 2, 5, 1, 5, 4, 4, 7, 1, 1, 0, 7, 7, 0, 4, 9, 2, 6, 5, 9, 1, 9, 6, 7, 9, 9, 2, 8, 2, 5, 0, 1, 1, 3, 1, 7, 2, 3, 9, 9, 1, 9, 3, 4, 0, 3, 3, 5, 0, 4, 8, 0, 3, 6, 0, 1, 9, 3, 1, 1, 0, 4, 5, 2, 2, 9, 6, 7, 6, 1, 9, 7, 9, 7, 3, 9, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A_4HIgghXNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yopred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONB0BNj9hYHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit = {'ImageId':[(i+1) for i in range(len(yopred))], 'Label':yopred}\n",
        "submission = pd.DataFrame.from_dict(submit)\n",
        "submission.to_csv('submission.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS9efUDDjKGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVQIlkAQDZnF",
        "colab_type": "code",
        "outputId": "50df99fe-3a10-4415-f90b-b9afd3c9a2b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(1,23):\n",
        "  ax = fig.add_subplot(1,22,i)\n",
        "  # ax.set_title(elems[i-1])\n",
        "  ax.axis('off')\n",
        "  plt.imshow(np.reshape(Xtest[i-1,:],(28,28)),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAAjCAYAAACQEND9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3WcNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 22 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}