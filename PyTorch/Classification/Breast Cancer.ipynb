{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='monokai', context='notebook', ticks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, Y = data.data, data.target\n",
    "\n",
    "# Reshape the data\n",
    "\n",
    "X = X.reshape(-1, X.shape[1])\n",
    "Y = Y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into two halves training and testing\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(X, Y, test_size=0.33)\n",
    "\n",
    "# Preprocess the data by scaling the data\n",
    "scaler = StandardScaler()\n",
    "Xtrain = scaler.fit_transform(Xtrain)\n",
    "Xval = scaler.transform(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = data.data.shape[1] # Represent the number of feature\n",
    "\n",
    "# Build the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(D, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "\n",
    "# Define the loss and optimizer for the model\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/1000, Train-Loss : 0.8444, Val-Loss : 0.8016\n",
      "Epoch : 2/1000, Train-Loss : 0.8358, Val-Loss : 0.7946\n",
      "Epoch : 3/1000, Train-Loss : 0.8272, Val-Loss : 0.7876\n",
      "Epoch : 4/1000, Train-Loss : 0.8187, Val-Loss : 0.7808\n",
      "Epoch : 5/1000, Train-Loss : 0.8102, Val-Loss : 0.7740\n",
      "Epoch : 6/1000, Train-Loss : 0.8019, Val-Loss : 0.7673\n",
      "Epoch : 7/1000, Train-Loss : 0.7937, Val-Loss : 0.7608\n",
      "Epoch : 8/1000, Train-Loss : 0.7855, Val-Loss : 0.7543\n",
      "Epoch : 9/1000, Train-Loss : 0.7775, Val-Loss : 0.7478\n",
      "Epoch : 10/1000, Train-Loss : 0.7696, Val-Loss : 0.7415\n",
      "Epoch : 11/1000, Train-Loss : 0.7617, Val-Loss : 0.7353\n",
      "Epoch : 12/1000, Train-Loss : 0.7540, Val-Loss : 0.7292\n",
      "Epoch : 13/1000, Train-Loss : 0.7463, Val-Loss : 0.7231\n",
      "Epoch : 14/1000, Train-Loss : 0.7388, Val-Loss : 0.7172\n",
      "Epoch : 15/1000, Train-Loss : 0.7314, Val-Loss : 0.7113\n",
      "Epoch : 16/1000, Train-Loss : 0.7240, Val-Loss : 0.7056\n",
      "Epoch : 17/1000, Train-Loss : 0.7168, Val-Loss : 0.6999\n",
      "Epoch : 18/1000, Train-Loss : 0.7097, Val-Loss : 0.6943\n",
      "Epoch : 19/1000, Train-Loss : 0.7027, Val-Loss : 0.6889\n",
      "Epoch : 20/1000, Train-Loss : 0.6958, Val-Loss : 0.6835\n",
      "Epoch : 21/1000, Train-Loss : 0.6890, Val-Loss : 0.6782\n",
      "Epoch : 22/1000, Train-Loss : 0.6823, Val-Loss : 0.6730\n",
      "Epoch : 23/1000, Train-Loss : 0.6757, Val-Loss : 0.6679\n",
      "Epoch : 24/1000, Train-Loss : 0.6692, Val-Loss : 0.6629\n",
      "Epoch : 25/1000, Train-Loss : 0.6628, Val-Loss : 0.6579\n",
      "Epoch : 26/1000, Train-Loss : 0.6566, Val-Loss : 0.6531\n",
      "Epoch : 27/1000, Train-Loss : 0.6504, Val-Loss : 0.6483\n",
      "Epoch : 28/1000, Train-Loss : 0.6443, Val-Loss : 0.6437\n",
      "Epoch : 29/1000, Train-Loss : 0.6383, Val-Loss : 0.6391\n",
      "Epoch : 30/1000, Train-Loss : 0.6325, Val-Loss : 0.6346\n",
      "Epoch : 31/1000, Train-Loss : 0.6267, Val-Loss : 0.6302\n",
      "Epoch : 32/1000, Train-Loss : 0.6210, Val-Loss : 0.6258\n",
      "Epoch : 33/1000, Train-Loss : 0.6154, Val-Loss : 0.6216\n",
      "Epoch : 34/1000, Train-Loss : 0.6099, Val-Loss : 0.6174\n",
      "Epoch : 35/1000, Train-Loss : 0.6045, Val-Loss : 0.6133\n",
      "Epoch : 36/1000, Train-Loss : 0.5992, Val-Loss : 0.6093\n",
      "Epoch : 37/1000, Train-Loss : 0.5940, Val-Loss : 0.6053\n",
      "Epoch : 38/1000, Train-Loss : 0.5889, Val-Loss : 0.6014\n",
      "Epoch : 39/1000, Train-Loss : 0.5839, Val-Loss : 0.5976\n",
      "Epoch : 40/1000, Train-Loss : 0.5789, Val-Loss : 0.5939\n",
      "Epoch : 41/1000, Train-Loss : 0.5741, Val-Loss : 0.5902\n",
      "Epoch : 42/1000, Train-Loss : 0.5693, Val-Loss : 0.5866\n",
      "Epoch : 43/1000, Train-Loss : 0.5646, Val-Loss : 0.5830\n",
      "Epoch : 44/1000, Train-Loss : 0.5599, Val-Loss : 0.5795\n",
      "Epoch : 45/1000, Train-Loss : 0.5554, Val-Loss : 0.5761\n",
      "Epoch : 46/1000, Train-Loss : 0.5509, Val-Loss : 0.5728\n",
      "Epoch : 47/1000, Train-Loss : 0.5465, Val-Loss : 0.5694\n",
      "Epoch : 48/1000, Train-Loss : 0.5422, Val-Loss : 0.5662\n",
      "Epoch : 49/1000, Train-Loss : 0.5380, Val-Loss : 0.5630\n",
      "Epoch : 50/1000, Train-Loss : 0.5338, Val-Loss : 0.5598\n",
      "Epoch : 51/1000, Train-Loss : 0.5297, Val-Loss : 0.5567\n",
      "Epoch : 52/1000, Train-Loss : 0.5256, Val-Loss : 0.5537\n",
      "Epoch : 53/1000, Train-Loss : 0.5216, Val-Loss : 0.5507\n",
      "Epoch : 54/1000, Train-Loss : 0.5177, Val-Loss : 0.5477\n",
      "Epoch : 55/1000, Train-Loss : 0.5139, Val-Loss : 0.5448\n",
      "Epoch : 56/1000, Train-Loss : 0.5101, Val-Loss : 0.5420\n",
      "Epoch : 57/1000, Train-Loss : 0.5064, Val-Loss : 0.5392\n",
      "Epoch : 58/1000, Train-Loss : 0.5027, Val-Loss : 0.5364\n",
      "Epoch : 59/1000, Train-Loss : 0.4991, Val-Loss : 0.5337\n",
      "Epoch : 60/1000, Train-Loss : 0.4955, Val-Loss : 0.5310\n",
      "Epoch : 61/1000, Train-Loss : 0.4920, Val-Loss : 0.5283\n",
      "Epoch : 62/1000, Train-Loss : 0.4885, Val-Loss : 0.5257\n",
      "Epoch : 63/1000, Train-Loss : 0.4852, Val-Loss : 0.5231\n",
      "Epoch : 64/1000, Train-Loss : 0.4818, Val-Loss : 0.5206\n",
      "Epoch : 65/1000, Train-Loss : 0.4785, Val-Loss : 0.5180\n",
      "Epoch : 66/1000, Train-Loss : 0.4753, Val-Loss : 0.5156\n",
      "Epoch : 67/1000, Train-Loss : 0.4721, Val-Loss : 0.5131\n",
      "Epoch : 68/1000, Train-Loss : 0.4689, Val-Loss : 0.5107\n",
      "Epoch : 69/1000, Train-Loss : 0.4658, Val-Loss : 0.5083\n",
      "Epoch : 70/1000, Train-Loss : 0.4627, Val-Loss : 0.5060\n",
      "Epoch : 71/1000, Train-Loss : 0.4597, Val-Loss : 0.5036\n",
      "Epoch : 72/1000, Train-Loss : 0.4567, Val-Loss : 0.5013\n",
      "Epoch : 73/1000, Train-Loss : 0.4538, Val-Loss : 0.4991\n",
      "Epoch : 74/1000, Train-Loss : 0.4509, Val-Loss : 0.4968\n",
      "Epoch : 75/1000, Train-Loss : 0.4480, Val-Loss : 0.4946\n",
      "Epoch : 76/1000, Train-Loss : 0.4452, Val-Loss : 0.4924\n",
      "Epoch : 77/1000, Train-Loss : 0.4424, Val-Loss : 0.4903\n",
      "Epoch : 78/1000, Train-Loss : 0.4397, Val-Loss : 0.4881\n",
      "Epoch : 79/1000, Train-Loss : 0.4370, Val-Loss : 0.4860\n",
      "Epoch : 80/1000, Train-Loss : 0.4343, Val-Loss : 0.4839\n",
      "Epoch : 81/1000, Train-Loss : 0.4317, Val-Loss : 0.4818\n",
      "Epoch : 82/1000, Train-Loss : 0.4291, Val-Loss : 0.4798\n",
      "Epoch : 83/1000, Train-Loss : 0.4265, Val-Loss : 0.4778\n",
      "Epoch : 84/1000, Train-Loss : 0.4240, Val-Loss : 0.4758\n",
      "Epoch : 85/1000, Train-Loss : 0.4215, Val-Loss : 0.4738\n",
      "Epoch : 86/1000, Train-Loss : 0.4190, Val-Loss : 0.4718\n",
      "Epoch : 87/1000, Train-Loss : 0.4166, Val-Loss : 0.4699\n",
      "Epoch : 88/1000, Train-Loss : 0.4142, Val-Loss : 0.4679\n",
      "Epoch : 89/1000, Train-Loss : 0.4118, Val-Loss : 0.4660\n",
      "Epoch : 90/1000, Train-Loss : 0.4095, Val-Loss : 0.4642\n",
      "Epoch : 91/1000, Train-Loss : 0.4071, Val-Loss : 0.4623\n",
      "Epoch : 92/1000, Train-Loss : 0.4049, Val-Loss : 0.4604\n",
      "Epoch : 93/1000, Train-Loss : 0.4026, Val-Loss : 0.4586\n",
      "Epoch : 94/1000, Train-Loss : 0.4004, Val-Loss : 0.4568\n",
      "Epoch : 95/1000, Train-Loss : 0.3981, Val-Loss : 0.4550\n",
      "Epoch : 96/1000, Train-Loss : 0.3960, Val-Loss : 0.4532\n",
      "Epoch : 97/1000, Train-Loss : 0.3938, Val-Loss : 0.4515\n",
      "Epoch : 98/1000, Train-Loss : 0.3917, Val-Loss : 0.4497\n",
      "Epoch : 99/1000, Train-Loss : 0.3896, Val-Loss : 0.4480\n",
      "Epoch : 100/1000, Train-Loss : 0.3875, Val-Loss : 0.4463\n",
      "Epoch : 101/1000, Train-Loss : 0.3854, Val-Loss : 0.4446\n",
      "Epoch : 102/1000, Train-Loss : 0.3834, Val-Loss : 0.4429\n",
      "Epoch : 103/1000, Train-Loss : 0.3814, Val-Loss : 0.4412\n",
      "Epoch : 104/1000, Train-Loss : 0.3794, Val-Loss : 0.4396\n",
      "Epoch : 105/1000, Train-Loss : 0.3774, Val-Loss : 0.4379\n",
      "Epoch : 106/1000, Train-Loss : 0.3755, Val-Loss : 0.4363\n",
      "Epoch : 107/1000, Train-Loss : 0.3735, Val-Loss : 0.4347\n",
      "Epoch : 108/1000, Train-Loss : 0.3716, Val-Loss : 0.4331\n",
      "Epoch : 109/1000, Train-Loss : 0.3698, Val-Loss : 0.4315\n",
      "Epoch : 110/1000, Train-Loss : 0.3679, Val-Loss : 0.4299\n",
      "Epoch : 111/1000, Train-Loss : 0.3661, Val-Loss : 0.4284\n",
      "Epoch : 112/1000, Train-Loss : 0.3642, Val-Loss : 0.4268\n",
      "Epoch : 113/1000, Train-Loss : 0.3624, Val-Loss : 0.4253\n",
      "Epoch : 114/1000, Train-Loss : 0.3606, Val-Loss : 0.4238\n",
      "Epoch : 115/1000, Train-Loss : 0.3589, Val-Loss : 0.4223\n",
      "Epoch : 116/1000, Train-Loss : 0.3571, Val-Loss : 0.4208\n",
      "Epoch : 117/1000, Train-Loss : 0.3554, Val-Loss : 0.4193\n",
      "Epoch : 118/1000, Train-Loss : 0.3537, Val-Loss : 0.4178\n",
      "Epoch : 119/1000, Train-Loss : 0.3520, Val-Loss : 0.4164\n",
      "Epoch : 120/1000, Train-Loss : 0.3503, Val-Loss : 0.4149\n",
      "Epoch : 121/1000, Train-Loss : 0.3487, Val-Loss : 0.4135\n",
      "Epoch : 122/1000, Train-Loss : 0.3470, Val-Loss : 0.4121\n",
      "Epoch : 123/1000, Train-Loss : 0.3454, Val-Loss : 0.4107\n",
      "Epoch : 124/1000, Train-Loss : 0.3438, Val-Loss : 0.4093\n",
      "Epoch : 125/1000, Train-Loss : 0.3422, Val-Loss : 0.4079\n",
      "Epoch : 126/1000, Train-Loss : 0.3406, Val-Loss : 0.4065\n",
      "Epoch : 127/1000, Train-Loss : 0.3390, Val-Loss : 0.4051\n",
      "Epoch : 128/1000, Train-Loss : 0.3375, Val-Loss : 0.4038\n",
      "Epoch : 129/1000, Train-Loss : 0.3360, Val-Loss : 0.4024\n",
      "Epoch : 130/1000, Train-Loss : 0.3344, Val-Loss : 0.4011\n",
      "Epoch : 131/1000, Train-Loss : 0.3329, Val-Loss : 0.3998\n",
      "Epoch : 132/1000, Train-Loss : 0.3314, Val-Loss : 0.3984\n",
      "Epoch : 133/1000, Train-Loss : 0.3300, Val-Loss : 0.3971\n",
      "Epoch : 134/1000, Train-Loss : 0.3285, Val-Loss : 0.3958\n",
      "Epoch : 135/1000, Train-Loss : 0.3271, Val-Loss : 0.3946\n",
      "Epoch : 136/1000, Train-Loss : 0.3256, Val-Loss : 0.3933\n",
      "Epoch : 137/1000, Train-Loss : 0.3242, Val-Loss : 0.3920\n",
      "Epoch : 138/1000, Train-Loss : 0.3228, Val-Loss : 0.3908\n",
      "Epoch : 139/1000, Train-Loss : 0.3214, Val-Loss : 0.3895\n",
      "Epoch : 140/1000, Train-Loss : 0.3200, Val-Loss : 0.3883\n",
      "Epoch : 141/1000, Train-Loss : 0.3187, Val-Loss : 0.3871\n",
      "Epoch : 142/1000, Train-Loss : 0.3173, Val-Loss : 0.3858\n",
      "Epoch : 143/1000, Train-Loss : 0.3160, Val-Loss : 0.3846\n",
      "Epoch : 144/1000, Train-Loss : 0.3146, Val-Loss : 0.3834\n",
      "Epoch : 145/1000, Train-Loss : 0.3133, Val-Loss : 0.3822\n",
      "Epoch : 146/1000, Train-Loss : 0.3120, Val-Loss : 0.3811\n",
      "Epoch : 147/1000, Train-Loss : 0.3107, Val-Loss : 0.3799\n",
      "Epoch : 148/1000, Train-Loss : 0.3094, Val-Loss : 0.3787\n",
      "Epoch : 149/1000, Train-Loss : 0.3082, Val-Loss : 0.3776\n",
      "Epoch : 150/1000, Train-Loss : 0.3069, Val-Loss : 0.3764\n",
      "Epoch : 151/1000, Train-Loss : 0.3057, Val-Loss : 0.3753\n",
      "Epoch : 152/1000, Train-Loss : 0.3044, Val-Loss : 0.3742\n",
      "Epoch : 153/1000, Train-Loss : 0.3032, Val-Loss : 0.3730\n",
      "Epoch : 154/1000, Train-Loss : 0.3020, Val-Loss : 0.3719\n",
      "Epoch : 155/1000, Train-Loss : 0.3008, Val-Loss : 0.3708\n",
      "Epoch : 156/1000, Train-Loss : 0.2996, Val-Loss : 0.3697\n",
      "Epoch : 157/1000, Train-Loss : 0.2984, Val-Loss : 0.3686\n",
      "Epoch : 158/1000, Train-Loss : 0.2972, Val-Loss : 0.3675\n",
      "Epoch : 159/1000, Train-Loss : 0.2960, Val-Loss : 0.3665\n",
      "Epoch : 160/1000, Train-Loss : 0.2949, Val-Loss : 0.3654\n",
      "Epoch : 161/1000, Train-Loss : 0.2937, Val-Loss : 0.3643\n",
      "Epoch : 162/1000, Train-Loss : 0.2926, Val-Loss : 0.3633\n",
      "Epoch : 163/1000, Train-Loss : 0.2915, Val-Loss : 0.3622\n",
      "Epoch : 164/1000, Train-Loss : 0.2903, Val-Loss : 0.3612\n",
      "Epoch : 165/1000, Train-Loss : 0.2892, Val-Loss : 0.3602\n",
      "Epoch : 166/1000, Train-Loss : 0.2881, Val-Loss : 0.3592\n",
      "Epoch : 167/1000, Train-Loss : 0.2870, Val-Loss : 0.3581\n",
      "Epoch : 168/1000, Train-Loss : 0.2860, Val-Loss : 0.3571\n",
      "Epoch : 169/1000, Train-Loss : 0.2849, Val-Loss : 0.3561\n",
      "Epoch : 170/1000, Train-Loss : 0.2838, Val-Loss : 0.3551\n",
      "Epoch : 171/1000, Train-Loss : 0.2828, Val-Loss : 0.3542\n",
      "Epoch : 172/1000, Train-Loss : 0.2817, Val-Loss : 0.3532\n",
      "Epoch : 173/1000, Train-Loss : 0.2807, Val-Loss : 0.3522\n",
      "Epoch : 174/1000, Train-Loss : 0.2797, Val-Loss : 0.3512\n",
      "Epoch : 175/1000, Train-Loss : 0.2786, Val-Loss : 0.3503\n",
      "Epoch : 176/1000, Train-Loss : 0.2776, Val-Loss : 0.3493\n",
      "Epoch : 177/1000, Train-Loss : 0.2766, Val-Loss : 0.3484\n",
      "Epoch : 178/1000, Train-Loss : 0.2756, Val-Loss : 0.3474\n",
      "Epoch : 179/1000, Train-Loss : 0.2746, Val-Loss : 0.3465\n",
      "Epoch : 180/1000, Train-Loss : 0.2736, Val-Loss : 0.3456\n",
      "Epoch : 181/1000, Train-Loss : 0.2727, Val-Loss : 0.3447\n",
      "Epoch : 182/1000, Train-Loss : 0.2717, Val-Loss : 0.3438\n",
      "Epoch : 183/1000, Train-Loss : 0.2707, Val-Loss : 0.3428\n",
      "Epoch : 184/1000, Train-Loss : 0.2698, Val-Loss : 0.3419\n",
      "Epoch : 185/1000, Train-Loss : 0.2689, Val-Loss : 0.3410\n",
      "Epoch : 186/1000, Train-Loss : 0.2679, Val-Loss : 0.3402\n",
      "Epoch : 187/1000, Train-Loss : 0.2670, Val-Loss : 0.3393\n",
      "Epoch : 188/1000, Train-Loss : 0.2661, Val-Loss : 0.3384\n",
      "Epoch : 189/1000, Train-Loss : 0.2651, Val-Loss : 0.3375\n",
      "Epoch : 190/1000, Train-Loss : 0.2642, Val-Loss : 0.3367\n",
      "Epoch : 191/1000, Train-Loss : 0.2633, Val-Loss : 0.3358\n",
      "Epoch : 192/1000, Train-Loss : 0.2624, Val-Loss : 0.3349\n",
      "Epoch : 193/1000, Train-Loss : 0.2615, Val-Loss : 0.3341\n",
      "Epoch : 194/1000, Train-Loss : 0.2607, Val-Loss : 0.3333\n",
      "Epoch : 195/1000, Train-Loss : 0.2598, Val-Loss : 0.3324\n",
      "Epoch : 196/1000, Train-Loss : 0.2589, Val-Loss : 0.3316\n",
      "Epoch : 197/1000, Train-Loss : 0.2581, Val-Loss : 0.3308\n",
      "Epoch : 198/1000, Train-Loss : 0.2572, Val-Loss : 0.3299\n",
      "Epoch : 199/1000, Train-Loss : 0.2564, Val-Loss : 0.3291\n",
      "Epoch : 200/1000, Train-Loss : 0.2555, Val-Loss : 0.3283\n",
      "Epoch : 201/1000, Train-Loss : 0.2547, Val-Loss : 0.3275\n",
      "Epoch : 202/1000, Train-Loss : 0.2538, Val-Loss : 0.3267\n",
      "Epoch : 203/1000, Train-Loss : 0.2530, Val-Loss : 0.3259\n",
      "Epoch : 204/1000, Train-Loss : 0.2522, Val-Loss : 0.3251\n",
      "Epoch : 205/1000, Train-Loss : 0.2514, Val-Loss : 0.3243\n",
      "Epoch : 206/1000, Train-Loss : 0.2506, Val-Loss : 0.3236\n",
      "Epoch : 207/1000, Train-Loss : 0.2498, Val-Loss : 0.3228\n",
      "Epoch : 208/1000, Train-Loss : 0.2490, Val-Loss : 0.3220\n",
      "Epoch : 209/1000, Train-Loss : 0.2482, Val-Loss : 0.3213\n",
      "Epoch : 210/1000, Train-Loss : 0.2474, Val-Loss : 0.3205\n",
      "Epoch : 211/1000, Train-Loss : 0.2466, Val-Loss : 0.3198\n",
      "Epoch : 212/1000, Train-Loss : 0.2458, Val-Loss : 0.3190\n",
      "Epoch : 213/1000, Train-Loss : 0.2451, Val-Loss : 0.3183\n",
      "Epoch : 214/1000, Train-Loss : 0.2443, Val-Loss : 0.3175\n",
      "Epoch : 215/1000, Train-Loss : 0.2436, Val-Loss : 0.3168\n",
      "Epoch : 216/1000, Train-Loss : 0.2428, Val-Loss : 0.3161\n",
      "Epoch : 217/1000, Train-Loss : 0.2421, Val-Loss : 0.3153\n",
      "Epoch : 218/1000, Train-Loss : 0.2413, Val-Loss : 0.3146\n",
      "Epoch : 219/1000, Train-Loss : 0.2406, Val-Loss : 0.3139\n",
      "Epoch : 220/1000, Train-Loss : 0.2398, Val-Loss : 0.3132\n",
      "Epoch : 221/1000, Train-Loss : 0.2391, Val-Loss : 0.3125\n",
      "Epoch : 222/1000, Train-Loss : 0.2384, Val-Loss : 0.3118\n",
      "Epoch : 223/1000, Train-Loss : 0.2377, Val-Loss : 0.3111\n",
      "Epoch : 224/1000, Train-Loss : 0.2370, Val-Loss : 0.3104\n",
      "Epoch : 225/1000, Train-Loss : 0.2362, Val-Loss : 0.3097\n",
      "Epoch : 226/1000, Train-Loss : 0.2355, Val-Loss : 0.3090\n",
      "Epoch : 227/1000, Train-Loss : 0.2348, Val-Loss : 0.3083\n",
      "Epoch : 228/1000, Train-Loss : 0.2342, Val-Loss : 0.3076\n",
      "Epoch : 229/1000, Train-Loss : 0.2335, Val-Loss : 0.3070\n",
      "Epoch : 230/1000, Train-Loss : 0.2328, Val-Loss : 0.3063\n",
      "Epoch : 231/1000, Train-Loss : 0.2321, Val-Loss : 0.3056\n",
      "Epoch : 232/1000, Train-Loss : 0.2314, Val-Loss : 0.3050\n",
      "Epoch : 233/1000, Train-Loss : 0.2308, Val-Loss : 0.3043\n",
      "Epoch : 234/1000, Train-Loss : 0.2301, Val-Loss : 0.3037\n",
      "Epoch : 235/1000, Train-Loss : 0.2294, Val-Loss : 0.3030\n",
      "Epoch : 236/1000, Train-Loss : 0.2288, Val-Loss : 0.3024\n",
      "Epoch : 237/1000, Train-Loss : 0.2281, Val-Loss : 0.3017\n",
      "Epoch : 238/1000, Train-Loss : 0.2275, Val-Loss : 0.3011\n",
      "Epoch : 239/1000, Train-Loss : 0.2268, Val-Loss : 0.3005\n",
      "Epoch : 240/1000, Train-Loss : 0.2262, Val-Loss : 0.2998\n",
      "Epoch : 241/1000, Train-Loss : 0.2255, Val-Loss : 0.2992\n",
      "Epoch : 242/1000, Train-Loss : 0.2249, Val-Loss : 0.2986\n",
      "Epoch : 243/1000, Train-Loss : 0.2243, Val-Loss : 0.2980\n",
      "Epoch : 244/1000, Train-Loss : 0.2236, Val-Loss : 0.2973\n",
      "Epoch : 245/1000, Train-Loss : 0.2230, Val-Loss : 0.2967\n",
      "Epoch : 246/1000, Train-Loss : 0.2224, Val-Loss : 0.2961\n",
      "Epoch : 247/1000, Train-Loss : 0.2218, Val-Loss : 0.2955\n",
      "Epoch : 248/1000, Train-Loss : 0.2212, Val-Loss : 0.2949\n",
      "Epoch : 249/1000, Train-Loss : 0.2206, Val-Loss : 0.2943\n",
      "Epoch : 250/1000, Train-Loss : 0.2200, Val-Loss : 0.2937\n",
      "Epoch : 251/1000, Train-Loss : 0.2194, Val-Loss : 0.2931\n",
      "Epoch : 252/1000, Train-Loss : 0.2188, Val-Loss : 0.2925\n",
      "Epoch : 253/1000, Train-Loss : 0.2182, Val-Loss : 0.2920\n",
      "Epoch : 254/1000, Train-Loss : 0.2176, Val-Loss : 0.2914\n",
      "Epoch : 255/1000, Train-Loss : 0.2170, Val-Loss : 0.2908\n",
      "Epoch : 256/1000, Train-Loss : 0.2164, Val-Loss : 0.2902\n",
      "Epoch : 257/1000, Train-Loss : 0.2159, Val-Loss : 0.2897\n",
      "Epoch : 258/1000, Train-Loss : 0.2153, Val-Loss : 0.2891\n",
      "Epoch : 259/1000, Train-Loss : 0.2147, Val-Loss : 0.2885\n",
      "Epoch : 260/1000, Train-Loss : 0.2141, Val-Loss : 0.2880\n",
      "Epoch : 261/1000, Train-Loss : 0.2136, Val-Loss : 0.2874\n",
      "Epoch : 262/1000, Train-Loss : 0.2130, Val-Loss : 0.2869\n",
      "Epoch : 263/1000, Train-Loss : 0.2125, Val-Loss : 0.2863\n",
      "Epoch : 264/1000, Train-Loss : 0.2119, Val-Loss : 0.2857\n",
      "Epoch : 265/1000, Train-Loss : 0.2114, Val-Loss : 0.2852\n",
      "Epoch : 266/1000, Train-Loss : 0.2108, Val-Loss : 0.2847\n",
      "Epoch : 267/1000, Train-Loss : 0.2103, Val-Loss : 0.2841\n",
      "Epoch : 268/1000, Train-Loss : 0.2097, Val-Loss : 0.2836\n",
      "Epoch : 269/1000, Train-Loss : 0.2092, Val-Loss : 0.2831\n",
      "Epoch : 270/1000, Train-Loss : 0.2087, Val-Loss : 0.2825\n",
      "Epoch : 271/1000, Train-Loss : 0.2081, Val-Loss : 0.2820\n",
      "Epoch : 272/1000, Train-Loss : 0.2076, Val-Loss : 0.2815\n",
      "Epoch : 273/1000, Train-Loss : 0.2071, Val-Loss : 0.2809\n",
      "Epoch : 274/1000, Train-Loss : 0.2065, Val-Loss : 0.2804\n",
      "Epoch : 275/1000, Train-Loss : 0.2060, Val-Loss : 0.2799\n",
      "Epoch : 276/1000, Train-Loss : 0.2055, Val-Loss : 0.2794\n",
      "Epoch : 277/1000, Train-Loss : 0.2050, Val-Loss : 0.2789\n",
      "Epoch : 278/1000, Train-Loss : 0.2045, Val-Loss : 0.2784\n",
      "Epoch : 279/1000, Train-Loss : 0.2040, Val-Loss : 0.2779\n",
      "Epoch : 280/1000, Train-Loss : 0.2035, Val-Loss : 0.2774\n",
      "Epoch : 281/1000, Train-Loss : 0.2030, Val-Loss : 0.2769\n",
      "Epoch : 282/1000, Train-Loss : 0.2025, Val-Loss : 0.2764\n",
      "Epoch : 283/1000, Train-Loss : 0.2020, Val-Loss : 0.2759\n",
      "Epoch : 284/1000, Train-Loss : 0.2015, Val-Loss : 0.2754\n",
      "Epoch : 285/1000, Train-Loss : 0.2010, Val-Loss : 0.2749\n",
      "Epoch : 286/1000, Train-Loss : 0.2005, Val-Loss : 0.2744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 287/1000, Train-Loss : 0.2000, Val-Loss : 0.2739\n",
      "Epoch : 288/1000, Train-Loss : 0.1995, Val-Loss : 0.2734\n",
      "Epoch : 289/1000, Train-Loss : 0.1991, Val-Loss : 0.2730\n",
      "Epoch : 290/1000, Train-Loss : 0.1986, Val-Loss : 0.2725\n",
      "Epoch : 291/1000, Train-Loss : 0.1981, Val-Loss : 0.2720\n",
      "Epoch : 292/1000, Train-Loss : 0.1976, Val-Loss : 0.2715\n",
      "Epoch : 293/1000, Train-Loss : 0.1972, Val-Loss : 0.2711\n",
      "Epoch : 294/1000, Train-Loss : 0.1967, Val-Loss : 0.2706\n",
      "Epoch : 295/1000, Train-Loss : 0.1962, Val-Loss : 0.2701\n",
      "Epoch : 296/1000, Train-Loss : 0.1958, Val-Loss : 0.2697\n",
      "Epoch : 297/1000, Train-Loss : 0.1953, Val-Loss : 0.2692\n",
      "Epoch : 298/1000, Train-Loss : 0.1949, Val-Loss : 0.2688\n",
      "Epoch : 299/1000, Train-Loss : 0.1944, Val-Loss : 0.2683\n",
      "Epoch : 300/1000, Train-Loss : 0.1940, Val-Loss : 0.2678\n",
      "Epoch : 301/1000, Train-Loss : 0.1935, Val-Loss : 0.2674\n",
      "Epoch : 302/1000, Train-Loss : 0.1931, Val-Loss : 0.2669\n",
      "Epoch : 303/1000, Train-Loss : 0.1926, Val-Loss : 0.2665\n",
      "Epoch : 304/1000, Train-Loss : 0.1922, Val-Loss : 0.2661\n",
      "Epoch : 305/1000, Train-Loss : 0.1917, Val-Loss : 0.2656\n",
      "Epoch : 306/1000, Train-Loss : 0.1913, Val-Loss : 0.2652\n",
      "Epoch : 307/1000, Train-Loss : 0.1909, Val-Loss : 0.2647\n",
      "Epoch : 308/1000, Train-Loss : 0.1904, Val-Loss : 0.2643\n",
      "Epoch : 309/1000, Train-Loss : 0.1900, Val-Loss : 0.2639\n",
      "Epoch : 310/1000, Train-Loss : 0.1896, Val-Loss : 0.2634\n",
      "Epoch : 311/1000, Train-Loss : 0.1891, Val-Loss : 0.2630\n",
      "Epoch : 312/1000, Train-Loss : 0.1887, Val-Loss : 0.2626\n",
      "Epoch : 313/1000, Train-Loss : 0.1883, Val-Loss : 0.2622\n",
      "Epoch : 314/1000, Train-Loss : 0.1879, Val-Loss : 0.2617\n",
      "Epoch : 315/1000, Train-Loss : 0.1874, Val-Loss : 0.2613\n",
      "Epoch : 316/1000, Train-Loss : 0.1870, Val-Loss : 0.2609\n",
      "Epoch : 317/1000, Train-Loss : 0.1866, Val-Loss : 0.2605\n",
      "Epoch : 318/1000, Train-Loss : 0.1862, Val-Loss : 0.2601\n",
      "Epoch : 319/1000, Train-Loss : 0.1858, Val-Loss : 0.2596\n",
      "Epoch : 320/1000, Train-Loss : 0.1854, Val-Loss : 0.2592\n",
      "Epoch : 321/1000, Train-Loss : 0.1850, Val-Loss : 0.2588\n",
      "Epoch : 322/1000, Train-Loss : 0.1846, Val-Loss : 0.2584\n",
      "Epoch : 323/1000, Train-Loss : 0.1842, Val-Loss : 0.2580\n",
      "Epoch : 324/1000, Train-Loss : 0.1838, Val-Loss : 0.2576\n",
      "Epoch : 325/1000, Train-Loss : 0.1834, Val-Loss : 0.2572\n",
      "Epoch : 326/1000, Train-Loss : 0.1830, Val-Loss : 0.2568\n",
      "Epoch : 327/1000, Train-Loss : 0.1826, Val-Loss : 0.2564\n",
      "Epoch : 328/1000, Train-Loss : 0.1822, Val-Loss : 0.2560\n",
      "Epoch : 329/1000, Train-Loss : 0.1818, Val-Loss : 0.2556\n",
      "Epoch : 330/1000, Train-Loss : 0.1814, Val-Loss : 0.2552\n",
      "Epoch : 331/1000, Train-Loss : 0.1810, Val-Loss : 0.2549\n",
      "Epoch : 332/1000, Train-Loss : 0.1806, Val-Loss : 0.2545\n",
      "Epoch : 333/1000, Train-Loss : 0.1803, Val-Loss : 0.2541\n",
      "Epoch : 334/1000, Train-Loss : 0.1799, Val-Loss : 0.2537\n",
      "Epoch : 335/1000, Train-Loss : 0.1795, Val-Loss : 0.2533\n",
      "Epoch : 336/1000, Train-Loss : 0.1791, Val-Loss : 0.2529\n",
      "Epoch : 337/1000, Train-Loss : 0.1788, Val-Loss : 0.2526\n",
      "Epoch : 338/1000, Train-Loss : 0.1784, Val-Loss : 0.2522\n",
      "Epoch : 339/1000, Train-Loss : 0.1780, Val-Loss : 0.2518\n",
      "Epoch : 340/1000, Train-Loss : 0.1776, Val-Loss : 0.2514\n",
      "Epoch : 341/1000, Train-Loss : 0.1773, Val-Loss : 0.2511\n",
      "Epoch : 342/1000, Train-Loss : 0.1769, Val-Loss : 0.2507\n",
      "Epoch : 343/1000, Train-Loss : 0.1765, Val-Loss : 0.2503\n",
      "Epoch : 344/1000, Train-Loss : 0.1762, Val-Loss : 0.2500\n",
      "Epoch : 345/1000, Train-Loss : 0.1758, Val-Loss : 0.2496\n",
      "Epoch : 346/1000, Train-Loss : 0.1755, Val-Loss : 0.2492\n",
      "Epoch : 347/1000, Train-Loss : 0.1751, Val-Loss : 0.2489\n",
      "Epoch : 348/1000, Train-Loss : 0.1747, Val-Loss : 0.2485\n",
      "Epoch : 349/1000, Train-Loss : 0.1744, Val-Loss : 0.2481\n",
      "Epoch : 350/1000, Train-Loss : 0.1740, Val-Loss : 0.2478\n",
      "Epoch : 351/1000, Train-Loss : 0.1737, Val-Loss : 0.2474\n",
      "Epoch : 352/1000, Train-Loss : 0.1733, Val-Loss : 0.2471\n",
      "Epoch : 353/1000, Train-Loss : 0.1730, Val-Loss : 0.2467\n",
      "Epoch : 354/1000, Train-Loss : 0.1726, Val-Loss : 0.2464\n",
      "Epoch : 355/1000, Train-Loss : 0.1723, Val-Loss : 0.2460\n",
      "Epoch : 356/1000, Train-Loss : 0.1720, Val-Loss : 0.2457\n",
      "Epoch : 357/1000, Train-Loss : 0.1716, Val-Loss : 0.2453\n",
      "Epoch : 358/1000, Train-Loss : 0.1713, Val-Loss : 0.2450\n",
      "Epoch : 359/1000, Train-Loss : 0.1709, Val-Loss : 0.2447\n",
      "Epoch : 360/1000, Train-Loss : 0.1706, Val-Loss : 0.2443\n",
      "Epoch : 361/1000, Train-Loss : 0.1703, Val-Loss : 0.2440\n",
      "Epoch : 362/1000, Train-Loss : 0.1699, Val-Loss : 0.2436\n",
      "Epoch : 363/1000, Train-Loss : 0.1696, Val-Loss : 0.2433\n",
      "Epoch : 364/1000, Train-Loss : 0.1693, Val-Loss : 0.2430\n",
      "Epoch : 365/1000, Train-Loss : 0.1689, Val-Loss : 0.2426\n",
      "Epoch : 366/1000, Train-Loss : 0.1686, Val-Loss : 0.2423\n",
      "Epoch : 367/1000, Train-Loss : 0.1683, Val-Loss : 0.2420\n",
      "Epoch : 368/1000, Train-Loss : 0.1680, Val-Loss : 0.2416\n",
      "Epoch : 369/1000, Train-Loss : 0.1676, Val-Loss : 0.2413\n",
      "Epoch : 370/1000, Train-Loss : 0.1673, Val-Loss : 0.2410\n",
      "Epoch : 371/1000, Train-Loss : 0.1670, Val-Loss : 0.2407\n",
      "Epoch : 372/1000, Train-Loss : 0.1667, Val-Loss : 0.2403\n",
      "Epoch : 373/1000, Train-Loss : 0.1663, Val-Loss : 0.2400\n",
      "Epoch : 374/1000, Train-Loss : 0.1660, Val-Loss : 0.2397\n",
      "Epoch : 375/1000, Train-Loss : 0.1657, Val-Loss : 0.2394\n",
      "Epoch : 376/1000, Train-Loss : 0.1654, Val-Loss : 0.2391\n",
      "Epoch : 377/1000, Train-Loss : 0.1651, Val-Loss : 0.2388\n",
      "Epoch : 378/1000, Train-Loss : 0.1648, Val-Loss : 0.2384\n",
      "Epoch : 379/1000, Train-Loss : 0.1645, Val-Loss : 0.2381\n",
      "Epoch : 380/1000, Train-Loss : 0.1642, Val-Loss : 0.2378\n",
      "Epoch : 381/1000, Train-Loss : 0.1639, Val-Loss : 0.2375\n",
      "Epoch : 382/1000, Train-Loss : 0.1635, Val-Loss : 0.2372\n",
      "Epoch : 383/1000, Train-Loss : 0.1632, Val-Loss : 0.2369\n",
      "Epoch : 384/1000, Train-Loss : 0.1629, Val-Loss : 0.2366\n",
      "Epoch : 385/1000, Train-Loss : 0.1626, Val-Loss : 0.2363\n",
      "Epoch : 386/1000, Train-Loss : 0.1623, Val-Loss : 0.2360\n",
      "Epoch : 387/1000, Train-Loss : 0.1620, Val-Loss : 0.2357\n",
      "Epoch : 388/1000, Train-Loss : 0.1617, Val-Loss : 0.2354\n",
      "Epoch : 389/1000, Train-Loss : 0.1614, Val-Loss : 0.2351\n",
      "Epoch : 390/1000, Train-Loss : 0.1611, Val-Loss : 0.2348\n",
      "Epoch : 391/1000, Train-Loss : 0.1609, Val-Loss : 0.2345\n",
      "Epoch : 392/1000, Train-Loss : 0.1606, Val-Loss : 0.2342\n",
      "Epoch : 393/1000, Train-Loss : 0.1603, Val-Loss : 0.2339\n",
      "Epoch : 394/1000, Train-Loss : 0.1600, Val-Loss : 0.2336\n",
      "Epoch : 395/1000, Train-Loss : 0.1597, Val-Loss : 0.2333\n",
      "Epoch : 396/1000, Train-Loss : 0.1594, Val-Loss : 0.2330\n",
      "Epoch : 397/1000, Train-Loss : 0.1591, Val-Loss : 0.2327\n",
      "Epoch : 398/1000, Train-Loss : 0.1588, Val-Loss : 0.2324\n",
      "Epoch : 399/1000, Train-Loss : 0.1585, Val-Loss : 0.2321\n",
      "Epoch : 400/1000, Train-Loss : 0.1583, Val-Loss : 0.2319\n",
      "Epoch : 401/1000, Train-Loss : 0.1580, Val-Loss : 0.2316\n",
      "Epoch : 402/1000, Train-Loss : 0.1577, Val-Loss : 0.2313\n",
      "Epoch : 403/1000, Train-Loss : 0.1574, Val-Loss : 0.2310\n",
      "Epoch : 404/1000, Train-Loss : 0.1571, Val-Loss : 0.2307\n",
      "Epoch : 405/1000, Train-Loss : 0.1569, Val-Loss : 0.2304\n",
      "Epoch : 406/1000, Train-Loss : 0.1566, Val-Loss : 0.2302\n",
      "Epoch : 407/1000, Train-Loss : 0.1563, Val-Loss : 0.2299\n",
      "Epoch : 408/1000, Train-Loss : 0.1560, Val-Loss : 0.2296\n",
      "Epoch : 409/1000, Train-Loss : 0.1558, Val-Loss : 0.2293\n",
      "Epoch : 410/1000, Train-Loss : 0.1555, Val-Loss : 0.2291\n",
      "Epoch : 411/1000, Train-Loss : 0.1552, Val-Loss : 0.2288\n",
      "Epoch : 412/1000, Train-Loss : 0.1549, Val-Loss : 0.2285\n",
      "Epoch : 413/1000, Train-Loss : 0.1547, Val-Loss : 0.2282\n",
      "Epoch : 414/1000, Train-Loss : 0.1544, Val-Loss : 0.2280\n",
      "Epoch : 415/1000, Train-Loss : 0.1541, Val-Loss : 0.2277\n",
      "Epoch : 416/1000, Train-Loss : 0.1539, Val-Loss : 0.2274\n",
      "Epoch : 417/1000, Train-Loss : 0.1536, Val-Loss : 0.2272\n",
      "Epoch : 418/1000, Train-Loss : 0.1533, Val-Loss : 0.2269\n",
      "Epoch : 419/1000, Train-Loss : 0.1531, Val-Loss : 0.2266\n",
      "Epoch : 420/1000, Train-Loss : 0.1528, Val-Loss : 0.2264\n",
      "Epoch : 421/1000, Train-Loss : 0.1526, Val-Loss : 0.2261\n",
      "Epoch : 422/1000, Train-Loss : 0.1523, Val-Loss : 0.2259\n",
      "Epoch : 423/1000, Train-Loss : 0.1520, Val-Loss : 0.2256\n",
      "Epoch : 424/1000, Train-Loss : 0.1518, Val-Loss : 0.2253\n",
      "Epoch : 425/1000, Train-Loss : 0.1515, Val-Loss : 0.2251\n",
      "Epoch : 426/1000, Train-Loss : 0.1513, Val-Loss : 0.2248\n",
      "Epoch : 427/1000, Train-Loss : 0.1510, Val-Loss : 0.2246\n",
      "Epoch : 428/1000, Train-Loss : 0.1508, Val-Loss : 0.2243\n",
      "Epoch : 429/1000, Train-Loss : 0.1505, Val-Loss : 0.2241\n",
      "Epoch : 430/1000, Train-Loss : 0.1503, Val-Loss : 0.2238\n",
      "Epoch : 431/1000, Train-Loss : 0.1500, Val-Loss : 0.2236\n",
      "Epoch : 432/1000, Train-Loss : 0.1498, Val-Loss : 0.2233\n",
      "Epoch : 433/1000, Train-Loss : 0.1495, Val-Loss : 0.2231\n",
      "Epoch : 434/1000, Train-Loss : 0.1493, Val-Loss : 0.2228\n",
      "Epoch : 435/1000, Train-Loss : 0.1490, Val-Loss : 0.2226\n",
      "Epoch : 436/1000, Train-Loss : 0.1488, Val-Loss : 0.2223\n",
      "Epoch : 437/1000, Train-Loss : 0.1485, Val-Loss : 0.2221\n",
      "Epoch : 438/1000, Train-Loss : 0.1483, Val-Loss : 0.2218\n",
      "Epoch : 439/1000, Train-Loss : 0.1480, Val-Loss : 0.2216\n",
      "Epoch : 440/1000, Train-Loss : 0.1478, Val-Loss : 0.2214\n",
      "Epoch : 441/1000, Train-Loss : 0.1476, Val-Loss : 0.2211\n",
      "Epoch : 442/1000, Train-Loss : 0.1473, Val-Loss : 0.2209\n",
      "Epoch : 443/1000, Train-Loss : 0.1471, Val-Loss : 0.2206\n",
      "Epoch : 444/1000, Train-Loss : 0.1468, Val-Loss : 0.2204\n",
      "Epoch : 445/1000, Train-Loss : 0.1466, Val-Loss : 0.2202\n",
      "Epoch : 446/1000, Train-Loss : 0.1464, Val-Loss : 0.2199\n",
      "Epoch : 447/1000, Train-Loss : 0.1461, Val-Loss : 0.2197\n",
      "Epoch : 448/1000, Train-Loss : 0.1459, Val-Loss : 0.2195\n",
      "Epoch : 449/1000, Train-Loss : 0.1457, Val-Loss : 0.2192\n",
      "Epoch : 450/1000, Train-Loss : 0.1454, Val-Loss : 0.2190\n",
      "Epoch : 451/1000, Train-Loss : 0.1452, Val-Loss : 0.2188\n",
      "Epoch : 452/1000, Train-Loss : 0.1450, Val-Loss : 0.2185\n",
      "Epoch : 453/1000, Train-Loss : 0.1447, Val-Loss : 0.2183\n",
      "Epoch : 454/1000, Train-Loss : 0.1445, Val-Loss : 0.2181\n",
      "Epoch : 455/1000, Train-Loss : 0.1443, Val-Loss : 0.2178\n",
      "Epoch : 456/1000, Train-Loss : 0.1441, Val-Loss : 0.2176\n",
      "Epoch : 457/1000, Train-Loss : 0.1438, Val-Loss : 0.2174\n",
      "Epoch : 458/1000, Train-Loss : 0.1436, Val-Loss : 0.2172\n",
      "Epoch : 459/1000, Train-Loss : 0.1434, Val-Loss : 0.2169\n",
      "Epoch : 460/1000, Train-Loss : 0.1431, Val-Loss : 0.2167\n",
      "Epoch : 461/1000, Train-Loss : 0.1429, Val-Loss : 0.2165\n",
      "Epoch : 462/1000, Train-Loss : 0.1427, Val-Loss : 0.2163\n",
      "Epoch : 463/1000, Train-Loss : 0.1425, Val-Loss : 0.2161\n",
      "Epoch : 464/1000, Train-Loss : 0.1423, Val-Loss : 0.2158\n",
      "Epoch : 465/1000, Train-Loss : 0.1420, Val-Loss : 0.2156\n",
      "Epoch : 466/1000, Train-Loss : 0.1418, Val-Loss : 0.2154\n",
      "Epoch : 467/1000, Train-Loss : 0.1416, Val-Loss : 0.2152\n",
      "Epoch : 468/1000, Train-Loss : 0.1414, Val-Loss : 0.2150\n",
      "Epoch : 469/1000, Train-Loss : 0.1412, Val-Loss : 0.2148\n",
      "Epoch : 470/1000, Train-Loss : 0.1409, Val-Loss : 0.2145\n",
      "Epoch : 471/1000, Train-Loss : 0.1407, Val-Loss : 0.2143\n",
      "Epoch : 472/1000, Train-Loss : 0.1405, Val-Loss : 0.2141\n",
      "Epoch : 473/1000, Train-Loss : 0.1403, Val-Loss : 0.2139\n",
      "Epoch : 474/1000, Train-Loss : 0.1401, Val-Loss : 0.2137\n",
      "Epoch : 475/1000, Train-Loss : 0.1399, Val-Loss : 0.2135\n",
      "Epoch : 476/1000, Train-Loss : 0.1397, Val-Loss : 0.2133\n",
      "Epoch : 477/1000, Train-Loss : 0.1394, Val-Loss : 0.2131\n",
      "Epoch : 478/1000, Train-Loss : 0.1392, Val-Loss : 0.2129\n",
      "Epoch : 479/1000, Train-Loss : 0.1390, Val-Loss : 0.2126\n",
      "Epoch : 480/1000, Train-Loss : 0.1388, Val-Loss : 0.2124\n",
      "Epoch : 481/1000, Train-Loss : 0.1386, Val-Loss : 0.2122\n",
      "Epoch : 482/1000, Train-Loss : 0.1384, Val-Loss : 0.2120\n",
      "Epoch : 483/1000, Train-Loss : 0.1382, Val-Loss : 0.2118\n",
      "Epoch : 484/1000, Train-Loss : 0.1380, Val-Loss : 0.2116\n",
      "Epoch : 485/1000, Train-Loss : 0.1378, Val-Loss : 0.2114\n",
      "Epoch : 486/1000, Train-Loss : 0.1376, Val-Loss : 0.2112\n",
      "Epoch : 487/1000, Train-Loss : 0.1374, Val-Loss : 0.2110\n",
      "Epoch : 488/1000, Train-Loss : 0.1372, Val-Loss : 0.2108\n",
      "Epoch : 489/1000, Train-Loss : 0.1370, Val-Loss : 0.2106\n",
      "Epoch : 490/1000, Train-Loss : 0.1368, Val-Loss : 0.2104\n",
      "Epoch : 491/1000, Train-Loss : 0.1366, Val-Loss : 0.2102\n",
      "Epoch : 492/1000, Train-Loss : 0.1364, Val-Loss : 0.2100\n",
      "Epoch : 493/1000, Train-Loss : 0.1362, Val-Loss : 0.2098\n",
      "Epoch : 494/1000, Train-Loss : 0.1360, Val-Loss : 0.2096\n",
      "Epoch : 495/1000, Train-Loss : 0.1358, Val-Loss : 0.2095\n",
      "Epoch : 496/1000, Train-Loss : 0.1356, Val-Loss : 0.2093\n",
      "Epoch : 497/1000, Train-Loss : 0.1354, Val-Loss : 0.2091\n",
      "Epoch : 498/1000, Train-Loss : 0.1352, Val-Loss : 0.2089\n",
      "Epoch : 499/1000, Train-Loss : 0.1350, Val-Loss : 0.2087\n",
      "Epoch : 500/1000, Train-Loss : 0.1348, Val-Loss : 0.2085\n",
      "Epoch : 501/1000, Train-Loss : 0.1346, Val-Loss : 0.2083\n",
      "Epoch : 502/1000, Train-Loss : 0.1344, Val-Loss : 0.2081\n",
      "Epoch : 503/1000, Train-Loss : 0.1342, Val-Loss : 0.2079\n",
      "Epoch : 504/1000, Train-Loss : 0.1340, Val-Loss : 0.2077\n",
      "Epoch : 505/1000, Train-Loss : 0.1338, Val-Loss : 0.2076\n",
      "Epoch : 506/1000, Train-Loss : 0.1336, Val-Loss : 0.2074\n",
      "Epoch : 507/1000, Train-Loss : 0.1334, Val-Loss : 0.2072\n",
      "Epoch : 508/1000, Train-Loss : 0.1332, Val-Loss : 0.2070\n",
      "Epoch : 509/1000, Train-Loss : 0.1331, Val-Loss : 0.2068\n",
      "Epoch : 510/1000, Train-Loss : 0.1329, Val-Loss : 0.2066\n",
      "Epoch : 511/1000, Train-Loss : 0.1327, Val-Loss : 0.2065\n",
      "Epoch : 512/1000, Train-Loss : 0.1325, Val-Loss : 0.2063\n",
      "Epoch : 513/1000, Train-Loss : 0.1323, Val-Loss : 0.2061\n",
      "Epoch : 514/1000, Train-Loss : 0.1321, Val-Loss : 0.2059\n",
      "Epoch : 515/1000, Train-Loss : 0.1319, Val-Loss : 0.2057\n",
      "Epoch : 516/1000, Train-Loss : 0.1317, Val-Loss : 0.2056\n",
      "Epoch : 517/1000, Train-Loss : 0.1316, Val-Loss : 0.2054\n",
      "Epoch : 518/1000, Train-Loss : 0.1314, Val-Loss : 0.2052\n",
      "Epoch : 519/1000, Train-Loss : 0.1312, Val-Loss : 0.2050\n",
      "Epoch : 520/1000, Train-Loss : 0.1310, Val-Loss : 0.2048\n",
      "Epoch : 521/1000, Train-Loss : 0.1308, Val-Loss : 0.2047\n",
      "Epoch : 522/1000, Train-Loss : 0.1306, Val-Loss : 0.2045\n",
      "Epoch : 523/1000, Train-Loss : 0.1305, Val-Loss : 0.2043\n",
      "Epoch : 524/1000, Train-Loss : 0.1303, Val-Loss : 0.2041\n",
      "Epoch : 525/1000, Train-Loss : 0.1301, Val-Loss : 0.2040\n",
      "Epoch : 526/1000, Train-Loss : 0.1299, Val-Loss : 0.2038\n",
      "Epoch : 527/1000, Train-Loss : 0.1298, Val-Loss : 0.2036\n",
      "Epoch : 528/1000, Train-Loss : 0.1296, Val-Loss : 0.2035\n",
      "Epoch : 529/1000, Train-Loss : 0.1294, Val-Loss : 0.2033\n",
      "Epoch : 530/1000, Train-Loss : 0.1292, Val-Loss : 0.2031\n",
      "Epoch : 531/1000, Train-Loss : 0.1290, Val-Loss : 0.2030\n",
      "Epoch : 532/1000, Train-Loss : 0.1289, Val-Loss : 0.2028\n",
      "Epoch : 533/1000, Train-Loss : 0.1287, Val-Loss : 0.2026\n",
      "Epoch : 534/1000, Train-Loss : 0.1285, Val-Loss : 0.2025\n",
      "Epoch : 535/1000, Train-Loss : 0.1283, Val-Loss : 0.2023\n",
      "Epoch : 536/1000, Train-Loss : 0.1282, Val-Loss : 0.2021\n",
      "Epoch : 537/1000, Train-Loss : 0.1280, Val-Loss : 0.2020\n",
      "Epoch : 538/1000, Train-Loss : 0.1278, Val-Loss : 0.2018\n",
      "Epoch : 539/1000, Train-Loss : 0.1277, Val-Loss : 0.2016\n",
      "Epoch : 540/1000, Train-Loss : 0.1275, Val-Loss : 0.2015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 541/1000, Train-Loss : 0.1273, Val-Loss : 0.2013\n",
      "Epoch : 542/1000, Train-Loss : 0.1271, Val-Loss : 0.2011\n",
      "Epoch : 543/1000, Train-Loss : 0.1270, Val-Loss : 0.2010\n",
      "Epoch : 544/1000, Train-Loss : 0.1268, Val-Loss : 0.2008\n",
      "Epoch : 545/1000, Train-Loss : 0.1266, Val-Loss : 0.2007\n",
      "Epoch : 546/1000, Train-Loss : 0.1265, Val-Loss : 0.2005\n",
      "Epoch : 547/1000, Train-Loss : 0.1263, Val-Loss : 0.2003\n",
      "Epoch : 548/1000, Train-Loss : 0.1261, Val-Loss : 0.2002\n",
      "Epoch : 549/1000, Train-Loss : 0.1260, Val-Loss : 0.2000\n",
      "Epoch : 550/1000, Train-Loss : 0.1258, Val-Loss : 0.1999\n",
      "Epoch : 551/1000, Train-Loss : 0.1256, Val-Loss : 0.1997\n",
      "Epoch : 552/1000, Train-Loss : 0.1255, Val-Loss : 0.1996\n",
      "Epoch : 553/1000, Train-Loss : 0.1253, Val-Loss : 0.1994\n",
      "Epoch : 554/1000, Train-Loss : 0.1251, Val-Loss : 0.1993\n",
      "Epoch : 555/1000, Train-Loss : 0.1250, Val-Loss : 0.1991\n",
      "Epoch : 556/1000, Train-Loss : 0.1248, Val-Loss : 0.1989\n",
      "Epoch : 557/1000, Train-Loss : 0.1246, Val-Loss : 0.1988\n",
      "Epoch : 558/1000, Train-Loss : 0.1245, Val-Loss : 0.1986\n",
      "Epoch : 559/1000, Train-Loss : 0.1243, Val-Loss : 0.1985\n",
      "Epoch : 560/1000, Train-Loss : 0.1242, Val-Loss : 0.1983\n",
      "Epoch : 561/1000, Train-Loss : 0.1240, Val-Loss : 0.1982\n",
      "Epoch : 562/1000, Train-Loss : 0.1238, Val-Loss : 0.1980\n",
      "Epoch : 563/1000, Train-Loss : 0.1237, Val-Loss : 0.1979\n",
      "Epoch : 564/1000, Train-Loss : 0.1235, Val-Loss : 0.1977\n",
      "Epoch : 565/1000, Train-Loss : 0.1234, Val-Loss : 0.1976\n",
      "Epoch : 566/1000, Train-Loss : 0.1232, Val-Loss : 0.1974\n",
      "Epoch : 567/1000, Train-Loss : 0.1231, Val-Loss : 0.1973\n",
      "Epoch : 568/1000, Train-Loss : 0.1229, Val-Loss : 0.1972\n",
      "Epoch : 569/1000, Train-Loss : 0.1227, Val-Loss : 0.1970\n",
      "Epoch : 570/1000, Train-Loss : 0.1226, Val-Loss : 0.1969\n",
      "Epoch : 571/1000, Train-Loss : 0.1224, Val-Loss : 0.1967\n",
      "Epoch : 572/1000, Train-Loss : 0.1223, Val-Loss : 0.1966\n",
      "Epoch : 573/1000, Train-Loss : 0.1221, Val-Loss : 0.1964\n",
      "Epoch : 574/1000, Train-Loss : 0.1220, Val-Loss : 0.1963\n",
      "Epoch : 575/1000, Train-Loss : 0.1218, Val-Loss : 0.1961\n",
      "Epoch : 576/1000, Train-Loss : 0.1217, Val-Loss : 0.1960\n",
      "Epoch : 577/1000, Train-Loss : 0.1215, Val-Loss : 0.1959\n",
      "Epoch : 578/1000, Train-Loss : 0.1213, Val-Loss : 0.1957\n",
      "Epoch : 579/1000, Train-Loss : 0.1212, Val-Loss : 0.1956\n",
      "Epoch : 580/1000, Train-Loss : 0.1210, Val-Loss : 0.1954\n",
      "Epoch : 581/1000, Train-Loss : 0.1209, Val-Loss : 0.1953\n",
      "Epoch : 582/1000, Train-Loss : 0.1207, Val-Loss : 0.1952\n",
      "Epoch : 583/1000, Train-Loss : 0.1206, Val-Loss : 0.1950\n",
      "Epoch : 584/1000, Train-Loss : 0.1204, Val-Loss : 0.1949\n",
      "Epoch : 585/1000, Train-Loss : 0.1203, Val-Loss : 0.1947\n",
      "Epoch : 586/1000, Train-Loss : 0.1201, Val-Loss : 0.1946\n",
      "Epoch : 587/1000, Train-Loss : 0.1200, Val-Loss : 0.1945\n",
      "Epoch : 588/1000, Train-Loss : 0.1199, Val-Loss : 0.1943\n",
      "Epoch : 589/1000, Train-Loss : 0.1197, Val-Loss : 0.1942\n",
      "Epoch : 590/1000, Train-Loss : 0.1196, Val-Loss : 0.1941\n",
      "Epoch : 591/1000, Train-Loss : 0.1194, Val-Loss : 0.1939\n",
      "Epoch : 592/1000, Train-Loss : 0.1193, Val-Loss : 0.1938\n",
      "Epoch : 593/1000, Train-Loss : 0.1191, Val-Loss : 0.1937\n",
      "Epoch : 594/1000, Train-Loss : 0.1190, Val-Loss : 0.1935\n",
      "Epoch : 595/1000, Train-Loss : 0.1188, Val-Loss : 0.1934\n",
      "Epoch : 596/1000, Train-Loss : 0.1187, Val-Loss : 0.1933\n",
      "Epoch : 597/1000, Train-Loss : 0.1185, Val-Loss : 0.1931\n",
      "Epoch : 598/1000, Train-Loss : 0.1184, Val-Loss : 0.1930\n",
      "Epoch : 599/1000, Train-Loss : 0.1183, Val-Loss : 0.1929\n",
      "Epoch : 600/1000, Train-Loss : 0.1181, Val-Loss : 0.1927\n",
      "Epoch : 601/1000, Train-Loss : 0.1180, Val-Loss : 0.1926\n",
      "Epoch : 602/1000, Train-Loss : 0.1178, Val-Loss : 0.1925\n",
      "Epoch : 603/1000, Train-Loss : 0.1177, Val-Loss : 0.1924\n",
      "Epoch : 604/1000, Train-Loss : 0.1175, Val-Loss : 0.1922\n",
      "Epoch : 605/1000, Train-Loss : 0.1174, Val-Loss : 0.1921\n",
      "Epoch : 606/1000, Train-Loss : 0.1173, Val-Loss : 0.1920\n",
      "Epoch : 607/1000, Train-Loss : 0.1171, Val-Loss : 0.1918\n",
      "Epoch : 608/1000, Train-Loss : 0.1170, Val-Loss : 0.1917\n",
      "Epoch : 609/1000, Train-Loss : 0.1168, Val-Loss : 0.1916\n",
      "Epoch : 610/1000, Train-Loss : 0.1167, Val-Loss : 0.1915\n",
      "Epoch : 611/1000, Train-Loss : 0.1166, Val-Loss : 0.1913\n",
      "Epoch : 612/1000, Train-Loss : 0.1164, Val-Loss : 0.1912\n",
      "Epoch : 613/1000, Train-Loss : 0.1163, Val-Loss : 0.1911\n",
      "Epoch : 614/1000, Train-Loss : 0.1161, Val-Loss : 0.1910\n",
      "Epoch : 615/1000, Train-Loss : 0.1160, Val-Loss : 0.1908\n",
      "Epoch : 616/1000, Train-Loss : 0.1159, Val-Loss : 0.1907\n",
      "Epoch : 617/1000, Train-Loss : 0.1157, Val-Loss : 0.1906\n",
      "Epoch : 618/1000, Train-Loss : 0.1156, Val-Loss : 0.1905\n",
      "Epoch : 619/1000, Train-Loss : 0.1155, Val-Loss : 0.1904\n",
      "Epoch : 620/1000, Train-Loss : 0.1153, Val-Loss : 0.1902\n",
      "Epoch : 621/1000, Train-Loss : 0.1152, Val-Loss : 0.1901\n",
      "Epoch : 622/1000, Train-Loss : 0.1151, Val-Loss : 0.1900\n",
      "Epoch : 623/1000, Train-Loss : 0.1149, Val-Loss : 0.1899\n",
      "Epoch : 624/1000, Train-Loss : 0.1148, Val-Loss : 0.1898\n",
      "Epoch : 625/1000, Train-Loss : 0.1147, Val-Loss : 0.1896\n",
      "Epoch : 626/1000, Train-Loss : 0.1145, Val-Loss : 0.1895\n",
      "Epoch : 627/1000, Train-Loss : 0.1144, Val-Loss : 0.1894\n",
      "Epoch : 628/1000, Train-Loss : 0.1143, Val-Loss : 0.1893\n",
      "Epoch : 629/1000, Train-Loss : 0.1141, Val-Loss : 0.1892\n",
      "Epoch : 630/1000, Train-Loss : 0.1140, Val-Loss : 0.1891\n",
      "Epoch : 631/1000, Train-Loss : 0.1139, Val-Loss : 0.1889\n",
      "Epoch : 632/1000, Train-Loss : 0.1137, Val-Loss : 0.1888\n",
      "Epoch : 633/1000, Train-Loss : 0.1136, Val-Loss : 0.1887\n",
      "Epoch : 634/1000, Train-Loss : 0.1135, Val-Loss : 0.1886\n",
      "Epoch : 635/1000, Train-Loss : 0.1134, Val-Loss : 0.1885\n",
      "Epoch : 636/1000, Train-Loss : 0.1132, Val-Loss : 0.1884\n",
      "Epoch : 637/1000, Train-Loss : 0.1131, Val-Loss : 0.1882\n",
      "Epoch : 638/1000, Train-Loss : 0.1130, Val-Loss : 0.1881\n",
      "Epoch : 639/1000, Train-Loss : 0.1128, Val-Loss : 0.1880\n",
      "Epoch : 640/1000, Train-Loss : 0.1127, Val-Loss : 0.1879\n",
      "Epoch : 641/1000, Train-Loss : 0.1126, Val-Loss : 0.1878\n",
      "Epoch : 642/1000, Train-Loss : 0.1125, Val-Loss : 0.1877\n",
      "Epoch : 643/1000, Train-Loss : 0.1123, Val-Loss : 0.1876\n",
      "Epoch : 644/1000, Train-Loss : 0.1122, Val-Loss : 0.1875\n",
      "Epoch : 645/1000, Train-Loss : 0.1121, Val-Loss : 0.1873\n",
      "Epoch : 646/1000, Train-Loss : 0.1119, Val-Loss : 0.1872\n",
      "Epoch : 647/1000, Train-Loss : 0.1118, Val-Loss : 0.1871\n",
      "Epoch : 648/1000, Train-Loss : 0.1117, Val-Loss : 0.1870\n",
      "Epoch : 649/1000, Train-Loss : 0.1116, Val-Loss : 0.1869\n",
      "Epoch : 650/1000, Train-Loss : 0.1114, Val-Loss : 0.1868\n",
      "Epoch : 651/1000, Train-Loss : 0.1113, Val-Loss : 0.1867\n",
      "Epoch : 652/1000, Train-Loss : 0.1112, Val-Loss : 0.1866\n",
      "Epoch : 653/1000, Train-Loss : 0.1111, Val-Loss : 0.1865\n",
      "Epoch : 654/1000, Train-Loss : 0.1110, Val-Loss : 0.1864\n",
      "Epoch : 655/1000, Train-Loss : 0.1108, Val-Loss : 0.1863\n",
      "Epoch : 656/1000, Train-Loss : 0.1107, Val-Loss : 0.1862\n",
      "Epoch : 657/1000, Train-Loss : 0.1106, Val-Loss : 0.1860\n",
      "Epoch : 658/1000, Train-Loss : 0.1105, Val-Loss : 0.1859\n",
      "Epoch : 659/1000, Train-Loss : 0.1103, Val-Loss : 0.1858\n",
      "Epoch : 660/1000, Train-Loss : 0.1102, Val-Loss : 0.1857\n",
      "Epoch : 661/1000, Train-Loss : 0.1101, Val-Loss : 0.1856\n",
      "Epoch : 662/1000, Train-Loss : 0.1100, Val-Loss : 0.1855\n",
      "Epoch : 663/1000, Train-Loss : 0.1099, Val-Loss : 0.1854\n",
      "Epoch : 664/1000, Train-Loss : 0.1097, Val-Loss : 0.1853\n",
      "Epoch : 665/1000, Train-Loss : 0.1096, Val-Loss : 0.1852\n",
      "Epoch : 666/1000, Train-Loss : 0.1095, Val-Loss : 0.1851\n",
      "Epoch : 667/1000, Train-Loss : 0.1094, Val-Loss : 0.1850\n",
      "Epoch : 668/1000, Train-Loss : 0.1093, Val-Loss : 0.1849\n",
      "Epoch : 669/1000, Train-Loss : 0.1091, Val-Loss : 0.1848\n",
      "Epoch : 670/1000, Train-Loss : 0.1090, Val-Loss : 0.1847\n",
      "Epoch : 671/1000, Train-Loss : 0.1089, Val-Loss : 0.1846\n",
      "Epoch : 672/1000, Train-Loss : 0.1088, Val-Loss : 0.1845\n",
      "Epoch : 673/1000, Train-Loss : 0.1087, Val-Loss : 0.1844\n",
      "Epoch : 674/1000, Train-Loss : 0.1086, Val-Loss : 0.1843\n",
      "Epoch : 675/1000, Train-Loss : 0.1084, Val-Loss : 0.1842\n",
      "Epoch : 676/1000, Train-Loss : 0.1083, Val-Loss : 0.1841\n",
      "Epoch : 677/1000, Train-Loss : 0.1082, Val-Loss : 0.1840\n",
      "Epoch : 678/1000, Train-Loss : 0.1081, Val-Loss : 0.1839\n",
      "Epoch : 679/1000, Train-Loss : 0.1080, Val-Loss : 0.1838\n",
      "Epoch : 680/1000, Train-Loss : 0.1079, Val-Loss : 0.1837\n",
      "Epoch : 681/1000, Train-Loss : 0.1077, Val-Loss : 0.1836\n",
      "Epoch : 682/1000, Train-Loss : 0.1076, Val-Loss : 0.1835\n",
      "Epoch : 683/1000, Train-Loss : 0.1075, Val-Loss : 0.1834\n",
      "Epoch : 684/1000, Train-Loss : 0.1074, Val-Loss : 0.1833\n",
      "Epoch : 685/1000, Train-Loss : 0.1073, Val-Loss : 0.1832\n",
      "Epoch : 686/1000, Train-Loss : 0.1072, Val-Loss : 0.1831\n",
      "Epoch : 687/1000, Train-Loss : 0.1071, Val-Loss : 0.1830\n",
      "Epoch : 688/1000, Train-Loss : 0.1070, Val-Loss : 0.1829\n",
      "Epoch : 689/1000, Train-Loss : 0.1068, Val-Loss : 0.1828\n",
      "Epoch : 690/1000, Train-Loss : 0.1067, Val-Loss : 0.1827\n",
      "Epoch : 691/1000, Train-Loss : 0.1066, Val-Loss : 0.1826\n",
      "Epoch : 692/1000, Train-Loss : 0.1065, Val-Loss : 0.1825\n",
      "Epoch : 693/1000, Train-Loss : 0.1064, Val-Loss : 0.1825\n",
      "Epoch : 694/1000, Train-Loss : 0.1063, Val-Loss : 0.1824\n",
      "Epoch : 695/1000, Train-Loss : 0.1062, Val-Loss : 0.1823\n",
      "Epoch : 696/1000, Train-Loss : 0.1061, Val-Loss : 0.1822\n",
      "Epoch : 697/1000, Train-Loss : 0.1059, Val-Loss : 0.1821\n",
      "Epoch : 698/1000, Train-Loss : 0.1058, Val-Loss : 0.1820\n",
      "Epoch : 699/1000, Train-Loss : 0.1057, Val-Loss : 0.1819\n",
      "Epoch : 700/1000, Train-Loss : 0.1056, Val-Loss : 0.1818\n",
      "Epoch : 701/1000, Train-Loss : 0.1055, Val-Loss : 0.1817\n",
      "Epoch : 702/1000, Train-Loss : 0.1054, Val-Loss : 0.1816\n",
      "Epoch : 703/1000, Train-Loss : 0.1053, Val-Loss : 0.1815\n",
      "Epoch : 704/1000, Train-Loss : 0.1052, Val-Loss : 0.1814\n",
      "Epoch : 705/1000, Train-Loss : 0.1051, Val-Loss : 0.1813\n",
      "Epoch : 706/1000, Train-Loss : 0.1050, Val-Loss : 0.1813\n",
      "Epoch : 707/1000, Train-Loss : 0.1049, Val-Loss : 0.1812\n",
      "Epoch : 708/1000, Train-Loss : 0.1048, Val-Loss : 0.1811\n",
      "Epoch : 709/1000, Train-Loss : 0.1046, Val-Loss : 0.1810\n",
      "Epoch : 710/1000, Train-Loss : 0.1045, Val-Loss : 0.1809\n",
      "Epoch : 711/1000, Train-Loss : 0.1044, Val-Loss : 0.1808\n",
      "Epoch : 712/1000, Train-Loss : 0.1043, Val-Loss : 0.1807\n",
      "Epoch : 713/1000, Train-Loss : 0.1042, Val-Loss : 0.1806\n",
      "Epoch : 714/1000, Train-Loss : 0.1041, Val-Loss : 0.1805\n",
      "Epoch : 715/1000, Train-Loss : 0.1040, Val-Loss : 0.1805\n",
      "Epoch : 716/1000, Train-Loss : 0.1039, Val-Loss : 0.1804\n",
      "Epoch : 717/1000, Train-Loss : 0.1038, Val-Loss : 0.1803\n",
      "Epoch : 718/1000, Train-Loss : 0.1037, Val-Loss : 0.1802\n",
      "Epoch : 719/1000, Train-Loss : 0.1036, Val-Loss : 0.1801\n",
      "Epoch : 720/1000, Train-Loss : 0.1035, Val-Loss : 0.1800\n",
      "Epoch : 721/1000, Train-Loss : 0.1034, Val-Loss : 0.1799\n",
      "Epoch : 722/1000, Train-Loss : 0.1033, Val-Loss : 0.1799\n",
      "Epoch : 723/1000, Train-Loss : 0.1032, Val-Loss : 0.1798\n",
      "Epoch : 724/1000, Train-Loss : 0.1031, Val-Loss : 0.1797\n",
      "Epoch : 725/1000, Train-Loss : 0.1030, Val-Loss : 0.1796\n",
      "Epoch : 726/1000, Train-Loss : 0.1029, Val-Loss : 0.1795\n",
      "Epoch : 727/1000, Train-Loss : 0.1028, Val-Loss : 0.1794\n",
      "Epoch : 728/1000, Train-Loss : 0.1027, Val-Loss : 0.1793\n",
      "Epoch : 729/1000, Train-Loss : 0.1026, Val-Loss : 0.1793\n",
      "Epoch : 730/1000, Train-Loss : 0.1025, Val-Loss : 0.1792\n",
      "Epoch : 731/1000, Train-Loss : 0.1024, Val-Loss : 0.1791\n",
      "Epoch : 732/1000, Train-Loss : 0.1023, Val-Loss : 0.1790\n",
      "Epoch : 733/1000, Train-Loss : 0.1021, Val-Loss : 0.1789\n",
      "Epoch : 734/1000, Train-Loss : 0.1020, Val-Loss : 0.1788\n",
      "Epoch : 735/1000, Train-Loss : 0.1019, Val-Loss : 0.1788\n",
      "Epoch : 736/1000, Train-Loss : 0.1018, Val-Loss : 0.1787\n",
      "Epoch : 737/1000, Train-Loss : 0.1017, Val-Loss : 0.1786\n",
      "Epoch : 738/1000, Train-Loss : 0.1016, Val-Loss : 0.1785\n",
      "Epoch : 739/1000, Train-Loss : 0.1015, Val-Loss : 0.1784\n",
      "Epoch : 740/1000, Train-Loss : 0.1014, Val-Loss : 0.1784\n",
      "Epoch : 741/1000, Train-Loss : 0.1013, Val-Loss : 0.1783\n",
      "Epoch : 742/1000, Train-Loss : 0.1013, Val-Loss : 0.1782\n",
      "Epoch : 743/1000, Train-Loss : 0.1012, Val-Loss : 0.1781\n",
      "Epoch : 744/1000, Train-Loss : 0.1011, Val-Loss : 0.1780\n",
      "Epoch : 745/1000, Train-Loss : 0.1010, Val-Loss : 0.1780\n",
      "Epoch : 746/1000, Train-Loss : 0.1009, Val-Loss : 0.1779\n",
      "Epoch : 747/1000, Train-Loss : 0.1008, Val-Loss : 0.1778\n",
      "Epoch : 748/1000, Train-Loss : 0.1007, Val-Loss : 0.1777\n",
      "Epoch : 749/1000, Train-Loss : 0.1006, Val-Loss : 0.1776\n",
      "Epoch : 750/1000, Train-Loss : 0.1005, Val-Loss : 0.1776\n",
      "Epoch : 751/1000, Train-Loss : 0.1004, Val-Loss : 0.1775\n",
      "Epoch : 752/1000, Train-Loss : 0.1003, Val-Loss : 0.1774\n",
      "Epoch : 753/1000, Train-Loss : 0.1002, Val-Loss : 0.1773\n",
      "Epoch : 754/1000, Train-Loss : 0.1001, Val-Loss : 0.1772\n",
      "Epoch : 755/1000, Train-Loss : 0.1000, Val-Loss : 0.1772\n",
      "Epoch : 756/1000, Train-Loss : 0.0999, Val-Loss : 0.1771\n",
      "Epoch : 757/1000, Train-Loss : 0.0998, Val-Loss : 0.1770\n",
      "Epoch : 758/1000, Train-Loss : 0.0997, Val-Loss : 0.1769\n",
      "Epoch : 759/1000, Train-Loss : 0.0996, Val-Loss : 0.1769\n",
      "Epoch : 760/1000, Train-Loss : 0.0995, Val-Loss : 0.1768\n",
      "Epoch : 761/1000, Train-Loss : 0.0994, Val-Loss : 0.1767\n",
      "Epoch : 762/1000, Train-Loss : 0.0993, Val-Loss : 0.1766\n",
      "Epoch : 763/1000, Train-Loss : 0.0992, Val-Loss : 0.1766\n",
      "Epoch : 764/1000, Train-Loss : 0.0991, Val-Loss : 0.1765\n",
      "Epoch : 765/1000, Train-Loss : 0.0990, Val-Loss : 0.1764\n",
      "Epoch : 766/1000, Train-Loss : 0.0989, Val-Loss : 0.1763\n",
      "Epoch : 767/1000, Train-Loss : 0.0988, Val-Loss : 0.1763\n",
      "Epoch : 768/1000, Train-Loss : 0.0988, Val-Loss : 0.1762\n",
      "Epoch : 769/1000, Train-Loss : 0.0987, Val-Loss : 0.1761\n",
      "Epoch : 770/1000, Train-Loss : 0.0986, Val-Loss : 0.1760\n",
      "Epoch : 771/1000, Train-Loss : 0.0985, Val-Loss : 0.1760\n",
      "Epoch : 772/1000, Train-Loss : 0.0984, Val-Loss : 0.1759\n",
      "Epoch : 773/1000, Train-Loss : 0.0983, Val-Loss : 0.1758\n",
      "Epoch : 774/1000, Train-Loss : 0.0982, Val-Loss : 0.1757\n",
      "Epoch : 775/1000, Train-Loss : 0.0981, Val-Loss : 0.1757\n",
      "Epoch : 776/1000, Train-Loss : 0.0980, Val-Loss : 0.1756\n",
      "Epoch : 777/1000, Train-Loss : 0.0979, Val-Loss : 0.1755\n",
      "Epoch : 778/1000, Train-Loss : 0.0978, Val-Loss : 0.1755\n",
      "Epoch : 779/1000, Train-Loss : 0.0977, Val-Loss : 0.1754\n",
      "Epoch : 780/1000, Train-Loss : 0.0977, Val-Loss : 0.1753\n",
      "Epoch : 781/1000, Train-Loss : 0.0976, Val-Loss : 0.1752\n",
      "Epoch : 782/1000, Train-Loss : 0.0975, Val-Loss : 0.1752\n",
      "Epoch : 783/1000, Train-Loss : 0.0974, Val-Loss : 0.1751\n",
      "Epoch : 784/1000, Train-Loss : 0.0973, Val-Loss : 0.1750\n",
      "Epoch : 785/1000, Train-Loss : 0.0972, Val-Loss : 0.1750\n",
      "Epoch : 786/1000, Train-Loss : 0.0971, Val-Loss : 0.1749\n",
      "Epoch : 787/1000, Train-Loss : 0.0970, Val-Loss : 0.1748\n",
      "Epoch : 788/1000, Train-Loss : 0.0969, Val-Loss : 0.1747\n",
      "Epoch : 789/1000, Train-Loss : 0.0968, Val-Loss : 0.1747\n",
      "Epoch : 790/1000, Train-Loss : 0.0968, Val-Loss : 0.1746\n",
      "Epoch : 791/1000, Train-Loss : 0.0967, Val-Loss : 0.1745\n",
      "Epoch : 792/1000, Train-Loss : 0.0966, Val-Loss : 0.1745\n",
      "Epoch : 793/1000, Train-Loss : 0.0965, Val-Loss : 0.1744\n",
      "Epoch : 794/1000, Train-Loss : 0.0964, Val-Loss : 0.1743\n",
      "Epoch : 795/1000, Train-Loss : 0.0963, Val-Loss : 0.1743\n",
      "Epoch : 796/1000, Train-Loss : 0.0962, Val-Loss : 0.1742\n",
      "Epoch : 797/1000, Train-Loss : 0.0961, Val-Loss : 0.1741\n",
      "Epoch : 798/1000, Train-Loss : 0.0960, Val-Loss : 0.1741\n",
      "Epoch : 799/1000, Train-Loss : 0.0960, Val-Loss : 0.1740\n",
      "Epoch : 800/1000, Train-Loss : 0.0959, Val-Loss : 0.1739\n",
      "Epoch : 801/1000, Train-Loss : 0.0958, Val-Loss : 0.1739\n",
      "Epoch : 802/1000, Train-Loss : 0.0957, Val-Loss : 0.1738\n",
      "Epoch : 803/1000, Train-Loss : 0.0956, Val-Loss : 0.1737\n",
      "Epoch : 804/1000, Train-Loss : 0.0955, Val-Loss : 0.1737\n",
      "Epoch : 805/1000, Train-Loss : 0.0954, Val-Loss : 0.1736\n",
      "Epoch : 806/1000, Train-Loss : 0.0954, Val-Loss : 0.1735\n",
      "Epoch : 807/1000, Train-Loss : 0.0953, Val-Loss : 0.1735\n",
      "Epoch : 808/1000, Train-Loss : 0.0952, Val-Loss : 0.1734\n",
      "Epoch : 809/1000, Train-Loss : 0.0951, Val-Loss : 0.1733\n",
      "Epoch : 810/1000, Train-Loss : 0.0950, Val-Loss : 0.1733\n",
      "Epoch : 811/1000, Train-Loss : 0.0949, Val-Loss : 0.1732\n",
      "Epoch : 812/1000, Train-Loss : 0.0948, Val-Loss : 0.1731\n",
      "Epoch : 813/1000, Train-Loss : 0.0948, Val-Loss : 0.1731\n",
      "Epoch : 814/1000, Train-Loss : 0.0947, Val-Loss : 0.1730\n",
      "Epoch : 815/1000, Train-Loss : 0.0946, Val-Loss : 0.1729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 816/1000, Train-Loss : 0.0945, Val-Loss : 0.1729\n",
      "Epoch : 817/1000, Train-Loss : 0.0944, Val-Loss : 0.1728\n",
      "Epoch : 818/1000, Train-Loss : 0.0943, Val-Loss : 0.1727\n",
      "Epoch : 819/1000, Train-Loss : 0.0943, Val-Loss : 0.1727\n",
      "Epoch : 820/1000, Train-Loss : 0.0942, Val-Loss : 0.1726\n",
      "Epoch : 821/1000, Train-Loss : 0.0941, Val-Loss : 0.1726\n",
      "Epoch : 822/1000, Train-Loss : 0.0940, Val-Loss : 0.1725\n",
      "Epoch : 823/1000, Train-Loss : 0.0939, Val-Loss : 0.1724\n",
      "Epoch : 824/1000, Train-Loss : 0.0938, Val-Loss : 0.1724\n",
      "Epoch : 825/1000, Train-Loss : 0.0938, Val-Loss : 0.1723\n",
      "Epoch : 826/1000, Train-Loss : 0.0937, Val-Loss : 0.1722\n",
      "Epoch : 827/1000, Train-Loss : 0.0936, Val-Loss : 0.1722\n",
      "Epoch : 828/1000, Train-Loss : 0.0935, Val-Loss : 0.1721\n",
      "Epoch : 829/1000, Train-Loss : 0.0934, Val-Loss : 0.1721\n",
      "Epoch : 830/1000, Train-Loss : 0.0933, Val-Loss : 0.1720\n",
      "Epoch : 831/1000, Train-Loss : 0.0933, Val-Loss : 0.1719\n",
      "Epoch : 832/1000, Train-Loss : 0.0932, Val-Loss : 0.1719\n",
      "Epoch : 833/1000, Train-Loss : 0.0931, Val-Loss : 0.1718\n",
      "Epoch : 834/1000, Train-Loss : 0.0930, Val-Loss : 0.1717\n",
      "Epoch : 835/1000, Train-Loss : 0.0929, Val-Loss : 0.1717\n",
      "Epoch : 836/1000, Train-Loss : 0.0929, Val-Loss : 0.1716\n",
      "Epoch : 837/1000, Train-Loss : 0.0928, Val-Loss : 0.1716\n",
      "Epoch : 838/1000, Train-Loss : 0.0927, Val-Loss : 0.1715\n",
      "Epoch : 839/1000, Train-Loss : 0.0926, Val-Loss : 0.1714\n",
      "Epoch : 840/1000, Train-Loss : 0.0925, Val-Loss : 0.1714\n",
      "Epoch : 841/1000, Train-Loss : 0.0925, Val-Loss : 0.1713\n",
      "Epoch : 842/1000, Train-Loss : 0.0924, Val-Loss : 0.1713\n",
      "Epoch : 843/1000, Train-Loss : 0.0923, Val-Loss : 0.1712\n",
      "Epoch : 844/1000, Train-Loss : 0.0922, Val-Loss : 0.1711\n",
      "Epoch : 845/1000, Train-Loss : 0.0921, Val-Loss : 0.1711\n",
      "Epoch : 846/1000, Train-Loss : 0.0921, Val-Loss : 0.1710\n",
      "Epoch : 847/1000, Train-Loss : 0.0920, Val-Loss : 0.1710\n",
      "Epoch : 848/1000, Train-Loss : 0.0919, Val-Loss : 0.1709\n",
      "Epoch : 849/1000, Train-Loss : 0.0918, Val-Loss : 0.1708\n",
      "Epoch : 850/1000, Train-Loss : 0.0917, Val-Loss : 0.1708\n",
      "Epoch : 851/1000, Train-Loss : 0.0917, Val-Loss : 0.1707\n",
      "Epoch : 852/1000, Train-Loss : 0.0916, Val-Loss : 0.1707\n",
      "Epoch : 853/1000, Train-Loss : 0.0915, Val-Loss : 0.1706\n",
      "Epoch : 854/1000, Train-Loss : 0.0914, Val-Loss : 0.1706\n",
      "Epoch : 855/1000, Train-Loss : 0.0914, Val-Loss : 0.1705\n",
      "Epoch : 856/1000, Train-Loss : 0.0913, Val-Loss : 0.1704\n",
      "Epoch : 857/1000, Train-Loss : 0.0912, Val-Loss : 0.1704\n",
      "Epoch : 858/1000, Train-Loss : 0.0911, Val-Loss : 0.1703\n",
      "Epoch : 859/1000, Train-Loss : 0.0911, Val-Loss : 0.1703\n",
      "Epoch : 860/1000, Train-Loss : 0.0910, Val-Loss : 0.1702\n",
      "Epoch : 861/1000, Train-Loss : 0.0909, Val-Loss : 0.1702\n",
      "Epoch : 862/1000, Train-Loss : 0.0908, Val-Loss : 0.1701\n",
      "Epoch : 863/1000, Train-Loss : 0.0907, Val-Loss : 0.1700\n",
      "Epoch : 864/1000, Train-Loss : 0.0907, Val-Loss : 0.1700\n",
      "Epoch : 865/1000, Train-Loss : 0.0906, Val-Loss : 0.1699\n",
      "Epoch : 866/1000, Train-Loss : 0.0905, Val-Loss : 0.1699\n",
      "Epoch : 867/1000, Train-Loss : 0.0904, Val-Loss : 0.1698\n",
      "Epoch : 868/1000, Train-Loss : 0.0904, Val-Loss : 0.1698\n",
      "Epoch : 869/1000, Train-Loss : 0.0903, Val-Loss : 0.1697\n",
      "Epoch : 870/1000, Train-Loss : 0.0902, Val-Loss : 0.1696\n",
      "Epoch : 871/1000, Train-Loss : 0.0901, Val-Loss : 0.1696\n",
      "Epoch : 872/1000, Train-Loss : 0.0901, Val-Loss : 0.1695\n",
      "Epoch : 873/1000, Train-Loss : 0.0900, Val-Loss : 0.1695\n",
      "Epoch : 874/1000, Train-Loss : 0.0899, Val-Loss : 0.1694\n",
      "Epoch : 875/1000, Train-Loss : 0.0898, Val-Loss : 0.1694\n",
      "Epoch : 876/1000, Train-Loss : 0.0898, Val-Loss : 0.1693\n",
      "Epoch : 877/1000, Train-Loss : 0.0897, Val-Loss : 0.1693\n",
      "Epoch : 878/1000, Train-Loss : 0.0896, Val-Loss : 0.1692\n",
      "Epoch : 879/1000, Train-Loss : 0.0895, Val-Loss : 0.1692\n",
      "Epoch : 880/1000, Train-Loss : 0.0895, Val-Loss : 0.1691\n",
      "Epoch : 881/1000, Train-Loss : 0.0894, Val-Loss : 0.1690\n",
      "Epoch : 882/1000, Train-Loss : 0.0893, Val-Loss : 0.1690\n",
      "Epoch : 883/1000, Train-Loss : 0.0892, Val-Loss : 0.1689\n",
      "Epoch : 884/1000, Train-Loss : 0.0892, Val-Loss : 0.1689\n",
      "Epoch : 885/1000, Train-Loss : 0.0891, Val-Loss : 0.1688\n",
      "Epoch : 886/1000, Train-Loss : 0.0890, Val-Loss : 0.1688\n",
      "Epoch : 887/1000, Train-Loss : 0.0890, Val-Loss : 0.1687\n",
      "Epoch : 888/1000, Train-Loss : 0.0889, Val-Loss : 0.1687\n",
      "Epoch : 889/1000, Train-Loss : 0.0888, Val-Loss : 0.1686\n",
      "Epoch : 890/1000, Train-Loss : 0.0887, Val-Loss : 0.1686\n",
      "Epoch : 891/1000, Train-Loss : 0.0887, Val-Loss : 0.1685\n",
      "Epoch : 892/1000, Train-Loss : 0.0886, Val-Loss : 0.1685\n",
      "Epoch : 893/1000, Train-Loss : 0.0885, Val-Loss : 0.1684\n",
      "Epoch : 894/1000, Train-Loss : 0.0884, Val-Loss : 0.1684\n",
      "Epoch : 895/1000, Train-Loss : 0.0884, Val-Loss : 0.1683\n",
      "Epoch : 896/1000, Train-Loss : 0.0883, Val-Loss : 0.1683\n",
      "Epoch : 897/1000, Train-Loss : 0.0882, Val-Loss : 0.1682\n",
      "Epoch : 898/1000, Train-Loss : 0.0882, Val-Loss : 0.1682\n",
      "Epoch : 899/1000, Train-Loss : 0.0881, Val-Loss : 0.1681\n",
      "Epoch : 900/1000, Train-Loss : 0.0880, Val-Loss : 0.1681\n",
      "Epoch : 901/1000, Train-Loss : 0.0879, Val-Loss : 0.1680\n",
      "Epoch : 902/1000, Train-Loss : 0.0879, Val-Loss : 0.1680\n",
      "Epoch : 903/1000, Train-Loss : 0.0878, Val-Loss : 0.1679\n",
      "Epoch : 904/1000, Train-Loss : 0.0877, Val-Loss : 0.1678\n",
      "Epoch : 905/1000, Train-Loss : 0.0877, Val-Loss : 0.1678\n",
      "Epoch : 906/1000, Train-Loss : 0.0876, Val-Loss : 0.1677\n",
      "Epoch : 907/1000, Train-Loss : 0.0875, Val-Loss : 0.1677\n",
      "Epoch : 908/1000, Train-Loss : 0.0875, Val-Loss : 0.1676\n",
      "Epoch : 909/1000, Train-Loss : 0.0874, Val-Loss : 0.1676\n",
      "Epoch : 910/1000, Train-Loss : 0.0873, Val-Loss : 0.1675\n",
      "Epoch : 911/1000, Train-Loss : 0.0872, Val-Loss : 0.1675\n",
      "Epoch : 912/1000, Train-Loss : 0.0872, Val-Loss : 0.1674\n",
      "Epoch : 913/1000, Train-Loss : 0.0871, Val-Loss : 0.1674\n",
      "Epoch : 914/1000, Train-Loss : 0.0870, Val-Loss : 0.1674\n",
      "Epoch : 915/1000, Train-Loss : 0.0870, Val-Loss : 0.1673\n",
      "Epoch : 916/1000, Train-Loss : 0.0869, Val-Loss : 0.1673\n",
      "Epoch : 917/1000, Train-Loss : 0.0868, Val-Loss : 0.1672\n",
      "Epoch : 918/1000, Train-Loss : 0.0868, Val-Loss : 0.1672\n",
      "Epoch : 919/1000, Train-Loss : 0.0867, Val-Loss : 0.1671\n",
      "Epoch : 920/1000, Train-Loss : 0.0866, Val-Loss : 0.1671\n",
      "Epoch : 921/1000, Train-Loss : 0.0866, Val-Loss : 0.1670\n",
      "Epoch : 922/1000, Train-Loss : 0.0865, Val-Loss : 0.1670\n",
      "Epoch : 923/1000, Train-Loss : 0.0864, Val-Loss : 0.1669\n",
      "Epoch : 924/1000, Train-Loss : 0.0863, Val-Loss : 0.1669\n",
      "Epoch : 925/1000, Train-Loss : 0.0863, Val-Loss : 0.1668\n",
      "Epoch : 926/1000, Train-Loss : 0.0862, Val-Loss : 0.1668\n",
      "Epoch : 927/1000, Train-Loss : 0.0861, Val-Loss : 0.1667\n",
      "Epoch : 928/1000, Train-Loss : 0.0861, Val-Loss : 0.1667\n",
      "Epoch : 929/1000, Train-Loss : 0.0860, Val-Loss : 0.1666\n",
      "Epoch : 930/1000, Train-Loss : 0.0859, Val-Loss : 0.1666\n",
      "Epoch : 931/1000, Train-Loss : 0.0859, Val-Loss : 0.1665\n",
      "Epoch : 932/1000, Train-Loss : 0.0858, Val-Loss : 0.1665\n",
      "Epoch : 933/1000, Train-Loss : 0.0857, Val-Loss : 0.1664\n",
      "Epoch : 934/1000, Train-Loss : 0.0857, Val-Loss : 0.1664\n",
      "Epoch : 935/1000, Train-Loss : 0.0856, Val-Loss : 0.1663\n",
      "Epoch : 936/1000, Train-Loss : 0.0855, Val-Loss : 0.1663\n",
      "Epoch : 937/1000, Train-Loss : 0.0855, Val-Loss : 0.1663\n",
      "Epoch : 938/1000, Train-Loss : 0.0854, Val-Loss : 0.1662\n",
      "Epoch : 939/1000, Train-Loss : 0.0853, Val-Loss : 0.1662\n",
      "Epoch : 940/1000, Train-Loss : 0.0853, Val-Loss : 0.1661\n",
      "Epoch : 941/1000, Train-Loss : 0.0852, Val-Loss : 0.1661\n",
      "Epoch : 942/1000, Train-Loss : 0.0851, Val-Loss : 0.1660\n",
      "Epoch : 943/1000, Train-Loss : 0.0851, Val-Loss : 0.1660\n",
      "Epoch : 944/1000, Train-Loss : 0.0850, Val-Loss : 0.1659\n",
      "Epoch : 945/1000, Train-Loss : 0.0849, Val-Loss : 0.1659\n",
      "Epoch : 946/1000, Train-Loss : 0.0849, Val-Loss : 0.1658\n",
      "Epoch : 947/1000, Train-Loss : 0.0848, Val-Loss : 0.1658\n",
      "Epoch : 948/1000, Train-Loss : 0.0848, Val-Loss : 0.1657\n",
      "Epoch : 949/1000, Train-Loss : 0.0847, Val-Loss : 0.1657\n",
      "Epoch : 950/1000, Train-Loss : 0.0846, Val-Loss : 0.1657\n",
      "Epoch : 951/1000, Train-Loss : 0.0846, Val-Loss : 0.1656\n",
      "Epoch : 952/1000, Train-Loss : 0.0845, Val-Loss : 0.1656\n",
      "Epoch : 953/1000, Train-Loss : 0.0844, Val-Loss : 0.1655\n",
      "Epoch : 954/1000, Train-Loss : 0.0844, Val-Loss : 0.1655\n",
      "Epoch : 955/1000, Train-Loss : 0.0843, Val-Loss : 0.1654\n",
      "Epoch : 956/1000, Train-Loss : 0.0842, Val-Loss : 0.1654\n",
      "Epoch : 957/1000, Train-Loss : 0.0842, Val-Loss : 0.1653\n",
      "Epoch : 958/1000, Train-Loss : 0.0841, Val-Loss : 0.1653\n",
      "Epoch : 959/1000, Train-Loss : 0.0840, Val-Loss : 0.1653\n",
      "Epoch : 960/1000, Train-Loss : 0.0840, Val-Loss : 0.1652\n",
      "Epoch : 961/1000, Train-Loss : 0.0839, Val-Loss : 0.1652\n",
      "Epoch : 962/1000, Train-Loss : 0.0839, Val-Loss : 0.1651\n",
      "Epoch : 963/1000, Train-Loss : 0.0838, Val-Loss : 0.1651\n",
      "Epoch : 964/1000, Train-Loss : 0.0837, Val-Loss : 0.1650\n",
      "Epoch : 965/1000, Train-Loss : 0.0837, Val-Loss : 0.1650\n",
      "Epoch : 966/1000, Train-Loss : 0.0836, Val-Loss : 0.1650\n",
      "Epoch : 967/1000, Train-Loss : 0.0835, Val-Loss : 0.1649\n",
      "Epoch : 968/1000, Train-Loss : 0.0835, Val-Loss : 0.1649\n",
      "Epoch : 969/1000, Train-Loss : 0.0834, Val-Loss : 0.1648\n",
      "Epoch : 970/1000, Train-Loss : 0.0833, Val-Loss : 0.1648\n",
      "Epoch : 971/1000, Train-Loss : 0.0833, Val-Loss : 0.1647\n",
      "Epoch : 972/1000, Train-Loss : 0.0832, Val-Loss : 0.1647\n",
      "Epoch : 973/1000, Train-Loss : 0.0832, Val-Loss : 0.1647\n",
      "Epoch : 974/1000, Train-Loss : 0.0831, Val-Loss : 0.1646\n",
      "Epoch : 975/1000, Train-Loss : 0.0830, Val-Loss : 0.1646\n",
      "Epoch : 976/1000, Train-Loss : 0.0830, Val-Loss : 0.1645\n",
      "Epoch : 977/1000, Train-Loss : 0.0829, Val-Loss : 0.1645\n",
      "Epoch : 978/1000, Train-Loss : 0.0828, Val-Loss : 0.1644\n",
      "Epoch : 979/1000, Train-Loss : 0.0828, Val-Loss : 0.1644\n",
      "Epoch : 980/1000, Train-Loss : 0.0827, Val-Loss : 0.1644\n",
      "Epoch : 981/1000, Train-Loss : 0.0827, Val-Loss : 0.1643\n",
      "Epoch : 982/1000, Train-Loss : 0.0826, Val-Loss : 0.1643\n",
      "Epoch : 983/1000, Train-Loss : 0.0825, Val-Loss : 0.1642\n",
      "Epoch : 984/1000, Train-Loss : 0.0825, Val-Loss : 0.1642\n",
      "Epoch : 985/1000, Train-Loss : 0.0824, Val-Loss : 0.1641\n",
      "Epoch : 986/1000, Train-Loss : 0.0824, Val-Loss : 0.1641\n",
      "Epoch : 987/1000, Train-Loss : 0.0823, Val-Loss : 0.1641\n",
      "Epoch : 988/1000, Train-Loss : 0.0822, Val-Loss : 0.1640\n",
      "Epoch : 989/1000, Train-Loss : 0.0822, Val-Loss : 0.1640\n",
      "Epoch : 990/1000, Train-Loss : 0.0821, Val-Loss : 0.1639\n",
      "Epoch : 991/1000, Train-Loss : 0.0821, Val-Loss : 0.1639\n",
      "Epoch : 992/1000, Train-Loss : 0.0820, Val-Loss : 0.1639\n",
      "Epoch : 993/1000, Train-Loss : 0.0819, Val-Loss : 0.1638\n",
      "Epoch : 994/1000, Train-Loss : 0.0819, Val-Loss : 0.1638\n",
      "Epoch : 995/1000, Train-Loss : 0.0818, Val-Loss : 0.1637\n",
      "Epoch : 996/1000, Train-Loss : 0.0818, Val-Loss : 0.1637\n",
      "Epoch : 997/1000, Train-Loss : 0.0817, Val-Loss : 0.1637\n",
      "Epoch : 998/1000, Train-Loss : 0.0816, Val-Loss : 0.1636\n",
      "Epoch : 999/1000, Train-Loss : 0.0816, Val-Loss : 0.1636\n",
      "Epoch : 1000/1000, Train-Loss : 0.0815, Val-Loss : 0.1635\n"
     ]
    }
   ],
   "source": [
    "# Convert each numpy to torch tensors\n",
    "inputs_train = torch.from_numpy(Xtrain.astype(np.float32))\n",
    "targets_train = torch.from_numpy(Ytrain.astype(np.float32))\n",
    "\n",
    "inputs_val = torch.from_numpy(Xval.astype(np.float32))\n",
    "targets_val = torch.from_numpy(Yval.astype(np.float32))\n",
    "\n",
    "# Train the model\n",
    "epochs = 1000\n",
    "trainlosses = []\n",
    "vallosses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs_train = model(inputs_train)\n",
    "    loss_train = criterion(outputs_train, targets_train)\n",
    "    \n",
    "    # Track the loss\n",
    "    trainlosses.append(loss_train)\n",
    "    \n",
    "    # Backward pass and Optimize the model\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    # Compute validation losses \n",
    "    outputs_val = model(inputs_val)\n",
    "    loss_val = criterion(outputs_val, targets_val)\n",
    "    vallosses.append(loss_val)\n",
    "    \n",
    "    print(\"Epoch : {}/{}, Train-Loss : {:.4f}, Val-Loss : {:.4f}\".format(epoch + 1, epochs, loss_train.item(), loss_val.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainlosses, label=\"train loss\")\n",
    "plt.plot(vallosses, label=\"val loss\")\n",
    "plt.title(\"Epoch vs Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Losses\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 98.6877, Val accuracy : 93.6170\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy of the model\n",
    "trainpreds = model(inputs_train).detach().numpy()\n",
    "valpreds = model(inputs_val).detach().numpy()\n",
    "\n",
    "train_acc = np.mean(Ytrain == np.round(trainpreds))\n",
    "val_acc = np.mean(Yval == np.round(valpreds))\n",
    "\n",
    "print(\"Train accuracy : {:.4f}, Val accuracy : {:.4f}\".format(train_acc * 100., val_acc * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.3329, -0.5163, -0.2098, -0.4287, -0.3260, -0.1363, -0.2730, -0.4830,\n",
       "                       -0.1062,  0.4435, -0.2312,  0.3008, -0.5097, -0.3629, -0.1529, -0.0651,\n",
       "                       -0.1173, -0.0299, -0.1279,  0.2674, -0.2878, -0.3878, -0.4537, -0.5309,\n",
       "                       -0.1977, -0.3675, -0.2350, -0.1692, -0.2654, -0.3477]])),\n",
       "             ('0.bias', tensor([0.3564]))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'mymodel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "\n",
    "model2 = nn.Sequential(\n",
    "    nn.Linear(D, 1), \n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model2.load_state_dict(torch.load('mymodel.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc : 98.6877\n"
     ]
    }
   ],
   "source": [
    "preds = model2(inputs_train).detach().numpy()\n",
    "acc = np.mean(Ytrain == np.round(preds))\n",
    "print(\"Acc : {:.4f}\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
