{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CBOW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPQc0zIAjvuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from cbow_mode import CBOWmode\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSYpbmJkNXiA",
        "colab_type": "code",
        "outputId": "dbbb17c4-53ab-45b7-b2e4-968c22a1c6c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "sent = \"\"\"Deep Learning has evolved from Artificial Neural Networks, which has been\n",
        "there since the 1940s. Neural Networks are interconnected networks of processing units\n",
        "called artificial neurons that loosely mimic axons in a biological brain. In a biological\n",
        "neuron, the dendrites receive input signals from various neighboring neurons, typically\n",
        "greater than 1000. These modified signals are then passed on to the cell body or soma of\n",
        "the neuron, where these signals are summed together and then passed on to the axon of the\n",
        "neuron. If the received input signal is more than a specified threshold, the axon will\n",
        "release a signal which again will pass on to neighboring dendrites of other neurons. Figure\n",
        "2-1 depicts the structure of a biological neuron for reference. The artificial neuron units\n",
        "are inspired by the biological neurons with some modifications as per convenience. Much\n",
        "like the dendrites, the input connections to the neuron carry the attenuated or amplified\n",
        "input signals from other neighboring neurons. The signals are passed on to the neuron, where\n",
        "the input signals are summed up and then a decision is taken what to output based on the\n",
        "total input received. For instance, for a binary threshold neuron an output value of 1 is\n",
        "provided when the total input exceeds a pre-defined threshold; otherwise, the output stays\n",
        "at 0. Several other types of neurons are used in artificial neural networks, and their\n",
        "implementation only differs with respect to the activation function on the total input to\n",
        "produce the neuron output. In Figure 2-2 the different biological equivalents are tagged in\n",
        "the artificial neuron for easy analogy and interpretation.\"\"\"\n",
        "\n",
        "xtrain, ytrain, word2idx, idx2word, vocab_size = CBOWmode().acceptString(sent)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(['deep', 'learning', 'evolved', 'from'], 'has'), (['learning', 'has', 'from', 'artificial'], 'evolved'), (['has', 'evolved', 'artificial', 'neural'], 'from'), (['evolved', 'from', 'neural', 'networks'], 'artificial'), (['from', 'artificial', 'networks', 'which'], 'neural'), (['artificial', 'neural', 'which', 'has'], 'networks'), (['neural', 'networks', 'has', 'been'], 'which'), (['networks', 'which', 'been', 'there'], 'has'), (['which', 'has', 'there', 'since'], 'been'), (['has', 'been', 'since', 'the'], 'there'), (['been', 'there', 'the', '1940s'], 'since'), (['there', 'since', '1940s', 'neural'], 'the'), (['since', 'the', 'neural', 'networks'], '1940s'), (['the', '1940s', 'networks', 'are'], 'neural'), (['1940s', 'neural', 'are', 'interconnected'], 'networks'), (['neural', 'networks', 'interconnected', 'networks'], 'are'), (['networks', 'are', 'networks', 'of'], 'interconnected'), (['are', 'interconnected', 'of', 'processing'], 'networks'), (['interconnected', 'networks', 'processing', 'units'], 'of'), (['networks', 'of', 'units', 'called'], 'processing'), (['of', 'processing', 'called', 'artificial'], 'units'), (['processing', 'units', 'artificial', 'neurons'], 'called'), (['units', 'called', 'neurons', 'that'], 'artificial'), (['called', 'artificial', 'that', 'loosely'], 'neurons'), (['artificial', 'neurons', 'loosely', 'mimic'], 'that'), (['neurons', 'that', 'mimic', 'axons'], 'loosely'), (['that', 'loosely', 'axons', 'in'], 'mimic'), (['loosely', 'mimic', 'in', 'a'], 'axons'), (['mimic', 'axons', 'a', 'biological'], 'in'), (['axons', 'in', 'biological', 'brain'], 'a'), (['in', 'a', 'brain', 'in'], 'biological'), (['a', 'biological', 'in', 'a'], 'brain'), (['biological', 'brain', 'a', 'biological'], 'in'), (['brain', 'in', 'biological', 'neuron'], 'a'), (['in', 'a', 'neuron', 'the'], 'biological'), (['a', 'biological', 'the', 'dendrites'], 'neuron'), (['biological', 'neuron', 'dendrites', 'receive'], 'the'), (['neuron', 'the', 'receive', 'input'], 'dendrites'), (['the', 'dendrites', 'input', 'signals'], 'receive'), (['dendrites', 'receive', 'signals', 'from'], 'input'), (['receive', 'input', 'from', 'various'], 'signals'), (['input', 'signals', 'various', 'neighboring'], 'from'), (['signals', 'from', 'neighboring', 'neurons'], 'various'), (['from', 'various', 'neurons', 'typically'], 'neighboring'), (['various', 'neighboring', 'typically', 'greater'], 'neurons'), (['neighboring', 'neurons', 'greater', 'than'], 'typically'), (['neurons', 'typically', 'than', '1000'], 'greater'), (['typically', 'greater', '1000', 'these'], 'than'), (['greater', 'than', 'these', 'modified'], '1000'), (['than', '1000', 'modified', 'signals'], 'these'), (['1000', 'these', 'signals', 'are'], 'modified'), (['these', 'modified', 'are', 'then'], 'signals'), (['modified', 'signals', 'then', 'passed'], 'are'), (['signals', 'are', 'passed', 'on'], 'then'), (['are', 'then', 'on', 'to'], 'passed'), (['then', 'passed', 'to', 'the'], 'on'), (['passed', 'on', 'the', 'cell'], 'to'), (['on', 'to', 'cell', 'body'], 'the'), (['to', 'the', 'body', 'or'], 'cell'), (['the', 'cell', 'or', 'soma'], 'body'), (['cell', 'body', 'soma', 'of'], 'or'), (['body', 'or', 'of', 'the'], 'soma'), (['or', 'soma', 'the', 'neuron'], 'of'), (['soma', 'of', 'neuron', 'where'], 'the'), (['of', 'the', 'where', 'these'], 'neuron'), (['the', 'neuron', 'these', 'signals'], 'where'), (['neuron', 'where', 'signals', 'are'], 'these'), (['where', 'these', 'are', 'summed'], 'signals'), (['these', 'signals', 'summed', 'together'], 'are'), (['signals', 'are', 'together', 'and'], 'summed'), (['are', 'summed', 'and', 'then'], 'together'), (['summed', 'together', 'then', 'passed'], 'and'), (['together', 'and', 'passed', 'on'], 'then'), (['and', 'then', 'on', 'to'], 'passed'), (['then', 'passed', 'to', 'the'], 'on'), (['passed', 'on', 'the', 'axon'], 'to'), (['on', 'to', 'axon', 'of'], 'the'), (['to', 'the', 'of', 'the'], 'axon'), (['the', 'axon', 'the', 'neuron'], 'of'), (['axon', 'of', 'neuron', 'if'], 'the'), (['of', 'the', 'if', 'the'], 'neuron'), (['the', 'neuron', 'the', 'received'], 'if'), (['neuron', 'if', 'received', 'input'], 'the'), (['if', 'the', 'input', 'signal'], 'received'), (['the', 'received', 'signal', 'is'], 'input'), (['received', 'input', 'is', 'more'], 'signal'), (['input', 'signal', 'more', 'than'], 'is'), (['signal', 'is', 'than', 'a'], 'more'), (['is', 'more', 'a', 'specified'], 'than'), (['more', 'than', 'specified', 'threshold'], 'a'), (['than', 'a', 'threshold', 'the'], 'specified'), (['a', 'specified', 'the', 'axon'], 'threshold'), (['specified', 'threshold', 'axon', 'will'], 'the'), (['threshold', 'the', 'will', 'release'], 'axon'), (['the', 'axon', 'release', 'a'], 'will'), (['axon', 'will', 'a', 'signal'], 'release'), (['will', 'release', 'signal', 'which'], 'a'), (['release', 'a', 'which', 'again'], 'signal'), (['a', 'signal', 'again', 'will'], 'which'), (['signal', 'which', 'will', 'pass'], 'again'), (['which', 'again', 'pass', 'on'], 'will'), (['again', 'will', 'on', 'to'], 'pass'), (['will', 'pass', 'to', 'neighboring'], 'on'), (['pass', 'on', 'neighboring', 'dendrites'], 'to'), (['on', 'to', 'dendrites', 'of'], 'neighboring'), (['to', 'neighboring', 'of', 'other'], 'dendrites'), (['neighboring', 'dendrites', 'other', 'neurons'], 'of'), (['dendrites', 'of', 'neurons', 'figure'], 'other'), (['of', 'other', 'figure', '21'], 'neurons'), (['other', 'neurons', '21', 'depicts'], 'figure'), (['neurons', 'figure', 'depicts', 'the'], '21'), (['figure', '21', 'the', 'structure'], 'depicts'), (['21', 'depicts', 'structure', 'of'], 'the'), (['depicts', 'the', 'of', 'a'], 'structure'), (['the', 'structure', 'a', 'biological'], 'of'), (['structure', 'of', 'biological', 'neuron'], 'a'), (['of', 'a', 'neuron', 'for'], 'biological'), (['a', 'biological', 'for', 'reference'], 'neuron'), (['biological', 'neuron', 'reference', 'the'], 'for'), (['neuron', 'for', 'the', 'artificial'], 'reference'), (['for', 'reference', 'artificial', 'neuron'], 'the'), (['reference', 'the', 'neuron', 'units'], 'artificial'), (['the', 'artificial', 'units', 'are'], 'neuron'), (['artificial', 'neuron', 'are', 'inspired'], 'units'), (['neuron', 'units', 'inspired', 'by'], 'are'), (['units', 'are', 'by', 'the'], 'inspired'), (['are', 'inspired', 'the', 'biological'], 'by'), (['inspired', 'by', 'biological', 'neurons'], 'the'), (['by', 'the', 'neurons', 'with'], 'biological'), (['the', 'biological', 'with', 'some'], 'neurons'), (['biological', 'neurons', 'some', 'modifications'], 'with'), (['neurons', 'with', 'modifications', 'as'], 'some'), (['with', 'some', 'as', 'per'], 'modifications'), (['some', 'modifications', 'per', 'convenience'], 'as'), (['modifications', 'as', 'convenience', 'much'], 'per'), (['as', 'per', 'much', 'like'], 'convenience'), (['per', 'convenience', 'like', 'the'], 'much'), (['convenience', 'much', 'the', 'dendrites'], 'like'), (['much', 'like', 'dendrites', 'the'], 'the'), (['like', 'the', 'the', 'input'], 'dendrites'), (['the', 'dendrites', 'input', 'connections'], 'the'), (['dendrites', 'the', 'connections', 'to'], 'input'), (['the', 'input', 'to', 'the'], 'connections'), (['input', 'connections', 'the', 'neuron'], 'to'), (['connections', 'to', 'neuron', 'carry'], 'the'), (['to', 'the', 'carry', 'the'], 'neuron'), (['the', 'neuron', 'the', 'attenuated'], 'carry'), (['neuron', 'carry', 'attenuated', 'or'], 'the'), (['carry', 'the', 'or', 'amplified'], 'attenuated'), (['the', 'attenuated', 'amplified', 'input'], 'or'), (['attenuated', 'or', 'input', 'signals'], 'amplified'), (['or', 'amplified', 'signals', 'from'], 'input'), (['amplified', 'input', 'from', 'other'], 'signals'), (['input', 'signals', 'other', 'neighboring'], 'from'), (['signals', 'from', 'neighboring', 'neurons'], 'other'), (['from', 'other', 'neurons', 'the'], 'neighboring'), (['other', 'neighboring', 'the', 'signals'], 'neurons'), (['neighboring', 'neurons', 'signals', 'are'], 'the'), (['neurons', 'the', 'are', 'passed'], 'signals'), (['the', 'signals', 'passed', 'on'], 'are'), (['signals', 'are', 'on', 'to'], 'passed'), (['are', 'passed', 'to', 'the'], 'on'), (['passed', 'on', 'the', 'neuron'], 'to'), (['on', 'to', 'neuron', 'where'], 'the'), (['to', 'the', 'where', 'the'], 'neuron'), (['the', 'neuron', 'the', 'input'], 'where'), (['neuron', 'where', 'input', 'signals'], 'the'), (['where', 'the', 'signals', 'are'], 'input'), (['the', 'input', 'are', 'summed'], 'signals'), (['input', 'signals', 'summed', 'up'], 'are'), (['signals', 'are', 'up', 'and'], 'summed'), (['are', 'summed', 'and', 'then'], 'up'), (['summed', 'up', 'then', 'a'], 'and'), (['up', 'and', 'a', 'decision'], 'then'), (['and', 'then', 'decision', 'is'], 'a'), (['then', 'a', 'is', 'taken'], 'decision'), (['a', 'decision', 'taken', 'what'], 'is'), (['decision', 'is', 'what', 'to'], 'taken'), (['is', 'taken', 'to', 'output'], 'what'), (['taken', 'what', 'output', 'based'], 'to'), (['what', 'to', 'based', 'on'], 'output'), (['to', 'output', 'on', 'the'], 'based'), (['output', 'based', 'the', 'total'], 'on'), (['based', 'on', 'total', 'input'], 'the'), (['on', 'the', 'input', 'received'], 'total'), (['the', 'total', 'received', 'for'], 'input'), (['total', 'input', 'for', 'instance'], 'received'), (['input', 'received', 'instance', 'for'], 'for'), (['received', 'for', 'for', 'a'], 'instance'), (['for', 'instance', 'a', 'binary'], 'for'), (['instance', 'for', 'binary', 'threshold'], 'a'), (['for', 'a', 'threshold', 'neuron'], 'binary'), (['a', 'binary', 'neuron', 'an'], 'threshold'), (['binary', 'threshold', 'an', 'output'], 'neuron'), (['threshold', 'neuron', 'output', 'value'], 'an'), (['neuron', 'an', 'value', 'of'], 'output'), (['an', 'output', 'of', '1'], 'value'), (['output', 'value', '1', 'is'], 'of'), (['value', 'of', 'is', 'provided'], '1'), (['of', '1', 'provided', 'when'], 'is'), (['1', 'is', 'when', 'the'], 'provided'), (['is', 'provided', 'the', 'total'], 'when'), (['provided', 'when', 'total', 'input'], 'the'), (['when', 'the', 'input', 'exceeds'], 'total'), (['the', 'total', 'exceeds', 'a'], 'input'), (['total', 'input', 'a', 'predefined'], 'exceeds'), (['input', 'exceeds', 'predefined', 'threshold'], 'a'), (['exceeds', 'a', 'threshold', 'otherwise'], 'predefined'), (['a', 'predefined', 'otherwise', 'the'], 'threshold'), (['predefined', 'threshold', 'the', 'output'], 'otherwise'), (['threshold', 'otherwise', 'output', 'stays'], 'the'), (['otherwise', 'the', 'stays', 'at'], 'output'), (['the', 'output', 'at', '0'], 'stays'), (['output', 'stays', '0', 'several'], 'at'), (['stays', 'at', 'several', 'other'], '0'), (['at', '0', 'other', 'types'], 'several'), (['0', 'several', 'types', 'of'], 'other'), (['several', 'other', 'of', 'neurons'], 'types'), (['other', 'types', 'neurons', 'are'], 'of'), (['types', 'of', 'are', 'used'], 'neurons'), (['of', 'neurons', 'used', 'in'], 'are'), (['neurons', 'are', 'in', 'artificial'], 'used'), (['are', 'used', 'artificial', 'neural'], 'in'), (['used', 'in', 'neural', 'networks'], 'artificial'), (['in', 'artificial', 'networks', 'and'], 'neural'), (['artificial', 'neural', 'and', 'their'], 'networks'), (['neural', 'networks', 'their', 'implementation'], 'and'), (['networks', 'and', 'implementation', 'only'], 'their'), (['and', 'their', 'only', 'differs'], 'implementation'), (['their', 'implementation', 'differs', 'with'], 'only'), (['implementation', 'only', 'with', 'respect'], 'differs'), (['only', 'differs', 'respect', 'to'], 'with'), (['differs', 'with', 'to', 'the'], 'respect'), (['with', 'respect', 'the', 'activation'], 'to'), (['respect', 'to', 'activation', 'function'], 'the'), (['to', 'the', 'function', 'on'], 'activation'), (['the', 'activation', 'on', 'the'], 'function'), (['activation', 'function', 'the', 'total'], 'on'), (['function', 'on', 'total', 'input'], 'the'), (['on', 'the', 'input', 'to'], 'total'), (['the', 'total', 'to', 'produce'], 'input'), (['total', 'input', 'produce', 'the'], 'to'), (['input', 'to', 'the', 'neuron'], 'produce'), (['to', 'produce', 'neuron', 'output'], 'the'), (['produce', 'the', 'output', 'in'], 'neuron'), (['the', 'neuron', 'in', 'figure'], 'output'), (['neuron', 'output', 'figure', '22'], 'in'), (['output', 'in', '22', 'the'], 'figure'), (['in', 'figure', 'the', 'different'], '22'), (['figure', '22', 'different', 'biological'], 'the'), (['22', 'the', 'biological', 'equivalents'], 'different'), (['the', 'different', 'equivalents', 'are'], 'biological'), (['different', 'biological', 'are', 'tagged'], 'equivalents'), (['biological', 'equivalents', 'tagged', 'in'], 'are'), (['equivalents', 'are', 'in', 'the'], 'tagged'), (['are', 'tagged', 'the', 'artificial'], 'in'), (['tagged', 'in', 'artificial', 'neuron'], 'the'), (['in', 'the', 'neuron', 'for'], 'artificial'), (['the', 'artificial', 'for', 'easy'], 'neuron'), (['artificial', 'neuron', 'easy', 'analogy'], 'for'), (['neuron', 'for', 'analogy', 'and'], 'easy'), (['for', 'easy', 'and', 'interpretation'], 'analogy')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDLdMYmBGqVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CBOW(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim=128):\n",
        "    super(CBOW, self).__init__()\n",
        "    self.input_embedding = nn.Embedding(vocab_size,embedding_dim)\n",
        "    self.output_embedding = nn.Linear(embedding_dim,vocab_size)\n",
        "    self.activation_function = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    hidden = sum(self.input_embedding(inputs)).view(1,-1)\n",
        "    out = self.output_embedding(hidden)\n",
        "    out = self.activation_function(out)\n",
        "    return out\n",
        "\n",
        "cbow = CBOW(vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiQ2DuBTTNsO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "aa8da16b-0e4d-41e6-84a6-ca8f321e94cb"
      },
      "source": [
        "cbow"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CBOW(\n",
              "  (input_embedding): Embedding(125, 128)\n",
              "  (output_embedding): Linear(in_features=128, out_features=125, bias=True)\n",
              "  (activation_function): LogSoftmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI9thpNdIUCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.NLLLoss()\n",
        "optimizer = optim.Adam(cbow.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxthrcifIWvi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68cbbebc-f396-4b30-e1fa-3648aa3f5c2a"
      },
      "source": [
        "epochs = 10000\n",
        "for i in range(epochs):\n",
        "  total_loss = 0\n",
        "  for _x, _y in zip(xtrain, ytrain):\n",
        "    _x = torch.tensor(_x, dtype=torch.long)\n",
        "    _y = torch.tensor([_y], dtype=torch.long)\n",
        "    cbow.zero_grad()\n",
        "    preds = cbow(_x)\n",
        "    loss = loss_func(preds, _y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.data\n",
        "\n",
        "  if i%10 == 0:\n",
        "    print('Epoch: {} || Loss : {:.9f}'.format(i, total_loss))\n",
        "print('Optimization Complete')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 || Loss : 9.485545158\n",
            "Epoch: 10 || Loss : 8.554885864\n",
            "Epoch: 20 || Loss : 6.908744335\n",
            "Epoch: 30 || Loss : 5.954354763\n",
            "Epoch: 40 || Loss : 5.290108204\n",
            "Epoch: 50 || Loss : 4.781785011\n",
            "Epoch: 60 || Loss : 4.409127235\n",
            "Epoch: 70 || Loss : 4.144235134\n",
            "Epoch: 80 || Loss : 3.952785730\n",
            "Epoch: 90 || Loss : 3.809466839\n",
            "Epoch: 100 || Loss : 3.690440655\n",
            "Epoch: 110 || Loss : 3.589958906\n",
            "Epoch: 120 || Loss : 3.495981216\n",
            "Epoch: 130 || Loss : 3.415200233\n",
            "Epoch: 140 || Loss : 3.351291418\n",
            "Epoch: 150 || Loss : 3.313579559\n",
            "Epoch: 160 || Loss : 3.274981737\n",
            "Epoch: 170 || Loss : 3.243943930\n",
            "Epoch: 180 || Loss : 3.209675312\n",
            "Epoch: 190 || Loss : 3.178027868\n",
            "Epoch: 200 || Loss : 3.146696806\n",
            "Epoch: 210 || Loss : 3.118318796\n",
            "Epoch: 220 || Loss : 3.095330477\n",
            "Epoch: 230 || Loss : 3.078472853\n",
            "Epoch: 240 || Loss : 3.065134525\n",
            "Epoch: 250 || Loss : 3.055623293\n",
            "Epoch: 260 || Loss : 3.048562527\n",
            "Epoch: 270 || Loss : 3.044171095\n",
            "Epoch: 280 || Loss : 3.039715767\n",
            "Epoch: 290 || Loss : 3.034532547\n",
            "Epoch: 300 || Loss : 3.026721954\n",
            "Epoch: 310 || Loss : 3.018901825\n",
            "Epoch: 320 || Loss : 3.013198137\n",
            "Epoch: 330 || Loss : 3.010762691\n",
            "Epoch: 340 || Loss : 3.009872913\n",
            "Epoch: 350 || Loss : 3.007549047\n",
            "Epoch: 360 || Loss : 3.003647327\n",
            "Epoch: 370 || Loss : 2.996876478\n",
            "Epoch: 380 || Loss : 2.991959572\n",
            "Epoch: 390 || Loss : 2.990882874\n",
            "Epoch: 400 || Loss : 2.990115881\n",
            "Epoch: 410 || Loss : 2.990308762\n",
            "Epoch: 420 || Loss : 2.987210274\n",
            "Epoch: 430 || Loss : 2.985809565\n",
            "Epoch: 440 || Loss : 2.987429142\n",
            "Epoch: 450 || Loss : 2.987572432\n",
            "Epoch: 460 || Loss : 2.985328913\n",
            "Epoch: 470 || Loss : 2.980339050\n",
            "Epoch: 480 || Loss : 2.979149818\n",
            "Epoch: 490 || Loss : 2.978484154\n",
            "Epoch: 500 || Loss : 2.975969315\n",
            "Epoch: 510 || Loss : 2.972128630\n",
            "Epoch: 520 || Loss : 2.973630905\n",
            "Epoch: 530 || Loss : 2.974987507\n",
            "Epoch: 540 || Loss : 2.972727776\n",
            "Epoch: 550 || Loss : 2.973808289\n",
            "Epoch: 560 || Loss : 2.976403952\n",
            "Epoch: 570 || Loss : 2.974786758\n",
            "Epoch: 580 || Loss : 2.971873999\n",
            "Epoch: 590 || Loss : 2.972805977\n",
            "Epoch: 600 || Loss : 2.972757339\n",
            "Epoch: 610 || Loss : 2.967948437\n",
            "Epoch: 620 || Loss : 2.967146397\n",
            "Epoch: 630 || Loss : 2.964792490\n",
            "Epoch: 640 || Loss : 2.965836525\n",
            "Epoch: 650 || Loss : 2.965221405\n",
            "Epoch: 660 || Loss : 2.965443134\n",
            "Epoch: 670 || Loss : 2.965846777\n",
            "Epoch: 680 || Loss : 2.966862440\n",
            "Epoch: 690 || Loss : 2.968706846\n",
            "Epoch: 700 || Loss : 2.966699123\n",
            "Epoch: 710 || Loss : 2.969168901\n",
            "Epoch: 720 || Loss : 2.967216969\n",
            "Epoch: 730 || Loss : 2.966060400\n",
            "Epoch: 740 || Loss : 2.963722229\n",
            "Epoch: 750 || Loss : 2.964070082\n",
            "Epoch: 760 || Loss : 2.961108446\n",
            "Epoch: 770 || Loss : 2.959106684\n",
            "Epoch: 780 || Loss : 2.959821701\n",
            "Epoch: 790 || Loss : 2.960685492\n",
            "Epoch: 800 || Loss : 2.961487532\n",
            "Epoch: 810 || Loss : 2.963571787\n",
            "Epoch: 820 || Loss : 2.963805199\n",
            "Epoch: 830 || Loss : 2.962598085\n",
            "Epoch: 840 || Loss : 2.964691162\n",
            "Epoch: 850 || Loss : 2.964685440\n",
            "Epoch: 860 || Loss : 2.961928368\n",
            "Epoch: 870 || Loss : 2.959730148\n",
            "Epoch: 880 || Loss : 2.959757566\n",
            "Epoch: 890 || Loss : 2.959009409\n",
            "Epoch: 900 || Loss : 2.956529856\n",
            "Epoch: 910 || Loss : 2.957059860\n",
            "Epoch: 920 || Loss : 2.957216501\n",
            "Epoch: 930 || Loss : 2.957570076\n",
            "Epoch: 940 || Loss : 2.960307360\n",
            "Epoch: 950 || Loss : 2.959864855\n",
            "Epoch: 960 || Loss : 2.959524632\n",
            "Epoch: 970 || Loss : 2.954423189\n",
            "Epoch: 980 || Loss : 2.959523439\n",
            "Epoch: 990 || Loss : 2.954310417\n",
            "Epoch: 1000 || Loss : 2.960598469\n",
            "Epoch: 1010 || Loss : 2.957911491\n",
            "Epoch: 1020 || Loss : 2.954563141\n",
            "Epoch: 1030 || Loss : 2.965518475\n",
            "Epoch: 1040 || Loss : 2.948397398\n",
            "Epoch: 1050 || Loss : 2.960302353\n",
            "Epoch: 1060 || Loss : 2.951819420\n",
            "Epoch: 1070 || Loss : 2.952073812\n",
            "Epoch: 1080 || Loss : 2.961216450\n",
            "Epoch: 1090 || Loss : 2.949748755\n",
            "Epoch: 1100 || Loss : 2.966409445\n",
            "Epoch: 1110 || Loss : 2.947488546\n",
            "Epoch: 1120 || Loss : 2.953445911\n",
            "Epoch: 1130 || Loss : 2.957089663\n",
            "Epoch: 1140 || Loss : 2.947538614\n",
            "Epoch: 1150 || Loss : 2.960961103\n",
            "Epoch: 1160 || Loss : 2.952928066\n",
            "Epoch: 1170 || Loss : 2.957443953\n",
            "Epoch: 1180 || Loss : 2.956204414\n",
            "Epoch: 1190 || Loss : 2.951834679\n",
            "Epoch: 1200 || Loss : 2.955668449\n",
            "Epoch: 1210 || Loss : 2.953148127\n",
            "Epoch: 1220 || Loss : 2.952566385\n",
            "Epoch: 1230 || Loss : 2.955170631\n",
            "Epoch: 1240 || Loss : 2.955219269\n",
            "Epoch: 1250 || Loss : 2.953903437\n",
            "Epoch: 1260 || Loss : 2.952236176\n",
            "Epoch: 1270 || Loss : 2.953930616\n",
            "Epoch: 1280 || Loss : 2.951106071\n",
            "Epoch: 1290 || Loss : 2.950838089\n",
            "Epoch: 1300 || Loss : 2.953861475\n",
            "Epoch: 1310 || Loss : 2.952717066\n",
            "Epoch: 1320 || Loss : 2.954872370\n",
            "Epoch: 1330 || Loss : 2.952412605\n",
            "Epoch: 1340 || Loss : 2.951568604\n",
            "Epoch: 1350 || Loss : 2.952291965\n",
            "Epoch: 1360 || Loss : 2.950124264\n",
            "Epoch: 1370 || Loss : 2.953017235\n",
            "Epoch: 1380 || Loss : 2.952742338\n",
            "Epoch: 1390 || Loss : 2.952318907\n",
            "Epoch: 1400 || Loss : 2.950727224\n",
            "Epoch: 1410 || Loss : 2.951394796\n",
            "Epoch: 1420 || Loss : 2.950302362\n",
            "Epoch: 1430 || Loss : 2.950940132\n",
            "Epoch: 1440 || Loss : 2.954200029\n",
            "Epoch: 1450 || Loss : 2.951121092\n",
            "Epoch: 1460 || Loss : 2.951888561\n",
            "Epoch: 1470 || Loss : 2.949273348\n",
            "Epoch: 1480 || Loss : 2.950246334\n",
            "Epoch: 1490 || Loss : 2.946459055\n",
            "Epoch: 1500 || Loss : 2.948656797\n",
            "Epoch: 1510 || Loss : 2.951440334\n",
            "Epoch: 1520 || Loss : 2.946093082\n",
            "Epoch: 1530 || Loss : 2.954388142\n",
            "Epoch: 1540 || Loss : 2.948628426\n",
            "Epoch: 1550 || Loss : 2.947506905\n",
            "Epoch: 1560 || Loss : 2.949087143\n",
            "Epoch: 1570 || Loss : 2.946643353\n",
            "Epoch: 1580 || Loss : 2.950396776\n",
            "Epoch: 1590 || Loss : 2.946226358\n",
            "Epoch: 1600 || Loss : 2.951863766\n",
            "Epoch: 1610 || Loss : 2.947225809\n",
            "Epoch: 1620 || Loss : 2.949116945\n",
            "Epoch: 1630 || Loss : 2.946454525\n",
            "Epoch: 1640 || Loss : 2.944454670\n",
            "Epoch: 1650 || Loss : 2.948748589\n",
            "Epoch: 1660 || Loss : 2.948097467\n",
            "Epoch: 1670 || Loss : 2.950002432\n",
            "Epoch: 1680 || Loss : 2.949099779\n",
            "Epoch: 1690 || Loss : 2.947218657\n",
            "Epoch: 1700 || Loss : 2.947450638\n",
            "Epoch: 1710 || Loss : 2.946233749\n",
            "Epoch: 1720 || Loss : 2.949260473\n",
            "Epoch: 1730 || Loss : 2.947571993\n",
            "Epoch: 1740 || Loss : 2.947432756\n",
            "Epoch: 1750 || Loss : 2.948127985\n",
            "Epoch: 1760 || Loss : 2.946412086\n",
            "Epoch: 1770 || Loss : 2.946526766\n",
            "Epoch: 1780 || Loss : 2.947853088\n",
            "Epoch: 1790 || Loss : 2.947693825\n",
            "Epoch: 1800 || Loss : 2.945923567\n",
            "Epoch: 1810 || Loss : 2.947520733\n",
            "Epoch: 1820 || Loss : 2.944617510\n",
            "Epoch: 1830 || Loss : 2.946772575\n",
            "Epoch: 1840 || Loss : 2.947113037\n",
            "Epoch: 1850 || Loss : 2.946464777\n",
            "Epoch: 1860 || Loss : 2.947594881\n",
            "Epoch: 1870 || Loss : 2.943633080\n",
            "Epoch: 1880 || Loss : 2.945674658\n",
            "Epoch: 1890 || Loss : 2.943446636\n",
            "Epoch: 1900 || Loss : 2.944724083\n",
            "Epoch: 1910 || Loss : 2.949694157\n",
            "Epoch: 1920 || Loss : 2.944302797\n",
            "Epoch: 1930 || Loss : 2.948041439\n",
            "Epoch: 1940 || Loss : 2.945302486\n",
            "Epoch: 1950 || Loss : 2.944251299\n",
            "Epoch: 1960 || Loss : 2.943276644\n",
            "Epoch: 1970 || Loss : 2.942556858\n",
            "Epoch: 1980 || Loss : 2.948447227\n",
            "Epoch: 1990 || Loss : 2.944097757\n",
            "Epoch: 2000 || Loss : 2.947558165\n",
            "Epoch: 2010 || Loss : 2.944019556\n",
            "Epoch: 2020 || Loss : 2.943477869\n",
            "Epoch: 2030 || Loss : 2.942563534\n",
            "Epoch: 2040 || Loss : 2.941870928\n",
            "Epoch: 2050 || Loss : 2.945359230\n",
            "Epoch: 2060 || Loss : 2.945502281\n",
            "Epoch: 2070 || Loss : 2.944746017\n",
            "Epoch: 2080 || Loss : 2.944910526\n",
            "Epoch: 2090 || Loss : 2.943256855\n",
            "Epoch: 2100 || Loss : 2.943596840\n",
            "Epoch: 2110 || Loss : 2.946405649\n",
            "Epoch: 2120 || Loss : 2.943359613\n",
            "Epoch: 2130 || Loss : 2.947150469\n",
            "Epoch: 2140 || Loss : 2.941406965\n",
            "Epoch: 2150 || Loss : 2.943373680\n",
            "Epoch: 2160 || Loss : 2.942890406\n",
            "Epoch: 2170 || Loss : 2.943035126\n",
            "Epoch: 2180 || Loss : 2.946275473\n",
            "Epoch: 2190 || Loss : 2.940318346\n",
            "Epoch: 2200 || Loss : 2.945188761\n",
            "Epoch: 2210 || Loss : 2.939507008\n",
            "Epoch: 2220 || Loss : 2.941030741\n",
            "Epoch: 2230 || Loss : 2.945867777\n",
            "Epoch: 2240 || Loss : 2.937994003\n",
            "Epoch: 2250 || Loss : 2.950204849\n",
            "Epoch: 2260 || Loss : 2.937953234\n",
            "Epoch: 2270 || Loss : 2.947787046\n",
            "Epoch: 2280 || Loss : 2.941194296\n",
            "Epoch: 2290 || Loss : 2.938000679\n",
            "Epoch: 2300 || Loss : 2.947544575\n",
            "Epoch: 2310 || Loss : 2.934073210\n",
            "Epoch: 2320 || Loss : 2.951748133\n",
            "Epoch: 2330 || Loss : 2.935196638\n",
            "Epoch: 2340 || Loss : 2.944952250\n",
            "Epoch: 2350 || Loss : 2.944419146\n",
            "Epoch: 2360 || Loss : 2.931074142\n",
            "Epoch: 2370 || Loss : 2.951978445\n",
            "Epoch: 2380 || Loss : 2.930823565\n",
            "Epoch: 2390 || Loss : 2.951049328\n",
            "Epoch: 2400 || Loss : 2.935576916\n",
            "Epoch: 2410 || Loss : 2.941003323\n",
            "Epoch: 2420 || Loss : 2.944254875\n",
            "Epoch: 2430 || Loss : 2.934563398\n",
            "Epoch: 2440 || Loss : 2.942761421\n",
            "Epoch: 2450 || Loss : 2.938625336\n",
            "Epoch: 2460 || Loss : 2.946533203\n",
            "Epoch: 2470 || Loss : 2.942198038\n",
            "Epoch: 2480 || Loss : 2.941440344\n",
            "Epoch: 2490 || Loss : 2.944837093\n",
            "Epoch: 2500 || Loss : 2.937134743\n",
            "Epoch: 2510 || Loss : 2.943686485\n",
            "Epoch: 2520 || Loss : 2.940393209\n",
            "Epoch: 2530 || Loss : 2.939595938\n",
            "Epoch: 2540 || Loss : 2.950050831\n",
            "Epoch: 2550 || Loss : 2.931720257\n",
            "Epoch: 2560 || Loss : 2.949250937\n",
            "Epoch: 2570 || Loss : 2.934021473\n",
            "Epoch: 2580 || Loss : 2.938987017\n",
            "Epoch: 2590 || Loss : 2.948548555\n",
            "Epoch: 2600 || Loss : 2.929622412\n",
            "Epoch: 2610 || Loss : 2.958746195\n",
            "Epoch: 2620 || Loss : 2.926625252\n",
            "Epoch: 2630 || Loss : 2.948379993\n",
            "Epoch: 2640 || Loss : 2.932777166\n",
            "Epoch: 2650 || Loss : 2.933575392\n",
            "Epoch: 2660 || Loss : 2.956125975\n",
            "Epoch: 2670 || Loss : 2.922467232\n",
            "Epoch: 2680 || Loss : 2.967276335\n",
            "Epoch: 2690 || Loss : 2.924945593\n",
            "Epoch: 2700 || Loss : 2.946886778\n",
            "Epoch: 2710 || Loss : 2.938551426\n",
            "Epoch: 2720 || Loss : 2.936480284\n",
            "Epoch: 2730 || Loss : 2.948575258\n",
            "Epoch: 2740 || Loss : 2.939981461\n",
            "Epoch: 2750 || Loss : 2.944398403\n",
            "Epoch: 2760 || Loss : 2.943624496\n",
            "Epoch: 2770 || Loss : 2.939682245\n",
            "Epoch: 2780 || Loss : 2.946695328\n",
            "Epoch: 2790 || Loss : 2.935820341\n",
            "Epoch: 2800 || Loss : 2.942921400\n",
            "Epoch: 2810 || Loss : 2.940092325\n",
            "Epoch: 2820 || Loss : 2.935840607\n",
            "Epoch: 2830 || Loss : 2.949234486\n",
            "Epoch: 2840 || Loss : 2.934118509\n",
            "Epoch: 2850 || Loss : 2.946475029\n",
            "Epoch: 2860 || Loss : 2.938049793\n",
            "Epoch: 2870 || Loss : 2.934867620\n",
            "Epoch: 2880 || Loss : 2.947174311\n",
            "Epoch: 2890 || Loss : 2.932070255\n",
            "Epoch: 2900 || Loss : 2.951825142\n",
            "Epoch: 2910 || Loss : 2.929456711\n",
            "Epoch: 2920 || Loss : 2.942781687\n",
            "Epoch: 2930 || Loss : 2.940683842\n",
            "Epoch: 2940 || Loss : 2.929689646\n",
            "Epoch: 2950 || Loss : 2.952918053\n",
            "Epoch: 2960 || Loss : 2.928288698\n",
            "Epoch: 2970 || Loss : 2.949481964\n",
            "Epoch: 2980 || Loss : 2.930619717\n",
            "Epoch: 2990 || Loss : 2.935733080\n",
            "Epoch: 3000 || Loss : 2.943258524\n",
            "Epoch: 3010 || Loss : 2.934513092\n",
            "Epoch: 3020 || Loss : 2.944728851\n",
            "Epoch: 3030 || Loss : 2.934132338\n",
            "Epoch: 3040 || Loss : 2.938723564\n",
            "Epoch: 3050 || Loss : 2.936924458\n",
            "Epoch: 3060 || Loss : 2.934240580\n",
            "Epoch: 3070 || Loss : 2.941004992\n",
            "Epoch: 3080 || Loss : 2.933873177\n",
            "Epoch: 3090 || Loss : 2.940876484\n",
            "Epoch: 3100 || Loss : 2.938793898\n",
            "Epoch: 3110 || Loss : 2.934894800\n",
            "Epoch: 3120 || Loss : 2.944200993\n",
            "Epoch: 3130 || Loss : 2.928084135\n",
            "Epoch: 3140 || Loss : 2.942182779\n",
            "Epoch: 3150 || Loss : 2.935031652\n",
            "Epoch: 3160 || Loss : 2.934540033\n",
            "Epoch: 3170 || Loss : 2.945099592\n",
            "Epoch: 3180 || Loss : 2.927820444\n",
            "Epoch: 3190 || Loss : 2.950567007\n",
            "Epoch: 3200 || Loss : 2.924279690\n",
            "Epoch: 3210 || Loss : 2.943071365\n",
            "Epoch: 3220 || Loss : 2.937207699\n",
            "Epoch: 3230 || Loss : 2.927903414\n",
            "Epoch: 3240 || Loss : 2.950568438\n",
            "Epoch: 3250 || Loss : 2.919913769\n",
            "Epoch: 3260 || Loss : 2.953597069\n",
            "Epoch: 3270 || Loss : 2.926058531\n",
            "Epoch: 3280 || Loss : 2.938328743\n",
            "Epoch: 3290 || Loss : 2.939896822\n",
            "Epoch: 3300 || Loss : 2.928381681\n",
            "Epoch: 3310 || Loss : 2.944681406\n",
            "Epoch: 3320 || Loss : 2.934011459\n",
            "Epoch: 3330 || Loss : 2.936543226\n",
            "Epoch: 3340 || Loss : 2.941111803\n",
            "Epoch: 3350 || Loss : 2.936306953\n",
            "Epoch: 3360 || Loss : 2.939476728\n",
            "Epoch: 3370 || Loss : 2.935795784\n",
            "Epoch: 3380 || Loss : 2.934641838\n",
            "Epoch: 3390 || Loss : 2.940335512\n",
            "Epoch: 3400 || Loss : 2.934294701\n",
            "Epoch: 3410 || Loss : 2.942413092\n",
            "Epoch: 3420 || Loss : 2.935172796\n",
            "Epoch: 3430 || Loss : 2.935556889\n",
            "Epoch: 3440 || Loss : 2.938077211\n",
            "Epoch: 3450 || Loss : 2.931556940\n",
            "Epoch: 3460 || Loss : 2.944659233\n",
            "Epoch: 3470 || Loss : 2.930311441\n",
            "Epoch: 3480 || Loss : 2.941167355\n",
            "Epoch: 3490 || Loss : 2.932687998\n",
            "Epoch: 3500 || Loss : 2.930700541\n",
            "Epoch: 3510 || Loss : 2.946904421\n",
            "Epoch: 3520 || Loss : 2.926648378\n",
            "Epoch: 3530 || Loss : 2.952833652\n",
            "Epoch: 3540 || Loss : 2.926945210\n",
            "Epoch: 3550 || Loss : 2.939154625\n",
            "Epoch: 3560 || Loss : 2.937086344\n",
            "Epoch: 3570 || Loss : 2.924476862\n",
            "Epoch: 3580 || Loss : 2.948795080\n",
            "Epoch: 3590 || Loss : 2.920805931\n",
            "Epoch: 3600 || Loss : 2.945894241\n",
            "Epoch: 3610 || Loss : 2.931672096\n",
            "Epoch: 3620 || Loss : 2.936206818\n",
            "Epoch: 3630 || Loss : 2.937694311\n",
            "Epoch: 3640 || Loss : 2.932864428\n",
            "Epoch: 3650 || Loss : 2.937546968\n",
            "Epoch: 3660 || Loss : 2.935599327\n",
            "Epoch: 3670 || Loss : 2.937218904\n",
            "Epoch: 3680 || Loss : 2.938687325\n",
            "Epoch: 3690 || Loss : 2.932157755\n",
            "Epoch: 3700 || Loss : 2.937393904\n",
            "Epoch: 3710 || Loss : 2.936011314\n",
            "Epoch: 3720 || Loss : 2.936220884\n",
            "Epoch: 3730 || Loss : 2.936698198\n",
            "Epoch: 3740 || Loss : 2.933971167\n",
            "Epoch: 3750 || Loss : 2.937360048\n",
            "Epoch: 3760 || Loss : 2.930841208\n",
            "Epoch: 3770 || Loss : 2.941565514\n",
            "Epoch: 3780 || Loss : 2.935086966\n",
            "Epoch: 3790 || Loss : 2.932820320\n",
            "Epoch: 3800 || Loss : 2.941427469\n",
            "Epoch: 3810 || Loss : 2.926454782\n",
            "Epoch: 3820 || Loss : 2.944899082\n",
            "Epoch: 3830 || Loss : 2.930194378\n",
            "Epoch: 3840 || Loss : 2.936856270\n",
            "Epoch: 3850 || Loss : 2.940357447\n",
            "Epoch: 3860 || Loss : 2.924549818\n",
            "Epoch: 3870 || Loss : 2.948896885\n",
            "Epoch: 3880 || Loss : 2.922186375\n",
            "Epoch: 3890 || Loss : 2.945571184\n",
            "Epoch: 3900 || Loss : 2.931460381\n",
            "Epoch: 3910 || Loss : 2.932830811\n",
            "Epoch: 3920 || Loss : 2.942060471\n",
            "Epoch: 3930 || Loss : 2.929436684\n",
            "Epoch: 3940 || Loss : 2.940524101\n",
            "Epoch: 3950 || Loss : 2.937564135\n",
            "Epoch: 3960 || Loss : 2.936851263\n",
            "Epoch: 3970 || Loss : 2.940714598\n",
            "Epoch: 3980 || Loss : 2.932665586\n",
            "Epoch: 3990 || Loss : 2.937012196\n",
            "Epoch: 4000 || Loss : 2.936119795\n",
            "Epoch: 4010 || Loss : 2.934021711\n",
            "Epoch: 4020 || Loss : 2.940912724\n",
            "Epoch: 4030 || Loss : 2.933359623\n",
            "Epoch: 4040 || Loss : 2.937124729\n",
            "Epoch: 4050 || Loss : 2.932367802\n",
            "Epoch: 4060 || Loss : 2.935784340\n",
            "Epoch: 4070 || Loss : 2.937908411\n",
            "Epoch: 4080 || Loss : 2.929309607\n",
            "Epoch: 4090 || Loss : 2.941068172\n",
            "Epoch: 4100 || Loss : 2.928760290\n",
            "Epoch: 4110 || Loss : 2.939408064\n",
            "Epoch: 4120 || Loss : 2.935585022\n",
            "Epoch: 4130 || Loss : 2.932655573\n",
            "Epoch: 4140 || Loss : 2.942459345\n",
            "Epoch: 4150 || Loss : 2.926755190\n",
            "Epoch: 4160 || Loss : 2.941165447\n",
            "Epoch: 4170 || Loss : 2.929603577\n",
            "Epoch: 4180 || Loss : 2.933041573\n",
            "Epoch: 4190 || Loss : 2.939038038\n",
            "Epoch: 4200 || Loss : 2.928110600\n",
            "Epoch: 4210 || Loss : 2.943497896\n",
            "Epoch: 4220 || Loss : 2.929665327\n",
            "Epoch: 4230 || Loss : 2.938308477\n",
            "Epoch: 4240 || Loss : 2.935456514\n",
            "Epoch: 4250 || Loss : 2.933395863\n",
            "Epoch: 4260 || Loss : 2.934864044\n",
            "Epoch: 4270 || Loss : 2.935733318\n",
            "Epoch: 4280 || Loss : 2.934836626\n",
            "Epoch: 4290 || Loss : 2.933782101\n",
            "Epoch: 4300 || Loss : 2.937267542\n",
            "Epoch: 4310 || Loss : 2.932351828\n",
            "Epoch: 4320 || Loss : 2.935334206\n",
            "Epoch: 4330 || Loss : 2.935789585\n",
            "Epoch: 4340 || Loss : 2.931928158\n",
            "Epoch: 4350 || Loss : 2.937262058\n",
            "Epoch: 4360 || Loss : 2.932126522\n",
            "Epoch: 4370 || Loss : 2.936731577\n",
            "Epoch: 4380 || Loss : 2.932679653\n",
            "Epoch: 4390 || Loss : 2.932818651\n",
            "Epoch: 4400 || Loss : 2.938127995\n",
            "Epoch: 4410 || Loss : 2.929378986\n",
            "Epoch: 4420 || Loss : 2.940026760\n",
            "Epoch: 4430 || Loss : 2.930205822\n",
            "Epoch: 4440 || Loss : 2.935094833\n",
            "Epoch: 4450 || Loss : 2.935239315\n",
            "Epoch: 4460 || Loss : 2.928556681\n",
            "Epoch: 4470 || Loss : 2.941234827\n",
            "Epoch: 4480 || Loss : 2.927066565\n",
            "Epoch: 4490 || Loss : 2.937347174\n",
            "Epoch: 4500 || Loss : 2.932324886\n",
            "Epoch: 4510 || Loss : 2.931624889\n",
            "Epoch: 4520 || Loss : 2.937452555\n",
            "Epoch: 4530 || Loss : 2.930214882\n",
            "Epoch: 4540 || Loss : 2.934339046\n",
            "Epoch: 4550 || Loss : 2.933552742\n",
            "Epoch: 4560 || Loss : 2.932679176\n",
            "Epoch: 4570 || Loss : 2.934515953\n",
            "Epoch: 4580 || Loss : 2.931103230\n",
            "Epoch: 4590 || Loss : 2.934769154\n",
            "Epoch: 4600 || Loss : 2.931617498\n",
            "Epoch: 4610 || Loss : 2.932798624\n",
            "Epoch: 4620 || Loss : 2.935067892\n",
            "Epoch: 4630 || Loss : 2.931943893\n",
            "Epoch: 4640 || Loss : 2.936245680\n",
            "Epoch: 4650 || Loss : 2.931897879\n",
            "Epoch: 4660 || Loss : 2.933233738\n",
            "Epoch: 4670 || Loss : 2.933828115\n",
            "Epoch: 4680 || Loss : 2.930072784\n",
            "Epoch: 4690 || Loss : 2.937004805\n",
            "Epoch: 4700 || Loss : 2.928675652\n",
            "Epoch: 4710 || Loss : 2.935442448\n",
            "Epoch: 4720 || Loss : 2.932283640\n",
            "Epoch: 4730 || Loss : 2.930905581\n",
            "Epoch: 4740 || Loss : 2.936345816\n",
            "Epoch: 4750 || Loss : 2.928584576\n",
            "Epoch: 4760 || Loss : 2.937451839\n",
            "Epoch: 4770 || Loss : 2.929213047\n",
            "Epoch: 4780 || Loss : 2.933156490\n",
            "Epoch: 4790 || Loss : 2.933872938\n",
            "Epoch: 4800 || Loss : 2.930285931\n",
            "Epoch: 4810 || Loss : 2.934634209\n",
            "Epoch: 4820 || Loss : 2.930984974\n",
            "Epoch: 4830 || Loss : 2.934124231\n",
            "Epoch: 4840 || Loss : 2.930061817\n",
            "Epoch: 4850 || Loss : 2.934726000\n",
            "Epoch: 4860 || Loss : 2.932449102\n",
            "Epoch: 4870 || Loss : 2.933924675\n",
            "Epoch: 4880 || Loss : 2.933327913\n",
            "Epoch: 4890 || Loss : 2.932581663\n",
            "Epoch: 4900 || Loss : 2.934108734\n",
            "Epoch: 4910 || Loss : 2.931264877\n",
            "Epoch: 4920 || Loss : 2.935552597\n",
            "Epoch: 4930 || Loss : 2.932579756\n",
            "Epoch: 4940 || Loss : 2.930638313\n",
            "Epoch: 4950 || Loss : 2.934805155\n",
            "Epoch: 4960 || Loss : 2.930256605\n",
            "Epoch: 4970 || Loss : 2.935595036\n",
            "Epoch: 4980 || Loss : 2.930703402\n",
            "Epoch: 4990 || Loss : 2.931888103\n",
            "Epoch: 5000 || Loss : 2.934298992\n",
            "Epoch: 5010 || Loss : 2.931532860\n",
            "Epoch: 5020 || Loss : 2.936602592\n",
            "Epoch: 5030 || Loss : 2.931581974\n",
            "Epoch: 5040 || Loss : 2.933749199\n",
            "Epoch: 5050 || Loss : 2.932740450\n",
            "Epoch: 5060 || Loss : 2.932616234\n",
            "Epoch: 5070 || Loss : 2.934676170\n",
            "Epoch: 5080 || Loss : 2.930629730\n",
            "Epoch: 5090 || Loss : 2.934694529\n",
            "Epoch: 5100 || Loss : 2.995963812\n",
            "Epoch: 5110 || Loss : 2.934063196\n",
            "Epoch: 5120 || Loss : 2.933877468\n",
            "Epoch: 5130 || Loss : 2.931564808\n",
            "Epoch: 5140 || Loss : 2.938277960\n",
            "Epoch: 5150 || Loss : 2.930130482\n",
            "Epoch: 5160 || Loss : 2.935306311\n",
            "Epoch: 5170 || Loss : 2.934741974\n",
            "Epoch: 5180 || Loss : 2.929631472\n",
            "Epoch: 5190 || Loss : 2.936414719\n",
            "Epoch: 5200 || Loss : 2.929898262\n",
            "Epoch: 5210 || Loss : 2.935286283\n",
            "Epoch: 5220 || Loss : 2.932260990\n",
            "Epoch: 5230 || Loss : 2.930091381\n",
            "Epoch: 5240 || Loss : 2.936490059\n",
            "Epoch: 5250 || Loss : 2.927457333\n",
            "Epoch: 5260 || Loss : 2.935594082\n",
            "Epoch: 5270 || Loss : 2.930928707\n",
            "Epoch: 5280 || Loss : 2.931262732\n",
            "Epoch: 5290 || Loss : 2.936971426\n",
            "Epoch: 5300 || Loss : 2.926687717\n",
            "Epoch: 5310 || Loss : 2.938029051\n",
            "Epoch: 5320 || Loss : 2.927593946\n",
            "Epoch: 5330 || Loss : 2.933060169\n",
            "Epoch: 5340 || Loss : 2.935843945\n",
            "Epoch: 5350 || Loss : 2.925857067\n",
            "Epoch: 5360 || Loss : 2.939496517\n",
            "Epoch: 5370 || Loss : 2.925712109\n",
            "Epoch: 5380 || Loss : 2.936693430\n",
            "Epoch: 5390 || Loss : 2.931035280\n",
            "Epoch: 5400 || Loss : 2.930098057\n",
            "Epoch: 5410 || Loss : 2.933379650\n",
            "Epoch: 5420 || Loss : 2.929767132\n",
            "Epoch: 5430 || Loss : 2.935117960\n",
            "Epoch: 5440 || Loss : 2.928230047\n",
            "Epoch: 5450 || Loss : 2.934800863\n",
            "Epoch: 5460 || Loss : 2.929982901\n",
            "Epoch: 5470 || Loss : 2.931620121\n",
            "Epoch: 5480 || Loss : 2.934413195\n",
            "Epoch: 5490 || Loss : 2.928673983\n",
            "Epoch: 5500 || Loss : 2.936355114\n",
            "Epoch: 5510 || Loss : 2.927784204\n",
            "Epoch: 5520 || Loss : 2.933195591\n",
            "Epoch: 5530 || Loss : 2.931083679\n",
            "Epoch: 5540 || Loss : 2.927924633\n",
            "Epoch: 5550 || Loss : 2.936281919\n",
            "Epoch: 5560 || Loss : 2.925352335\n",
            "Epoch: 5570 || Loss : 2.936726570\n",
            "Epoch: 5580 || Loss : 2.926934958\n",
            "Epoch: 5590 || Loss : 2.930195808\n",
            "Epoch: 5600 || Loss : 2.935262442\n",
            "Epoch: 5610 || Loss : 2.923324347\n",
            "Epoch: 5620 || Loss : 2.940924644\n",
            "Epoch: 5630 || Loss : 2.922865152\n",
            "Epoch: 5640 || Loss : 2.935492039\n",
            "Epoch: 5650 || Loss : 2.929652214\n",
            "Epoch: 5660 || Loss : 2.927995920\n",
            "Epoch: 5670 || Loss : 2.934935808\n",
            "Epoch: 5680 || Loss : 2.927074432\n",
            "Epoch: 5690 || Loss : 2.932364464\n",
            "Epoch: 5700 || Loss : 2.931365490\n",
            "Epoch: 5710 || Loss : 2.928104639\n",
            "Epoch: 5720 || Loss : 2.933071613\n",
            "Epoch: 5730 || Loss : 2.928053617\n",
            "Epoch: 5740 || Loss : 2.931867599\n",
            "Epoch: 5750 || Loss : 2.931179285\n",
            "Epoch: 5760 || Loss : 2.927961588\n",
            "Epoch: 5770 || Loss : 2.933277130\n",
            "Epoch: 5780 || Loss : 2.926289320\n",
            "Epoch: 5790 || Loss : 2.933633327\n",
            "Epoch: 5800 || Loss : 2.929298401\n",
            "Epoch: 5810 || Loss : 2.928848505\n",
            "Epoch: 5820 || Loss : 2.933104992\n",
            "Epoch: 5830 || Loss : 2.926633120\n",
            "Epoch: 5840 || Loss : 2.935573816\n",
            "Epoch: 5850 || Loss : 2.926885128\n",
            "Epoch: 5860 || Loss : 2.930202961\n",
            "Epoch: 5870 || Loss : 2.933135748\n",
            "Epoch: 5880 || Loss : 2.926235437\n",
            "Epoch: 5890 || Loss : 2.934968710\n",
            "Epoch: 5900 || Loss : 2.926601171\n",
            "Epoch: 5910 || Loss : 2.933129549\n",
            "Epoch: 5920 || Loss : 2.930351019\n",
            "Epoch: 5930 || Loss : 2.929420233\n",
            "Epoch: 5940 || Loss : 2.932685852\n",
            "Epoch: 5950 || Loss : 2.929155588\n",
            "Epoch: 5960 || Loss : 2.932052851\n",
            "Epoch: 5970 || Loss : 2.931454659\n",
            "Epoch: 5980 || Loss : 2.931503296\n",
            "Epoch: 5990 || Loss : 2.928963423\n",
            "Epoch: 6000 || Loss : 2.933220387\n",
            "Epoch: 6010 || Loss : 2.928840399\n",
            "Epoch: 6020 || Loss : 2.932261705\n",
            "Epoch: 6030 || Loss : 2.930630445\n",
            "Epoch: 6040 || Loss : 2.929934502\n",
            "Epoch: 6050 || Loss : 2.931832075\n",
            "Epoch: 6060 || Loss : 2.930622101\n",
            "Epoch: 6070 || Loss : 2.930904388\n",
            "Epoch: 6080 || Loss : 2.931836128\n",
            "Epoch: 6090 || Loss : 2.932483673\n",
            "Epoch: 6100 || Loss : 2.929312706\n",
            "Epoch: 6110 || Loss : 2.931486368\n",
            "Epoch: 6120 || Loss : 2.929871082\n",
            "Epoch: 6130 || Loss : 2.930498600\n",
            "Epoch: 6140 || Loss : 2.932173729\n",
            "Epoch: 6150 || Loss : 2.930439949\n",
            "Epoch: 6160 || Loss : 2.933050394\n",
            "Epoch: 6170 || Loss : 2.928608418\n",
            "Epoch: 6180 || Loss : 2.933095932\n",
            "Epoch: 6190 || Loss : 2.930106640\n",
            "Epoch: 6200 || Loss : 2.934052944\n",
            "Epoch: 6210 || Loss : 2.931491852\n",
            "Epoch: 6220 || Loss : 2.931375504\n",
            "Epoch: 6230 || Loss : 2.934457541\n",
            "Epoch: 6240 || Loss : 2.928148508\n",
            "Epoch: 6250 || Loss : 2.935398817\n",
            "Epoch: 6260 || Loss : 2.928902626\n",
            "Epoch: 6270 || Loss : 2.932260990\n",
            "Epoch: 6280 || Loss : 2.931400299\n",
            "Epoch: 6290 || Loss : 2.929919958\n",
            "Epoch: 6300 || Loss : 2.931369066\n",
            "Epoch: 6310 || Loss : 2.929012537\n",
            "Epoch: 6320 || Loss : 2.929731607\n",
            "Epoch: 6330 || Loss : 2.929138899\n",
            "Epoch: 6340 || Loss : 2.932008743\n",
            "Epoch: 6350 || Loss : 2.928446293\n",
            "Epoch: 6360 || Loss : 2.933013678\n",
            "Epoch: 6370 || Loss : 2.930975676\n",
            "Epoch: 6380 || Loss : 2.929995537\n",
            "Epoch: 6390 || Loss : 2.933158398\n",
            "Epoch: 6400 || Loss : 2.931391478\n",
            "Epoch: 6410 || Loss : 2.935493231\n",
            "Epoch: 6420 || Loss : 2.932182789\n",
            "Epoch: 6430 || Loss : 2.932031393\n",
            "Epoch: 6440 || Loss : 2.930217028\n",
            "Epoch: 6450 || Loss : 2.929020166\n",
            "Epoch: 6460 || Loss : 2.928107977\n",
            "Epoch: 6470 || Loss : 2.926527739\n",
            "Epoch: 6480 || Loss : 2.927485228\n",
            "Epoch: 6490 || Loss : 2.928538799\n",
            "Epoch: 6500 || Loss : 2.929911375\n",
            "Epoch: 6510 || Loss : 2.930197477\n",
            "Epoch: 6520 || Loss : 2.929131269\n",
            "Epoch: 6530 || Loss : 2.929172516\n",
            "Epoch: 6540 || Loss : 2.928740025\n",
            "Epoch: 6550 || Loss : 2.930818558\n",
            "Epoch: 6560 || Loss : 2.928526878\n",
            "Epoch: 6570 || Loss : 2.932296038\n",
            "Epoch: 6580 || Loss : 2.927174807\n",
            "Epoch: 6590 || Loss : 2.929868460\n",
            "Epoch: 6600 || Loss : 2.931784153\n",
            "Epoch: 6610 || Loss : 2.927038670\n",
            "Epoch: 6620 || Loss : 2.932409525\n",
            "Epoch: 6630 || Loss : 2.926300287\n",
            "Epoch: 6640 || Loss : 2.931772709\n",
            "Epoch: 6650 || Loss : 2.930916786\n",
            "Epoch: 6660 || Loss : 2.927440166\n",
            "Epoch: 6670 || Loss : 2.929227591\n",
            "Epoch: 6680 || Loss : 2.928855181\n",
            "Epoch: 6690 || Loss : 2.930916071\n",
            "Epoch: 6700 || Loss : 2.930126190\n",
            "Epoch: 6710 || Loss : 2.926531553\n",
            "Epoch: 6720 || Loss : 2.931087971\n",
            "Epoch: 6730 || Loss : 2.928793430\n",
            "Epoch: 6740 || Loss : 2.930070162\n",
            "Epoch: 6750 || Loss : 2.929698467\n",
            "Epoch: 6760 || Loss : 2.926421165\n",
            "Epoch: 6770 || Loss : 2.930868387\n",
            "Epoch: 6780 || Loss : 2.884228230\n",
            "Epoch: 6790 || Loss : 2.923247337\n",
            "Epoch: 6800 || Loss : 2.922460318\n",
            "Epoch: 6810 || Loss : 2.922645330\n",
            "Epoch: 6820 || Loss : 2.929861069\n",
            "Epoch: 6830 || Loss : 2.923108578\n",
            "Epoch: 6840 || Loss : 2.888805151\n",
            "Epoch: 6850 || Loss : 2.941496611\n",
            "Epoch: 6860 || Loss : 2.918972492\n",
            "Epoch: 6870 || Loss : 2.947779179\n",
            "Epoch: 6880 || Loss : 2.914926529\n",
            "Epoch: 6890 || Loss : 2.945505381\n",
            "Epoch: 6900 || Loss : 2.917451382\n",
            "Epoch: 6910 || Loss : 2.927580357\n",
            "Epoch: 6920 || Loss : 2.934642315\n",
            "Epoch: 6930 || Loss : 2.911987066\n",
            "Epoch: 6940 || Loss : 2.958749056\n",
            "Epoch: 6950 || Loss : 2.904389620\n",
            "Epoch: 6960 || Loss : 2.968711138\n",
            "Epoch: 6970 || Loss : 2.903795242\n",
            "Epoch: 6980 || Loss : 2.949053288\n",
            "Epoch: 6990 || Loss : 2.905012131\n",
            "Epoch: 7000 || Loss : 2.933478832\n",
            "Epoch: 7010 || Loss : 2.904799938\n",
            "Epoch: 7020 || Loss : 2.925429106\n",
            "Epoch: 7030 || Loss : 2.903881550\n",
            "Epoch: 7040 || Loss : 2.918833494\n",
            "Epoch: 7050 || Loss : 2.904779196\n",
            "Epoch: 7060 || Loss : 2.912558556\n",
            "Epoch: 7070 || Loss : 2.901716948\n",
            "Epoch: 7080 || Loss : 2.934608698\n",
            "Epoch: 7090 || Loss : 2.896242142\n",
            "Epoch: 7100 || Loss : 2.939249992\n",
            "Epoch: 7110 || Loss : 2.900173187\n",
            "Epoch: 7120 || Loss : 2.932345152\n",
            "Epoch: 7130 || Loss : 2.923190832\n",
            "Epoch: 7140 || Loss : 7.194828987\n",
            "Epoch: 7150 || Loss : 2.923963308\n",
            "Epoch: 7160 || Loss : 2.940690279\n",
            "Epoch: 7170 || Loss : 2.922082186\n",
            "Epoch: 7180 || Loss : 2.933288813\n",
            "Epoch: 7190 || Loss : 2.924462795\n",
            "Epoch: 7200 || Loss : 2.924530029\n",
            "Epoch: 7210 || Loss : 2.938302994\n",
            "Epoch: 7220 || Loss : 2.918534040\n",
            "Epoch: 7230 || Loss : 2.941524744\n",
            "Epoch: 7240 || Loss : 2.914698362\n",
            "Epoch: 7250 || Loss : 2.933887005\n",
            "Epoch: 7260 || Loss : 2.922344446\n",
            "Epoch: 7270 || Loss : 2.920226097\n",
            "Epoch: 7280 || Loss : 2.945950985\n",
            "Epoch: 7290 || Loss : 2.908700705\n",
            "Epoch: 7300 || Loss : 2.962985039\n",
            "Epoch: 7310 || Loss : 2.896176338\n",
            "Epoch: 7320 || Loss : 2.957727194\n",
            "Epoch: 7330 || Loss : 2.894336939\n",
            "Epoch: 7340 || Loss : 2.936891079\n",
            "Epoch: 7350 || Loss : 2.909849644\n",
            "Epoch: 7360 || Loss : 2.908301115\n",
            "Epoch: 7370 || Loss : 2.895800829\n",
            "Epoch: 7380 || Loss : 2.903942823\n",
            "Epoch: 7390 || Loss : 2.959674358\n",
            "Epoch: 7400 || Loss : 2.900492191\n",
            "Epoch: 7410 || Loss : 2.951425552\n",
            "Epoch: 7420 || Loss : 2.910031319\n",
            "Epoch: 7430 || Loss : 2.924854279\n",
            "Epoch: 7440 || Loss : 2.935065031\n",
            "Epoch: 7450 || Loss : 2.902727365\n",
            "Epoch: 7460 || Loss : 2.965882301\n",
            "Epoch: 7470 || Loss : 2.900358677\n",
            "Epoch: 7480 || Loss : 2.949800253\n",
            "Epoch: 7490 || Loss : 2.917963028\n",
            "Epoch: 7500 || Loss : 2.917551279\n",
            "Epoch: 7510 || Loss : 2.937047720\n",
            "Epoch: 7520 || Loss : 2.913263083\n",
            "Epoch: 7530 || Loss : 2.934454203\n",
            "Epoch: 7540 || Loss : 2.922517300\n",
            "Epoch: 7550 || Loss : 2.928375959\n",
            "Epoch: 7560 || Loss : 2.927709341\n",
            "Epoch: 7570 || Loss : 2.928147078\n",
            "Epoch: 7580 || Loss : 2.929561615\n",
            "Epoch: 7590 || Loss : 2.922083855\n",
            "Epoch: 7600 || Loss : 2.931411028\n",
            "Epoch: 7610 || Loss : 2.922586918\n",
            "Epoch: 7620 || Loss : 2.930394173\n",
            "Epoch: 7630 || Loss : 2.924302101\n",
            "Epoch: 7640 || Loss : 2.924064159\n",
            "Epoch: 7650 || Loss : 2.931880713\n",
            "Epoch: 7660 || Loss : 2.918198824\n",
            "Epoch: 7670 || Loss : 2.938033581\n",
            "Epoch: 7680 || Loss : 2.918165445\n",
            "Epoch: 7690 || Loss : 2.931366682\n",
            "Epoch: 7700 || Loss : 2.926143408\n",
            "Epoch: 7710 || Loss : 2.921942711\n",
            "Epoch: 7720 || Loss : 2.938323021\n",
            "Epoch: 7730 || Loss : 2.913762331\n",
            "Epoch: 7740 || Loss : 2.945588589\n",
            "Epoch: 7750 || Loss : 2.915294170\n",
            "Epoch: 7760 || Loss : 2.935277224\n",
            "Epoch: 7770 || Loss : 2.915355444\n",
            "Epoch: 7780 || Loss : 2.917666197\n",
            "Epoch: 7790 || Loss : 2.940661430\n",
            "Epoch: 7800 || Loss : 2.904581547\n",
            "Epoch: 7810 || Loss : 2.971398592\n",
            "Epoch: 7820 || Loss : 2.897476196\n",
            "Epoch: 7830 || Loss : 2.969563961\n",
            "Epoch: 7840 || Loss : 2.897524357\n",
            "Epoch: 7850 || Loss : 2.947294474\n",
            "Epoch: 7860 || Loss : 2.907124758\n",
            "Epoch: 7870 || Loss : 2.920737982\n",
            "Epoch: 7880 || Loss : 2.930784941\n",
            "Epoch: 7890 || Loss : 2.907274008\n",
            "Epoch: 7900 || Loss : 2.955497742\n",
            "Epoch: 7910 || Loss : 2.907225847\n",
            "Epoch: 7920 || Loss : 2.938961744\n",
            "Epoch: 7930 || Loss : 2.922164917\n",
            "Epoch: 7940 || Loss : 2.922976494\n",
            "Epoch: 7950 || Loss : 2.931970119\n",
            "Epoch: 7960 || Loss : 2.923538685\n",
            "Epoch: 7970 || Loss : 2.928436518\n",
            "Epoch: 7980 || Loss : 2.926012278\n",
            "Epoch: 7990 || Loss : 2.928147554\n",
            "Epoch: 8000 || Loss : 2.928998232\n",
            "Epoch: 8010 || Loss : 2.926318407\n",
            "Epoch: 8020 || Loss : 2.926709890\n",
            "Epoch: 8030 || Loss : 2.927267075\n",
            "Epoch: 8040 || Loss : 2.924012661\n",
            "Epoch: 8050 || Loss : 2.926842213\n",
            "Epoch: 8060 || Loss : 2.926369429\n",
            "Epoch: 8070 || Loss : 2.925979376\n",
            "Epoch: 8080 || Loss : 2.925947428\n",
            "Epoch: 8090 || Loss : 2.926759720\n",
            "Epoch: 8100 || Loss : 2.924769402\n",
            "Epoch: 8110 || Loss : 2.925548315\n",
            "Epoch: 8120 || Loss : 2.926121473\n",
            "Epoch: 8130 || Loss : 2.925473452\n",
            "Epoch: 8140 || Loss : 2.926798105\n",
            "Epoch: 8150 || Loss : 2.925855398\n",
            "Epoch: 8160 || Loss : 2.926602602\n",
            "Epoch: 8170 || Loss : 2.926195383\n",
            "Epoch: 8180 || Loss : 2.921631098\n",
            "Epoch: 8190 || Loss : 2.931246758\n",
            "Epoch: 8200 || Loss : 2.920798540\n",
            "Epoch: 8210 || Loss : 2.928814650\n",
            "Epoch: 8220 || Loss : 2.923412561\n",
            "Epoch: 8230 || Loss : 2.920233250\n",
            "Epoch: 8240 || Loss : 2.932358027\n",
            "Epoch: 8250 || Loss : 2.918995380\n",
            "Epoch: 8260 || Loss : 2.932577133\n",
            "Epoch: 8270 || Loss : 2.921179771\n",
            "Epoch: 8280 || Loss : 2.923799753\n",
            "Epoch: 8290 || Loss : 2.928019524\n",
            "Epoch: 8300 || Loss : 2.915029764\n",
            "Epoch: 8310 || Loss : 2.933683634\n",
            "Epoch: 8320 || Loss : 2.918674946\n",
            "Epoch: 8330 || Loss : 2.924940586\n",
            "Epoch: 8340 || Loss : 2.929136276\n",
            "Epoch: 8350 || Loss : 2.917583466\n",
            "Epoch: 8360 || Loss : 2.931152105\n",
            "Epoch: 8370 || Loss : 2.923130751\n",
            "Epoch: 8380 || Loss : 2.925527096\n",
            "Epoch: 8390 || Loss : 2.925853968\n",
            "Epoch: 8400 || Loss : 2.922059536\n",
            "Epoch: 8410 || Loss : 2.925020933\n",
            "Epoch: 8420 || Loss : 2.922157526\n",
            "Epoch: 8430 || Loss : 2.924808025\n",
            "Epoch: 8440 || Loss : 2.927211046\n",
            "Epoch: 8450 || Loss : 2.924693584\n",
            "Epoch: 8460 || Loss : 2.923834562\n",
            "Epoch: 8470 || Loss : 2.923844576\n",
            "Epoch: 8480 || Loss : 2.925360680\n",
            "Epoch: 8490 || Loss : 2.925118685\n",
            "Epoch: 8500 || Loss : 2.923531055\n",
            "Epoch: 8510 || Loss : 2.924791098\n",
            "Epoch: 8520 || Loss : 2.921887636\n",
            "Epoch: 8530 || Loss : 2.923181057\n",
            "Epoch: 8540 || Loss : 2.926593542\n",
            "Epoch: 8550 || Loss : 2.924593925\n",
            "Epoch: 8560 || Loss : 2.926842213\n",
            "Epoch: 8570 || Loss : 2.919935465\n",
            "Epoch: 8580 || Loss : 2.924386024\n",
            "Epoch: 8590 || Loss : 2.922178030\n",
            "Epoch: 8600 || Loss : 2.921553373\n",
            "Epoch: 8610 || Loss : 2.927124023\n",
            "Epoch: 8620 || Loss : 2.917754889\n",
            "Epoch: 8630 || Loss : 2.927304029\n",
            "Epoch: 8640 || Loss : 2.923700571\n",
            "Epoch: 8650 || Loss : 2.922665358\n",
            "Epoch: 8660 || Loss : 2.926436901\n",
            "Epoch: 8670 || Loss : 2.915494919\n",
            "Epoch: 8680 || Loss : 2.930050135\n",
            "Epoch: 8690 || Loss : 2.916678190\n",
            "Epoch: 8700 || Loss : 2.925322771\n",
            "Epoch: 8710 || Loss : 2.928474665\n",
            "Epoch: 8720 || Loss : 2.913868904\n",
            "Epoch: 8730 || Loss : 2.934603930\n",
            "Epoch: 8740 || Loss : 2.912650347\n",
            "Epoch: 8750 || Loss : 2.928952456\n",
            "Epoch: 8760 || Loss : 2.918554783\n",
            "Epoch: 8770 || Loss : 2.918774128\n",
            "Epoch: 8780 || Loss : 2.929049492\n",
            "Epoch: 8790 || Loss : 2.914014578\n",
            "Epoch: 8800 || Loss : 2.927627563\n",
            "Epoch: 8810 || Loss : 2.918906450\n",
            "Epoch: 8820 || Loss : 2.920796156\n",
            "Epoch: 8830 || Loss : 2.925051451\n",
            "Epoch: 8840 || Loss : 2.919871092\n",
            "Epoch: 8850 || Loss : 3.994157314\n",
            "Epoch: 8860 || Loss : 2.920618057\n",
            "Epoch: 8870 || Loss : 2.920207977\n",
            "Epoch: 8880 || Loss : 2.922303438\n",
            "Epoch: 8890 || Loss : 2.917020082\n",
            "Epoch: 8900 || Loss : 2.922130585\n",
            "Epoch: 8910 || Loss : 2.919890642\n",
            "Epoch: 8920 || Loss : 2.920415401\n",
            "Epoch: 8930 || Loss : 2.924293756\n",
            "Epoch: 8940 || Loss : 2.919686794\n",
            "Epoch: 8950 || Loss : 2.930217505\n",
            "Epoch: 8960 || Loss : 2.916601658\n",
            "Epoch: 8970 || Loss : 2.927107096\n",
            "Epoch: 8980 || Loss : 2.919283867\n",
            "Epoch: 8990 || Loss : 2.918938398\n",
            "Epoch: 9000 || Loss : 2.929083586\n",
            "Epoch: 9010 || Loss : 2.911405802\n",
            "Epoch: 9020 || Loss : 2.930467367\n",
            "Epoch: 9030 || Loss : 2.915282726\n",
            "Epoch: 9040 || Loss : 2.921728134\n",
            "Epoch: 9050 || Loss : 2.929205418\n",
            "Epoch: 9060 || Loss : 2.911183834\n",
            "Epoch: 9070 || Loss : 2.935647488\n",
            "Epoch: 9080 || Loss : 2.909591198\n",
            "Epoch: 9090 || Loss : 2.926600456\n",
            "Epoch: 9100 || Loss : 2.923471451\n",
            "Epoch: 9110 || Loss : 2.907206535\n",
            "Epoch: 9120 || Loss : 2.937988758\n",
            "Epoch: 9130 || Loss : 2.905361414\n",
            "Epoch: 9140 || Loss : 2.932992935\n",
            "Epoch: 9150 || Loss : 2.913402557\n",
            "Epoch: 9160 || Loss : 2.917844772\n",
            "Epoch: 9170 || Loss : 2.930580616\n",
            "Epoch: 9180 || Loss : 2.911416531\n",
            "Epoch: 9190 || Loss : 2.933341026\n",
            "Epoch: 9200 || Loss : 2.913073063\n",
            "Epoch: 9210 || Loss : 2.921917439\n",
            "Epoch: 9220 || Loss : 2.920129061\n",
            "Epoch: 9230 || Loss : 2.919799328\n",
            "Epoch: 9240 || Loss : 2.922137022\n",
            "Epoch: 9250 || Loss : 2.921528101\n",
            "Epoch: 9260 || Loss : 2.919905186\n",
            "Epoch: 9270 || Loss : 2.921800852\n",
            "Epoch: 9280 || Loss : 2.921443224\n",
            "Epoch: 9290 || Loss : 2.917552233\n",
            "Epoch: 9300 || Loss : 2.922256708\n",
            "Epoch: 9310 || Loss : 2.919138432\n",
            "Epoch: 9320 || Loss : 2.920278311\n",
            "Epoch: 9330 || Loss : 2.920469522\n",
            "Epoch: 9340 || Loss : 2.919768810\n",
            "Epoch: 9350 || Loss : 2.920911789\n",
            "Epoch: 9360 || Loss : 2.919659376\n",
            "Epoch: 9370 || Loss : 2.921268940\n",
            "Epoch: 9380 || Loss : 2.919146538\n",
            "Epoch: 9390 || Loss : 2.921736717\n",
            "Epoch: 9400 || Loss : 2.921234131\n",
            "Epoch: 9410 || Loss : 2.916944981\n",
            "Epoch: 9420 || Loss : 2.922524929\n",
            "Epoch: 9430 || Loss : 2.917870283\n",
            "Epoch: 9440 || Loss : 2.921968222\n",
            "Epoch: 9450 || Loss : 2.926083803\n",
            "Epoch: 9460 || Loss : 2.915419340\n",
            "Epoch: 9470 || Loss : 2.926723719\n",
            "Epoch: 9480 || Loss : 2.915127993\n",
            "Epoch: 9490 || Loss : 2.921528101\n",
            "Epoch: 9500 || Loss : 2.919826746\n",
            "Epoch: 9510 || Loss : 2.915055752\n",
            "Epoch: 9520 || Loss : 2.932076693\n",
            "Epoch: 9530 || Loss : 2.909466028\n",
            "Epoch: 9540 || Loss : 2.927868128\n",
            "Epoch: 9550 || Loss : 2.914573908\n",
            "Epoch: 9560 || Loss : 2.919824123\n",
            "Epoch: 9570 || Loss : 2.925386906\n",
            "Epoch: 9580 || Loss : 2.909350157\n",
            "Epoch: 9590 || Loss : 2.934005260\n",
            "Epoch: 9600 || Loss : 2.907209873\n",
            "Epoch: 9610 || Loss : 2.928974152\n",
            "Epoch: 9620 || Loss : 2.918038845\n",
            "Epoch: 9630 || Loss : 2.914959669\n",
            "Epoch: 9640 || Loss : 2.928221941\n",
            "Epoch: 9650 || Loss : 2.913708925\n",
            "Epoch: 9660 || Loss : 2.927628994\n",
            "Epoch: 9670 || Loss : 2.914118290\n",
            "Epoch: 9680 || Loss : 2.923843384\n",
            "Epoch: 9690 || Loss : 2.918612480\n",
            "Epoch: 9700 || Loss : 2.917822838\n",
            "Epoch: 9710 || Loss : 2.923960447\n",
            "Epoch: 9720 || Loss : 2.913002014\n",
            "Epoch: 9730 || Loss : 2.927059412\n",
            "Epoch: 9740 || Loss : 2.916925192\n",
            "Epoch: 9750 || Loss : 2.919353247\n",
            "Epoch: 9760 || Loss : 2.922629833\n",
            "Epoch: 9770 || Loss : 2.917867661\n",
            "Epoch: 9780 || Loss : 2.925077915\n",
            "Epoch: 9790 || Loss : 2.917118549\n",
            "Epoch: 9800 || Loss : 2.922598362\n",
            "Epoch: 9810 || Loss : 2.920358419\n",
            "Epoch: 9820 || Loss : 2.917553902\n",
            "Epoch: 9830 || Loss : 2.922419071\n",
            "Epoch: 9840 || Loss : 2.915260077\n",
            "Epoch: 9850 || Loss : 2.922233820\n",
            "Epoch: 9860 || Loss : 2.919237375\n",
            "Epoch: 9870 || Loss : 2.916808844\n",
            "Epoch: 9880 || Loss : 2.925045729\n",
            "Epoch: 9890 || Loss : 2.911214113\n",
            "Epoch: 9900 || Loss : 2.924265385\n",
            "Epoch: 9910 || Loss : 2.917178869\n",
            "Epoch: 9920 || Loss : 2.918057680\n",
            "Epoch: 9930 || Loss : 2.928427696\n",
            "Epoch: 9940 || Loss : 2.907940865\n",
            "Epoch: 9950 || Loss : 2.931074142\n",
            "Epoch: 9960 || Loss : 2.910658121\n",
            "Epoch: 9970 || Loss : 2.917853594\n",
            "Epoch: 9980 || Loss : 2.927549839\n",
            "Epoch: 9990 || Loss : 2.902357101\n",
            "Optimization Complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV21B4r5a9kL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0c7171a3-9cfb-4fb4-b9d0-29914715b5ba"
      },
      "source": [
        "cbow.input_embedding.weight"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 3.0215,  1.2937,  1.4516,  ...,  3.2231,  0.0474,  3.2007],\n",
              "        [-0.6527,  1.0256, -0.7541,  ...,  0.4343,  0.1671,  2.4930],\n",
              "        [-1.5068, -0.9981,  2.1132,  ..., -2.5933,  2.3292,  1.3337],\n",
              "        ...,\n",
              "        [ 0.5691,  0.5858, -0.8781,  ..., -0.7339,  0.1027, -1.2055],\n",
              "        [ 0.1784,  4.0685,  0.7740,  ..., -3.3073,  1.1522, -0.3599],\n",
              "        [-0.2432,  1.9286, -2.2815,  ..., -0.9852, -1.0373,  1.8692]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rATCvThMbGK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "2a5b7794-f285-4819-8b68-b90553341cff"
      },
      "source": [
        "W_embedded = TSNE(n_components=2).fit_transform(cbow.input_embedding.weight.detach().numpy())\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(len(W_embedded[:11, :])):\n",
        "  plt.text(W_embedded[i,0],W_embedded[i,1],idx2word[i])\n",
        "plt.xlim(-250,150)\n",
        "plt.ylim(-250,150)\n",
        "plt.show()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAJDCAYAAAC/hOi8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAI0RaAAAjRFoAACN+f8BHfrEaDChLsgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}