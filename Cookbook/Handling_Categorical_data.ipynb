{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Nominal Features\n",
    "\n",
    "* Features which does not follow a natural ordering (e.g. apple, banana, grapes etc.) are called nominal features\n",
    "\n",
    "* Features which follow a natural ordering (e.g. low, medium, high etc.) are called ordinal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hot Encoding \n",
      " [[0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n",
      "Classes ['California' 'Delaware' 'Texas']\n",
      "Reversed One-Hot Encoding ['Texas' 'California' 'Texas' 'Delaware' 'Texas']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# For single class\n",
    "\n",
    "feature = np.array([[\"Texas\"],\n",
    "                   [\"California\"],\n",
    "                   [\"Texas\"],\n",
    "                   [\"Delaware\"],\n",
    "                   [\"Texas\"]])\n",
    "\n",
    "one_hot = preprocessing.LabelBinarizer()\n",
    "print('One Hot Encoding \\n',one_hot.fit_transform(feature))\n",
    "print('Classes {}'.format(one_hot.classes_))\n",
    "print('Reversed One-Hot Encoding {}'.format(one_hot.inverse_transform(one_hot.transform(feature))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hot Multiclass encoding \n",
      " [[0 0 0 1 1]\n",
      " [1 1 0 0 0]\n",
      " [0 0 0 1 1]\n",
      " [0 0 1 1 0]\n",
      " [1 0 0 0 1]]\n",
      "One Hot Multiclass classes: ['Albama' 'California' 'Delware' 'Florida' 'Texas']\n"
     ]
    }
   ],
   "source": [
    "# For multiclass\n",
    "multiclass_feature = [(\"Texas\", \"Florida\"),\n",
    "                     (\"California\", \"Albama\"),\n",
    "                     (\"Texas\", \"Florida\"),\n",
    "                     (\"Delware\", \"Florida\"),\n",
    "                     (\"Texas\", \"Albama\")]\n",
    "\n",
    "one_hot_multiclass = preprocessing.MultiLabelBinarizer()\n",
    "print(\"One Hot Multiclass encoding \\n\",one_hot_multiclass.fit_transform(multiclass_feature))\n",
    "print(\"One Hot Multiclass classes: {}\".format(one_hot_multiclass.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Ordinal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"Score\":[\"Low\", \"Low\", \"Medium\", \"Medium\", \"High\"]})\n",
    "\n",
    "# Create scale mappers\n",
    "scale_mapper = {\"Low\":1, \"Medium\":2, \"High\":3}\n",
    "\n",
    "df[\"Score\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Dictionary of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "data_dict = [{\"Red\":2, \"Blue\":4},\n",
    "            {\"Red\":4, \"Blue\":3},\n",
    "            {\"Red\":1, \"Yellow\":2},\n",
    "            {\"Red\": 2, \"Yellow\":2}]\n",
    "\n",
    "dictvectorizer = DictVectorizer(sparse=False)\n",
    "features = dictvectorizer.fit_transform(data_dict)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blue', 'Red', 'Yellow']\n"
     ]
    }
   ],
   "source": [
    "print(dictvectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing Missing Class Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 1.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "## Solution - 1 --> Applicable for smaller dataset\n",
    "\n",
    "# Create a feature matrix with categorical feature\n",
    "X = np.array([[0, 2.10, 1.45],\n",
    "            [1, 1.18, 1.33],\n",
    "            [0, 1.22, 1.27],\n",
    "            [1, -0.21, -1.19]])\n",
    "\n",
    "\n",
    "# Create feature matrix with missing categorical feature\n",
    "X_with_nan = np.array([[np.nan, 0.87, 1.31],\n",
    "                        [np.nan, -0.67, -0.22]])\n",
    "\n",
    "# Train KNN Learner\n",
    "clf = KNeighborsClassifier(3, weights='distance')\n",
    "trained_model = clf.fit(X[:, 1:], X[:, 0])\n",
    "\n",
    "imputed_values = trained_model.predict(X_with_nan[:,1:])\n",
    "\n",
    "X_with_imputed = np.hstack((imputed_values.reshape(-1,1), X_with_nan[:,1:]))\n",
    "\n",
    "np.vstack((X_with_imputed, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 0.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Solution - 2 --> Applicable for Larger Dataset\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X_complete = np.vstack((X_with_nan, X))\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "imputer.fit_transform(X_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Imbalanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create an imbalanced dataset\n",
    "features, targets = datasets.make_classification(n_samples = 150,\n",
    "                                                n_features = 3, \n",
    "                                                n_informative = 3, \n",
    "                                                n_redundant = 0,\n",
    "                                                n_classes = 2,\n",
    "                                                weights = [.10, .90],\n",
    "                                                random_state = 1)\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " So you can see how imbalanced the dataset is is.\n",
    "### Solution - 1 \n",
    "weights = {0:.9,  1: 0.1}\n",
    "\n",
    "RandomForestClassifier(weights = weights)\n",
    "\n",
    "### Solution - 2\n",
    "RandomForestClassifier(weights = 'balanced')\n",
    "\n",
    "which will create weights inversely proportional to class frequencies\n",
    "\n",
    "### Solution - 3\n",
    "Using either downsampling of majority class or upsampling of minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
